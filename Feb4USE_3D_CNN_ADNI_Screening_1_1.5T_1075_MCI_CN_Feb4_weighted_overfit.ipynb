{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from scipy import ndimage\n",
    "from scipy import linalg\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "index = np.array(range(629))\n",
    "random.seed(40)\n",
    "random.shuffle(index)\n",
    "\n",
    "train_index = index[0:440]\n",
    "val_index = index[440:503]\n",
    "test_index = index[503:629]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataimage_train = [dataimage[j] for j in train_index]\n",
    "#print(dataimage_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.]\n",
      "1 [0.]\n",
      "2 [0.]\n",
      "3 [0.]\n",
      "4 [0.]\n",
      "5 [0.]\n",
      "6 [0.]\n",
      "7 [0.]\n",
      "8 [0.]\n",
      "9 [0.]\n",
      "10 [0.]\n",
      "11 [0.]\n",
      "12 [0.]\n",
      "13 [0.]\n",
      "14 [0.]\n",
      "15 [0.]\n",
      "16 [0.]\n",
      "17 [0.]\n",
      "18 [0.]\n",
      "19 [0.]\n",
      "20 [0.]\n",
      "21 [0.]\n",
      "22 [0.]\n",
      "23 [0.]\n",
      "24 [0.]\n",
      "25 [0.]\n",
      "26 [0.]\n",
      "27 [0.]\n",
      "28 [0.]\n",
      "29 [0.]\n",
      "30 [0.]\n",
      "31 [0.]\n",
      "32 [0.]\n",
      "33 [0.]\n",
      "34 [0.]\n",
      "35 [0.]\n",
      "36 [0.]\n",
      "37 [0.]\n",
      "38 [0.]\n",
      "39 [0.]\n",
      "40 [0.]\n",
      "41 [0.]\n",
      "42 [0.]\n",
      "43 [0.]\n",
      "44 [0.]\n",
      "45 [0.]\n",
      "46 [0.]\n",
      "47 [0.]\n",
      "48 [0.]\n",
      "49 [0.]\n",
      "50 [0.]\n",
      "51 [0.]\n",
      "52 [0.]\n",
      "53 [0.]\n",
      "54 [0.]\n",
      "55 [0.]\n",
      "56 [0.]\n",
      "57 [0.]\n",
      "58 [0.]\n",
      "59 [0.]\n",
      "60 [0.]\n",
      "61 [0.]\n",
      "62 [0.]\n",
      "63 [0.]\n",
      "64 [0.]\n",
      "65 [0.]\n",
      "66 [0.]\n",
      "67 [0.]\n",
      "68 [0.]\n",
      "69 [0.]\n",
      "70 [0.]\n",
      "71 [0.]\n",
      "72 [0.]\n",
      "73 [0.]\n",
      "74 [0.]\n",
      "75 [0.]\n",
      "76 [0.]\n",
      "77 [0.]\n",
      "78 [0.]\n",
      "79 [0.]\n",
      "80 [0.]\n",
      "81 [0.]\n",
      "82 [0.]\n",
      "83 [0.]\n",
      "84 [0.]\n",
      "85 [0.]\n",
      "86 [0.]\n",
      "87 [0.]\n",
      "88 [0.]\n",
      "89 [0.]\n",
      "90 [0.]\n",
      "91 [0.]\n",
      "92 [0.]\n",
      "93 [0.]\n",
      "94 [0.]\n",
      "95 [0.]\n",
      "96 [0.]\n",
      "97 [0.]\n",
      "98 [0.]\n",
      "99 [0.]\n",
      "100 [0.]\n",
      "101 [0.]\n",
      "102 [0.]\n",
      "103 [0.]\n",
      "104 [0.]\n",
      "105 [0.]\n",
      "106 [0.]\n",
      "107 [0.]\n",
      "108 [0.]\n",
      "109 [0.]\n",
      "110 [0.]\n",
      "111 [0.]\n",
      "112 [0.]\n",
      "113 [0.]\n",
      "114 [0.]\n",
      "115 [0.]\n",
      "116 [0.]\n",
      "117 [0.]\n",
      "118 [0.]\n",
      "119 [0.]\n",
      "120 [0.]\n",
      "121 [0.]\n",
      "122 [0.]\n",
      "123 [0.]\n",
      "124 [0.]\n",
      "125 [0.]\n",
      "126 [0.]\n",
      "127 [0.]\n",
      "128 [0.]\n",
      "129 [0.]\n",
      "130 [0.]\n",
      "131 [0.]\n",
      "132 [0.]\n",
      "133 [0.]\n",
      "134 [0.]\n",
      "135 [0.]\n",
      "136 [0.]\n",
      "137 [0.]\n",
      "138 [0.]\n",
      "139 [0.]\n",
      "140 [0.]\n",
      "141 [0.]\n",
      "142 [0.]\n",
      "143 [0.]\n",
      "144 [0.]\n",
      "145 [0.]\n",
      "146 [0.]\n",
      "147 [0.]\n",
      "148 [0.]\n",
      "149 [0.]\n",
      "150 [0.]\n",
      "151 [0.]\n",
      "152 [0.]\n",
      "153 [0.]\n",
      "154 [0.]\n",
      "155 [0.]\n",
      "156 [0.]\n",
      "157 [0.]\n",
      "158 [0.]\n",
      "159 [0.]\n",
      "160 [0.]\n",
      "161 [0.]\n",
      "162 [0.]\n",
      "163 [0.]\n",
      "164 [0.]\n",
      "165 [0.]\n",
      "166 [0.]\n",
      "167 [0.]\n",
      "168 [0.]\n",
      "169 [0.]\n",
      "170 [0.]\n",
      "171 [0.]\n",
      "172 [0.]\n",
      "173 [0.]\n",
      "174 [0.]\n",
      "175 [0.]\n",
      "176 [0.]\n",
      "177 [0.]\n",
      "178 [0.]\n",
      "179 [0.]\n",
      "180 [0.]\n",
      "181 [0.]\n",
      "182 [0.]\n",
      "183 [0.]\n",
      "184 [0.]\n",
      "185 [0.]\n",
      "186 [0.]\n",
      "187 [0.]\n",
      "188 [0.]\n",
      "189 [0.]\n",
      "190 [0.]\n",
      "191 [0.]\n",
      "192 [0.]\n",
      "193 [0.]\n",
      "194 [0.]\n",
      "195 [0.]\n",
      "196 [0.]\n",
      "197 [0.]\n",
      "198 [0.]\n",
      "199 [0.]\n",
      "200 [0.]\n",
      "201 [0.]\n",
      "202 [0.]\n",
      "203 [0.]\n",
      "204 [0.]\n",
      "205 [0.]\n",
      "206 [0.]\n",
      "207 [0.]\n",
      "208 [0.]\n",
      "209 [0.]\n",
      "210 [0.]\n",
      "211 [0.]\n",
      "212 [0.]\n",
      "213 [0.]\n",
      "214 [0.]\n",
      "215 [0.]\n",
      "216 [0.]\n",
      "217 [0.]\n",
      "218 [0.]\n",
      "219 [0.]\n",
      "220 [0.]\n",
      "221 [0.]\n",
      "222 [0.]\n",
      "223 [0.]\n",
      "224 [0.]\n",
      "225 [0.]\n",
      "226 [0.]\n",
      "227 [0.]\n",
      "228 [1.]\n",
      "229 [1.]\n",
      "230 [1.]\n",
      "231 [1.]\n",
      "232 [1.]\n",
      "233 [1.]\n",
      "234 [1.]\n",
      "235 [1.]\n",
      "236 [1.]\n",
      "237 [1.]\n",
      "238 [1.]\n",
      "239 [1.]\n",
      "240 [1.]\n",
      "241 [1.]\n",
      "242 [1.]\n",
      "243 [1.]\n",
      "244 [1.]\n",
      "245 [1.]\n",
      "246 [1.]\n",
      "247 [1.]\n",
      "248 [1.]\n",
      "249 [1.]\n",
      "250 [1.]\n",
      "251 [1.]\n",
      "252 [1.]\n",
      "253 [1.]\n",
      "254 [1.]\n",
      "255 [1.]\n",
      "256 [1.]\n",
      "257 [1.]\n",
      "258 [1.]\n",
      "259 [1.]\n",
      "260 [1.]\n",
      "261 [1.]\n",
      "262 [1.]\n",
      "263 [1.]\n",
      "264 [1.]\n",
      "265 [1.]\n",
      "266 [1.]\n",
      "267 [1.]\n",
      "268 [1.]\n",
      "269 [1.]\n",
      "270 [1.]\n",
      "271 [1.]\n",
      "272 [1.]\n",
      "273 [1.]\n",
      "274 [1.]\n",
      "275 [1.]\n",
      "276 [1.]\n",
      "277 [1.]\n",
      "278 [1.]\n",
      "279 [1.]\n",
      "280 [1.]\n",
      "281 [1.]\n",
      "282 [1.]\n",
      "283 [1.]\n",
      "284 [1.]\n",
      "285 [1.]\n",
      "286 [1.]\n",
      "287 [1.]\n",
      "288 [1.]\n",
      "289 [1.]\n",
      "290 [1.]\n",
      "291 [1.]\n",
      "292 [1.]\n",
      "293 [1.]\n",
      "294 [1.]\n",
      "295 [1.]\n",
      "296 [1.]\n",
      "297 [1.]\n",
      "298 [1.]\n",
      "299 [1.]\n",
      "300 [1.]\n",
      "301 [1.]\n",
      "302 [1.]\n",
      "303 [1.]\n",
      "304 [1.]\n",
      "305 [1.]\n",
      "306 [1.]\n",
      "307 [1.]\n",
      "308 [1.]\n",
      "309 [1.]\n",
      "310 [1.]\n",
      "311 [1.]\n",
      "312 [1.]\n",
      "313 [1.]\n",
      "314 [1.]\n",
      "315 [1.]\n",
      "316 [1.]\n",
      "317 [1.]\n",
      "318 [1.]\n",
      "319 [1.]\n",
      "320 [1.]\n",
      "321 [1.]\n",
      "322 [1.]\n",
      "323 [1.]\n",
      "324 [1.]\n",
      "325 [1.]\n",
      "326 [1.]\n",
      "327 [1.]\n",
      "328 [1.]\n",
      "329 [1.]\n",
      "330 [1.]\n",
      "331 [1.]\n",
      "332 [1.]\n",
      "333 [1.]\n",
      "334 [1.]\n",
      "335 [1.]\n",
      "336 [1.]\n",
      "337 [1.]\n",
      "338 [1.]\n",
      "339 [1.]\n",
      "340 [1.]\n",
      "341 [1.]\n",
      "342 [1.]\n",
      "343 [1.]\n",
      "344 [1.]\n",
      "345 [1.]\n",
      "346 [1.]\n",
      "347 [1.]\n",
      "348 [1.]\n",
      "349 [1.]\n",
      "350 [1.]\n",
      "351 [1.]\n",
      "352 [1.]\n",
      "353 [1.]\n",
      "354 [1.]\n",
      "355 [1.]\n",
      "356 [1.]\n",
      "357 [1.]\n",
      "358 [1.]\n",
      "359 [1.]\n",
      "360 [1.]\n",
      "361 [1.]\n",
      "362 [1.]\n",
      "363 [1.]\n",
      "364 [1.]\n",
      "365 [1.]\n",
      "366 [1.]\n",
      "367 [1.]\n",
      "368 [1.]\n",
      "369 [1.]\n",
      "370 [1.]\n",
      "371 [1.]\n",
      "372 [1.]\n",
      "373 [1.]\n",
      "374 [1.]\n",
      "375 [1.]\n",
      "376 [1.]\n",
      "377 [1.]\n",
      "378 [1.]\n",
      "379 [1.]\n",
      "380 [1.]\n",
      "381 [1.]\n",
      "382 [1.]\n",
      "383 [1.]\n",
      "384 [1.]\n",
      "385 [1.]\n",
      "386 [1.]\n",
      "387 [1.]\n",
      "388 [1.]\n",
      "389 [1.]\n",
      "390 [1.]\n",
      "391 [1.]\n",
      "392 [1.]\n",
      "393 [1.]\n",
      "394 [1.]\n",
      "395 [1.]\n",
      "396 [1.]\n",
      "397 [1.]\n",
      "398 [1.]\n",
      "399 [1.]\n",
      "400 [1.]\n",
      "401 [1.]\n",
      "402 [1.]\n",
      "403 [1.]\n",
      "404 [1.]\n",
      "405 [1.]\n",
      "406 [1.]\n",
      "407 [1.]\n",
      "408 [1.]\n",
      "409 [1.]\n",
      "410 [1.]\n",
      "411 [1.]\n",
      "412 [1.]\n",
      "413 [1.]\n",
      "414 [1.]\n",
      "415 [1.]\n",
      "416 [1.]\n",
      "417 [1.]\n",
      "418 [1.]\n",
      "419 [1.]\n",
      "420 [1.]\n",
      "421 [1.]\n",
      "422 [1.]\n",
      "423 [1.]\n",
      "424 [1.]\n",
      "425 [1.]\n",
      "426 [1.]\n",
      "427 [1.]\n",
      "428 [1.]\n",
      "429 [1.]\n",
      "430 [1.]\n",
      "431 [1.]\n",
      "432 [1.]\n",
      "433 [1.]\n",
      "434 [1.]\n",
      "435 [1.]\n",
      "436 [1.]\n",
      "437 [1.]\n",
      "438 [1.]\n",
      "439 [1.]\n",
      "440 [1.]\n",
      "441 [1.]\n",
      "442 [1.]\n",
      "443 [1.]\n",
      "444 [1.]\n",
      "445 [1.]\n",
      "446 [1.]\n",
      "447 [1.]\n",
      "448 [1.]\n",
      "449 [1.]\n",
      "450 [1.]\n",
      "451 [1.]\n",
      "452 [1.]\n",
      "453 [1.]\n",
      "454 [1.]\n",
      "455 [1.]\n",
      "456 [1.]\n",
      "457 [1.]\n",
      "458 [1.]\n",
      "459 [1.]\n",
      "460 [1.]\n",
      "461 [1.]\n",
      "462 [1.]\n",
      "463 [1.]\n",
      "464 [1.]\n",
      "465 [1.]\n",
      "466 [1.]\n",
      "467 [1.]\n",
      "468 [1.]\n",
      "469 [1.]\n",
      "470 [1.]\n",
      "471 [1.]\n",
      "472 [1.]\n",
      "473 [1.]\n",
      "474 [1.]\n",
      "475 [1.]\n",
      "476 [1.]\n",
      "477 [1.]\n",
      "478 [1.]\n",
      "479 [1.]\n",
      "480 [1.]\n",
      "481 [1.]\n",
      "482 [1.]\n",
      "483 [1.]\n",
      "484 [1.]\n",
      "485 [1.]\n",
      "486 [1.]\n",
      "487 [1.]\n",
      "488 [1.]\n",
      "489 [1.]\n",
      "490 [1.]\n",
      "491 [1.]\n",
      "492 [1.]\n",
      "493 [1.]\n",
      "494 [1.]\n",
      "495 [1.]\n",
      "496 [1.]\n",
      "497 [1.]\n",
      "498 [1.]\n",
      "499 [1.]\n",
      "500 [1.]\n",
      "501 [1.]\n",
      "502 [1.]\n",
      "503 [1.]\n",
      "504 [1.]\n",
      "505 [1.]\n",
      "506 [1.]\n",
      "507 [1.]\n",
      "508 [1.]\n",
      "509 [1.]\n",
      "510 [1.]\n",
      "511 [1.]\n",
      "512 [1.]\n",
      "513 [1.]\n",
      "514 [1.]\n",
      "515 [1.]\n",
      "516 [1.]\n",
      "517 [1.]\n",
      "518 [1.]\n",
      "519 [1.]\n",
      "520 [1.]\n",
      "521 [1.]\n",
      "522 [1.]\n",
      "523 [1.]\n",
      "524 [1.]\n",
      "525 [1.]\n",
      "526 [1.]\n",
      "527 [1.]\n",
      "528 [1.]\n",
      "529 [1.]\n",
      "530 [1.]\n",
      "531 [1.]\n",
      "532 [1.]\n",
      "533 [1.]\n",
      "534 [1.]\n",
      "535 [1.]\n",
      "536 [1.]\n",
      "537 [1.]\n",
      "538 [1.]\n",
      "539 [1.]\n",
      "540 [1.]\n",
      "541 [1.]\n",
      "542 [1.]\n",
      "543 [1.]\n",
      "544 [1.]\n",
      "545 [1.]\n",
      "546 [1.]\n",
      "547 [1.]\n",
      "548 [1.]\n",
      "549 [1.]\n",
      "550 [1.]\n",
      "551 [1.]\n",
      "552 [1.]\n",
      "553 [1.]\n",
      "554 [1.]\n",
      "555 [1.]\n",
      "556 [1.]\n",
      "557 [1.]\n",
      "558 [1.]\n",
      "559 [1.]\n",
      "560 [1.]\n",
      "561 [1.]\n",
      "562 [1.]\n",
      "563 [1.]\n",
      "564 [1.]\n",
      "565 [1.]\n",
      "566 [1.]\n",
      "567 [1.]\n",
      "568 [1.]\n",
      "569 [1.]\n",
      "570 [1.]\n",
      "571 [1.]\n",
      "572 [1.]\n",
      "573 [1.]\n",
      "574 [1.]\n",
      "575 [1.]\n",
      "576 [1.]\n",
      "577 [1.]\n",
      "578 [1.]\n",
      "579 [1.]\n",
      "580 [1.]\n",
      "581 [1.]\n",
      "582 [1.]\n",
      "583 [1.]\n",
      "584 [1.]\n",
      "585 [1.]\n",
      "586 [1.]\n",
      "587 [1.]\n",
      "588 [1.]\n",
      "589 [1.]\n",
      "590 [1.]\n",
      "591 [1.]\n",
      "592 [1.]\n",
      "593 [1.]\n",
      "594 [1.]\n",
      "595 [1.]\n",
      "596 [1.]\n",
      "597 [1.]\n",
      "598 [1.]\n",
      "599 [1.]\n",
      "600 [1.]\n",
      "601 [1.]\n",
      "602 [1.]\n",
      "603 [1.]\n",
      "604 [1.]\n",
      "605 [1.]\n",
      "606 [1.]\n",
      "607 [1.]\n",
      "608 [1.]\n",
      "609 [1.]\n",
      "610 [1.]\n",
      "611 [1.]\n",
      "612 [1.]\n",
      "613 [1.]\n",
      "614 [1.]\n",
      "615 [1.]\n",
      "616 [1.]\n",
      "617 [1.]\n",
      "618 [1.]\n",
      "619 [1.]\n",
      "620 [1.]\n",
      "621 [1.]\n",
      "622 [1.]\n",
      "623 [1.]\n",
      "624 [1.]\n",
      "625 [1.]\n",
      "626 [1.]\n",
      "627 [1.]\n",
      "628 [1.]\n"
     ]
    }
   ],
   "source": [
    "lab = np.zeros((629,1)) #first AD:188 then CN:288\n",
    "lab[228:629, 0] = 1 #MCI -- 1; CN -- 0\n",
    "for i in range(0, 629):\n",
    "    print(i, lab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401.0 228.0 629.0\n"
     ]
    }
   ],
   "source": [
    "cn = 0.\n",
    "mci = 0.\n",
    "total_num = 0.\n",
    "for i in lab:\n",
    "    if(i == 1):\n",
    "        mci += 1\n",
    "    elif(i == 0):\n",
    "        cn += 1\n",
    "total_num = cn + mci\n",
    "print(mci, cn, total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "def ToTensor(np_array):\n",
    "    tensor = torch.from_numpy(np_array)\n",
    "    tensor = tensor.float()\n",
    "    return tensor\n",
    "\n",
    "class ADNI_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, ptype, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        #if(ptype == 'train'):\n",
    "            #img = np.load('GRAY_AD_CN_Jan25.npy')\n",
    "        \n",
    "        #if(ptype == 'val'):\n",
    "            #img = np.load('GRAY_AD_CN_Jan25.npy')\n",
    "        \n",
    "        #if(ptype == 'test'):\n",
    "            #img = np.load('GRAY_AD_CN_Jan25.npy')\n",
    "        self.ptype = ptype\n",
    "        \n",
    "        self.img = np.load('GRAY_CN_MCI_Feb4_3D.npy') # 416 * ((121 * 121) * 3)\n",
    "        self.lab = np.zeros((629,1)) #first AD:188 then CN:288\n",
    "        self.lab[228:629, 0] = 1 #CN -- 0; MCI -- 1\n",
    "        #for i in range(188):\n",
    "            #lab[i] = 1\n",
    "        if(self.ptype == 'train'):\n",
    "            self.img = self.img[train_index]\n",
    "            #img = np.load('GRAY_AD_CN_Jan25.npy')\n",
    "            #for i in range(440):\n",
    "                #for j in range(3):\n",
    "                    #self.img[i][j] = self.img[i][j] + np.random.normal(0, 0.01, (121, 121))\n",
    "                    #print(self.img[i][j].shape)\n",
    "                    #count += 1\n",
    "            #print(count)\n",
    "            self.lab = self.lab[train_index]\n",
    "        if(self.ptype == 'val'):\n",
    "            #img = np.load('GRAY_AD_CN_Jan25.npy')\n",
    "            self.img = self.img[val_index]\n",
    "            self.lab = self.lab[val_index]\n",
    "        if(self.ptype == 'test'):\n",
    "            #img = np.load('GRAY_AD_CN_Jan25.npy')\n",
    "            self.img = self.img[test_index]\n",
    "            self.lab = self.lab[test_index]\n",
    "        \n",
    "        print(\"great job dude\")\n",
    "        \n",
    "\n",
    "    def __len__(self):#return int: number of mri\n",
    "        return len(self.img)\n",
    "\n",
    "    def __getitem__(self, idx):#input the dataset and desires i-th item\n",
    "        sample = {'image': self.img[idx], 'labels': self.lab[idx,0]} \n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great job dude\n",
      "great job dude\n",
      "great job dude\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "ADNI_Data_train = ADNI_Dataset('train')\n",
    "\n",
    "ADNI_Data_val = ADNI_Dataset('val')\n",
    "\n",
    "ADNI_Data_test = ADNI_Dataset('test')\n",
    "\n",
    "\n",
    "\n",
    "dataloader_train = DataLoader(ADNI_Data_train, batch_size=2,\n",
    "                        shuffle=True, num_workers=4)\n",
    "dataloader_val = DataLoader(ADNI_Data_val, batch_size=2,\n",
    "                        shuffle=True, num_workers=4)\n",
    "dataloader_test = DataLoader(ADNI_Data_test, batch_size=2,\n",
    "                        shuffle=True, num_workers=4)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "#design the network configuration\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "#121 * 145 * 121 * 1\n",
    "#60 * 72 * 60 * 2\n",
    "#30 * 36 * 30 * 4\n",
    "#15 * 18 * 15 * 8\n",
    "#7 * 9 * 7 * 16\n",
    "#3 * 4 * 3 * 32\n",
    "#linear: 3 * 4 * 3 * 32 = 1152\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels = 1, out_channels = 2, kernel_size = 5, padding=2)\n",
    "        self.conv2 = nn.Conv3d(2, 4, 5, padding=2)\n",
    "        self.conv3 = nn.Conv3d(4, 8, 5, padding=2)\n",
    "        self.conv4 = nn.Conv3d(8, 16, 5, padding=2)\n",
    "        self.conv5 = nn.Conv3d(16, 32, 5, padding=2)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.fc1 = nn.Linear(3 * 4 * 3 * 32, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x): #batch_size * 256*256*160*1\n",
    "        x = self.pool(F.relu(self.conv1(x)))#batch_size * 128 * 128 * 80 * 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))#batch_size * 64 * 64 * 40 * 4\n",
    "        x = self.pool(F.relu(self.conv3(x)))#batch_size * 32 * 32 * 20 * 8\n",
    "        x = self.pool(F.relu(self.conv4(x)))#batch_size * 16 * 16 * 10 * 16\n",
    "        x = self.pool(F.relu(self.conv5(x)))#batch_size * 8 * 8 * 5 * 32\n",
    "        x = x.view(-1, 3 * 4 * 3 * 32)#batch_size * 10240(8*8*5*32)\n",
    "        x = F.relu(self.fc1(x))#batch_size * 1024\n",
    "        x = F.relu(self.fc2(x))#batch_size * 256\n",
    "        x = F.relu(self.fc3(x))#batch_size * 64\n",
    "        x = self.fc4(x)#batch_size * 3\n",
    "        return x\n",
    "\n",
    "net_3d = Net().cuda()\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch \n",
    "Weight = torch.tensor([total_num / cn, total_num / mci])\n",
    "criterion = nn.CrossEntropyLoss(weight = Weight.cuda())\n",
    "optimizer = optim.SGD(net_3d.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.680\n",
      "[2] loss: 0.749\n",
      "[3] loss: 0.645\n",
      "[4] loss: 0.745\n",
      "[5] loss: 0.682\n",
      "[6] loss: 0.736\n",
      "[7] loss: 0.685\n",
      "[8] loss: 0.719\n",
      "[9] loss: 0.707\n",
      "[10] loss: 0.694\n",
      "[11] loss: 0.711\n",
      "[12] loss: 0.669\n",
      "[13] loss: 0.704\n",
      "[14] loss: 0.706\n",
      "[15] loss: 0.744\n",
      "[16] loss: 0.646\n",
      "[17] loss: 0.748\n",
      "[18] loss: 0.709\n",
      "[19] loss: 0.707\n",
      "[20] loss: 0.652\n",
      "[21] loss: 0.706\n",
      "[22] loss: 0.706\n",
      "[23] loss: 0.733\n",
      "[24] loss: 0.702\n",
      "[25] loss: 0.673\n",
      "[26] loss: 0.698\n",
      "[27] loss: 0.706\n",
      "[28] loss: 0.694\n",
      "[29] loss: 0.701\n",
      "[30] loss: 0.705\n",
      "[31] loss: 0.691\n",
      "[32] loss: 0.691\n",
      "[33] loss: 0.701\n",
      "[34] loss: 0.692\n",
      "[35] loss: 0.693\n",
      "[36] loss: 0.692\n",
      "[37] loss: 0.696\n",
      "[38] loss: 0.680\n",
      "[39] loss: 0.670\n",
      "[40] loss: 0.704\n",
      "[41] loss: 0.645\n",
      "[42] loss: 0.630\n",
      "[43] loss: 0.720\n",
      "[44] loss: 0.726\n",
      "[45] loss: 0.731\n",
      "[46] loss: 0.734\n",
      "[47] loss: 0.736\n",
      "[48] loss: 0.737\n",
      "[49] loss: 0.737\n",
      "[50] loss: 0.736\n",
      "[51] loss: 0.734\n",
      "[52] loss: 0.731\n",
      "[53] loss: 0.728\n",
      "[54] loss: 0.601\n",
      "[55] loss: 0.723\n",
      "[56] loss: 0.721\n",
      "[57] loss: 0.615\n",
      "[58] loss: 0.718\n",
      "[59] loss: 0.717\n",
      "[60] loss: 0.769\n",
      "[61] loss: 0.712\n",
      "[62] loss: 0.708\n",
      "[63] loss: 0.705\n",
      "[64] loss: 0.668\n",
      "[65] loss: 0.699\n",
      "[66] loss: 0.697\n",
      "[67] loss: 0.688\n",
      "[68] loss: 0.689\n",
      "[69] loss: 0.702\n",
      "[70] loss: 0.695\n",
      "[71] loss: 0.694\n",
      "[72] loss: 0.693\n",
      "[73] loss: 0.700\n",
      "[74] loss: 0.687\n",
      "[75] loss: 0.704\n",
      "[76] loss: 0.691\n",
      "[77] loss: 0.703\n",
      "[78] loss: 0.692\n",
      "[79] loss: 0.694\n",
      "[80] loss: 0.695\n",
      "[81] loss: 0.708\n",
      "[82] loss: 0.697\n",
      "[83] loss: 0.681\n",
      "[84] loss: 0.698\n",
      "[85] loss: 0.698\n",
      "[86] loss: 0.698\n",
      "[87] loss: 0.698\n",
      "[88] loss: 0.697\n",
      "[89] loss: 0.696\n",
      "[90] loss: 0.696\n",
      "[91] loss: 0.701\n",
      "[92] loss: 0.705\n",
      "[93] loss: 0.691\n",
      "[94] loss: 0.691\n",
      "[95] loss: 0.690\n",
      "[96] loss: 0.690\n",
      "[97] loss: 0.689\n",
      "[98] loss: 0.688\n",
      "[99] loss: 0.721\n",
      "[100] loss: 0.720\n",
      "[101] loss: 0.713\n",
      "[102] loss: 0.685\n",
      "[103] loss: 0.690\n",
      "[104] loss: 0.698\n",
      "[105] loss: 0.693\n",
      "[106] loss: 0.691\n",
      "[107] loss: 0.683\n",
      "[108] loss: 0.670\n",
      "[109] loss: 0.705\n",
      "[110] loss: 0.710\n",
      "[111] loss: 0.713\n",
      "[112] loss: 0.716\n",
      "[113] loss: 0.619\n",
      "[114] loss: 0.721\n",
      "[115] loss: 0.604\n",
      "[116] loss: 0.727\n",
      "[117] loss: 0.587\n",
      "[118] loss: 0.576\n",
      "[119] loss: 0.742\n",
      "[120] loss: 0.552\n",
      "[121] loss: 0.538\n",
      "[122] loss: 0.763\n",
      "[123] loss: 0.510\n",
      "[124] loss: 0.778\n",
      "[125] loss: 0.955\n",
      "[126] loss: 0.482\n",
      "[127] loss: 0.792\n",
      "[128] loss: 0.794\n",
      "[129] loss: 0.471\n",
      "[130] loss: 0.467\n",
      "[131] loss: 0.998\n",
      "[132] loss: 0.803\n",
      "[133] loss: 0.461\n",
      "[134] loss: 0.803\n",
      "[135] loss: 0.803\n",
      "[136] loss: 0.800\n",
      "[137] loss: 0.796\n",
      "[138] loss: 0.791\n",
      "[139] loss: 0.956\n",
      "[140] loss: 0.776\n",
      "[141] loss: 0.514\n",
      "[142] loss: 0.761\n",
      "[143] loss: 0.755\n",
      "[144] loss: 0.863\n",
      "[145] loss: 0.565\n",
      "[146] loss: 0.577\n",
      "[147] loss: 0.732\n",
      "[148] loss: 0.729\n",
      "[149] loss: 0.599\n",
      "[150] loss: 0.724\n",
      "[151] loss: 0.607\n",
      "[152] loss: 0.722\n",
      "[153] loss: 0.722\n",
      "[154] loss: 0.720\n",
      "[155] loss: 0.616\n",
      "[156] loss: 0.719\n",
      "[157] loss: 0.718\n",
      "[158] loss: 0.620\n",
      "[159] loss: 0.618\n",
      "[160] loss: 0.611\n",
      "[161] loss: 0.601\n",
      "[162] loss: 0.731\n",
      "[163] loss: 0.735\n",
      "[164] loss: 0.569\n",
      "[165] loss: 0.744\n",
      "[166] loss: 0.860\n",
      "[167] loss: 0.748\n",
      "[168] loss: 0.550\n",
      "[169] loss: 0.547\n",
      "[170] loss: 0.540\n",
      "[171] loss: 0.530\n",
      "[172] loss: 0.766\n",
      "[173] loss: 0.771\n",
      "[174] loss: 0.775\n",
      "[175] loss: 0.498\n",
      "[176] loss: 0.781\n",
      "[177] loss: 0.783\n",
      "[178] loss: 0.784\n",
      "[179] loss: 0.783\n",
      "[180] loss: 0.780\n",
      "[181] loss: 0.935\n",
      "[182] loss: 0.509\n",
      "[183] loss: 0.515\n",
      "[184] loss: 0.517\n",
      "[185] loss: 0.515\n",
      "[186] loss: 0.770\n",
      "[187] loss: 0.506\n",
      "[188] loss: 0.500\n",
      "[189] loss: 0.490\n",
      "[190] loss: 0.790\n",
      "[191] loss: 0.471\n",
      "[192] loss: 0.803\n",
      "[193] loss: 0.808\n",
      "[194] loss: 0.811\n",
      "[195] loss: 0.811\n",
      "[196] loss: 0.450\n",
      "[197] loss: 0.448\n",
      "[198] loss: 0.443\n",
      "[199] loss: 0.821\n",
      "[200] loss: 0.432\n",
      "[201] loss: 0.425\n",
      "[202] loss: 0.417\n",
      "[203] loss: 0.406\n",
      "[204] loss: 1.121\n",
      "[205] loss: 0.389\n",
      "[206] loss: 0.382\n",
      "[207] loss: 1.167\n",
      "[208] loss: 0.370\n",
      "[209] loss: 0.887\n",
      "[210] loss: 0.889\n",
      "[211] loss: 0.887\n",
      "[212] loss: 0.884\n",
      "[213] loss: 0.374\n",
      "[214] loss: 0.875\n",
      "[215] loss: 0.870\n",
      "[216] loss: 1.132\n",
      "[217] loss: 0.401\n",
      "[218] loss: 0.409\n",
      "[219] loss: 0.414\n",
      "[220] loss: 0.415\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 1.082\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 1.082\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.414\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 1.082\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.840\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.414\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.414\n",
      "[2] loss: 0.843\n",
      "[3] loss: 0.845\n",
      "[4] loss: 0.410\n",
      "[5] loss: 0.845\n",
      "[6] loss: 0.844\n",
      "[7] loss: 0.841\n",
      "[8] loss: 0.419\n",
      "[9] loss: 0.421\n",
      "[10] loss: 0.420\n",
      "[11] loss: 0.417\n",
      "[12] loss: 0.843\n",
      "[13] loss: 0.845\n",
      "[14] loss: 0.408\n",
      "[15] loss: 0.405\n",
      "[16] loss: 0.853\n",
      "[17] loss: 0.398\n",
      "[18] loss: 0.859\n",
      "[19] loss: 1.127\n",
      "[20] loss: 1.119\n",
      "[21] loss: 0.848\n",
      "[22] loss: 0.839\n",
      "[23] loss: 0.829\n",
      "[24] loss: 1.032\n",
      "[25] loss: 0.458\n",
      "[26] loss: 0.795\n",
      "[27] loss: 0.785\n",
      "[28] loss: 0.502\n",
      "[29] loss: 0.769\n",
      "[30] loss: 0.524\n",
      "[31] loss: 0.758\n",
      "[32] loss: 0.874\n",
      "[33] loss: 0.553\n",
      "[34] loss: 0.561\n",
      "[35] loss: 0.564\n",
      "[36] loss: 0.741\n",
      "[37] loss: 0.564\n",
      "[38] loss: 0.846\n",
      "[39] loss: 0.843\n",
      "[40] loss: 0.570\n",
      "[41] loss: 0.573\n",
      "[42] loss: 0.571\n",
      "[43] loss: 0.740\n",
      "[44] loss: 0.563\n",
      "[45] loss: 0.745\n",
      "[46] loss: 0.747\n",
      "[47] loss: 0.748\n",
      "[48] loss: 0.550\n",
      "[49] loss: 0.547\n",
      "[50] loss: 0.539\n",
      "[51] loss: 0.889\n",
      "[52] loss: 0.526\n",
      "[53] loss: 0.765\n",
      "[54] loss: 0.767\n",
      "[55] loss: 0.768\n",
      "[56] loss: 0.514\n",
      "[57] loss: 0.769\n",
      "[58] loss: 0.770\n",
      "[59] loss: 0.769\n",
      "[60] loss: 0.515\n",
      "[61] loss: 0.515\n",
      "[62] loss: 0.511\n",
      "[63] loss: 0.504\n",
      "[64] loss: 0.494\n",
      "[65] loss: 0.787\n",
      "[66] loss: 0.474\n",
      "[67] loss: 0.463\n",
      "[68] loss: 0.450\n",
      "[69] loss: 0.436\n",
      "[70] loss: 1.068\n",
      "[71] loss: 1.084\n",
      "[72] loss: 0.411\n",
      "[73] loss: 0.847\n",
      "[74] loss: 0.405\n",
      "[75] loss: 0.852\n",
      "[76] loss: 0.399\n",
      "[77] loss: 0.396\n",
      "[78] loss: 0.862\n",
      "[79] loss: 0.387\n",
      "[80] loss: 0.870\n",
      "[81] loss: 0.872\n",
      "[82] loss: 0.381\n",
      "[83] loss: 0.873\n",
      "[84] loss: 0.380\n",
      "[85] loss: 0.874\n",
      "[86] loss: 0.873\n",
      "[87] loss: 0.382\n",
      "[88] loss: 0.383\n",
      "[89] loss: 0.871\n",
      "[90] loss: 0.870\n",
      "[91] loss: 0.867\n",
      "[92] loss: 0.862\n",
      "[93] loss: 0.856\n",
      "[94] loss: 0.848\n",
      "[95] loss: 0.416\n",
      "[96] loss: 0.832\n",
      "[97] loss: 0.431\n",
      "[98] loss: 0.436\n",
      "[99] loss: 0.820\n",
      "[100] loss: 0.441\n",
      "[101] loss: 1.030\n",
      "[102] loss: 0.448\n",
      "[103] loss: 0.810\n",
      "[104] loss: 0.454\n",
      "[105] loss: 0.455\n",
      "[106] loss: 0.453\n",
      "[107] loss: 0.448\n",
      "[108] loss: 0.818\n",
      "[109] loss: 0.436\n",
      "[110] loss: 1.052\n",
      "[111] loss: 0.429\n",
      "[112] loss: 1.060\n",
      "[113] loss: 0.828\n",
      "[114] loss: 0.825\n",
      "[115] loss: 0.820\n",
      "[116] loss: 0.814\n",
      "[117] loss: 0.807\n",
      "[118] loss: 0.465\n",
      "[119] loss: 0.472\n",
      "[120] loss: 0.792\n",
      "[121] loss: 0.789\n",
      "[122] loss: 0.486\n",
      "[123] loss: 0.950\n",
      "[124] loss: 0.938\n",
      "[125] loss: 0.509\n",
      "[126] loss: 0.517\n",
      "[127] loss: 0.764\n",
      "[128] loss: 0.761\n",
      "[129] loss: 0.757\n",
      "[130] loss: 0.753\n",
      "[131] loss: 0.748\n",
      "[132] loss: 0.560\n",
      "[133] loss: 0.740\n",
      "[134] loss: 0.573\n",
      "[135] loss: 0.736\n",
      "[136] loss: 0.734\n",
      "[137] loss: 0.815\n",
      "[138] loss: 0.595\n",
      "[139] loss: 0.725\n",
      "[140] loss: 0.606\n",
      "[141] loss: 0.608\n",
      "[142] loss: 0.604\n",
      "[143] loss: 0.597\n",
      "[144] loss: 0.586\n",
      "[145] loss: 0.737\n",
      "[146] loss: 0.742\n",
      "[147] loss: 0.746\n",
      "[148] loss: 0.550\n",
      "[149] loss: 0.871\n",
      "[150] loss: 0.753\n",
      "[151] loss: 0.540\n",
      "[152] loss: 0.755\n",
      "[153] loss: 0.880\n",
      "[154] loss: 0.540\n",
      "[155] loss: 0.540\n",
      "[156] loss: 0.537\n",
      "[157] loss: 0.530\n",
      "[158] loss: 0.520\n",
      "[159] loss: 0.771\n",
      "[160] loss: 0.777\n",
      "[161] loss: 0.780\n",
      "[162] loss: 0.490\n",
      "[163] loss: 0.484\n",
      "[164] loss: 0.792\n",
      "[165] loss: 0.796\n",
      "[166] loss: 0.798\n",
      "[167] loss: 0.798\n",
      "[168] loss: 0.983\n",
      "[169] loss: 0.972\n",
      "[170] loss: 0.784\n",
      "[171] loss: 0.500\n",
      "[172] loss: 0.508\n",
      "[173] loss: 0.512\n",
      "[174] loss: 0.914\n",
      "[175] loss: 0.765\n",
      "[176] loss: 0.896\n",
      "[177] loss: 0.755\n",
      "[178] loss: 0.863\n",
      "[179] loss: 0.565\n",
      "[180] loss: 0.577\n",
      "[181] loss: 0.732\n",
      "[182] loss: 0.808\n",
      "[183] loss: 0.724\n",
      "[184] loss: 0.615\n",
      "[185] loss: 0.716\n",
      "[186] loss: 0.713\n",
      "[187] loss: 0.710\n",
      "[188] loss: 0.706\n",
      "[189] loss: 0.661\n",
      "[190] loss: 0.722\n",
      "[191] loss: 0.675\n",
      "[192] loss: 0.697\n",
      "[193] loss: 0.683\n",
      "[194] loss: 0.704\n",
      "[195] loss: 0.695\n",
      "[196] loss: 0.693\n",
      "[197] loss: 0.699\n",
      "[198] loss: 0.687\n",
      "[199] loss: 0.681\n",
      "[200] loss: 0.716\n",
      "[201] loss: 0.686\n",
      "[202] loss: 0.685\n",
      "[203] loss: 0.657\n",
      "[204] loss: 0.681\n",
      "[205] loss: 0.638\n",
      "[206] loss: 0.676\n",
      "[207] loss: 0.673\n",
      "[208] loss: 0.671\n",
      "[209] loss: 0.669\n",
      "[210] loss: 0.825\n",
      "[211] loss: 0.831\n",
      "[212] loss: 0.830\n",
      "[213] loss: 0.822\n",
      "[214] loss: 0.669\n",
      "[215] loss: 0.671\n",
      "[216] loss: 0.605\n",
      "[217] loss: 0.787\n",
      "[218] loss: 0.778\n",
      "[219] loss: 0.765\n",
      "[220] loss: 0.680\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.656\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.656\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.656\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.656\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.656\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.683\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.732\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.656\n",
      "\n",
      "\n",
      "[1] loss: 0.683\n",
      "[2] loss: 0.686\n",
      "[3] loss: 0.711\n",
      "[4] loss: 0.697\n",
      "[5] loss: 0.697\n",
      "[6] loss: 0.721\n",
      "[7] loss: 0.659\n",
      "[8] loss: 0.707\n",
      "[9] loss: 0.710\n",
      "[10] loss: 0.633\n",
      "[11] loss: 0.624\n",
      "[12] loss: 0.783\n",
      "[13] loss: 0.604\n",
      "[14] loss: 0.594\n",
      "[15] loss: 0.581\n",
      "[16] loss: 0.565\n",
      "[17] loss: 0.547\n",
      "[18] loss: 0.528\n",
      "[19] loss: 0.771\n",
      "[20] loss: 0.781\n",
      "[21] loss: 0.789\n",
      "[22] loss: 0.795\n",
      "[23] loss: 0.798\n",
      "[24] loss: 0.463\n",
      "[25] loss: 0.458\n",
      "[26] loss: 0.810\n",
      "[27] loss: 0.814\n",
      "[28] loss: 1.027\n",
      "[29] loss: 1.021\n",
      "[30] loss: 0.807\n",
      "[31] loss: 0.800\n",
      "[32] loss: 0.474\n",
      "[33] loss: 0.789\n",
      "[34] loss: 0.488\n",
      "[35] loss: 0.493\n",
      "[36] loss: 0.493\n",
      "[37] loss: 0.782\n",
      "[38] loss: 0.782\n",
      "[39] loss: 0.492\n",
      "[40] loss: 0.490\n",
      "[41] loss: 0.485\n",
      "[42] loss: 0.478\n",
      "[43] loss: 0.797\n",
      "[44] loss: 0.801\n",
      "[45] loss: 0.804\n",
      "[46] loss: 0.458\n",
      "[47] loss: 0.454\n",
      "[48] loss: 0.812\n",
      "[49] loss: 0.815\n",
      "[50] loss: 0.816\n",
      "[51] loss: 0.815\n",
      "[52] loss: 0.448\n",
      "[53] loss: 0.448\n",
      "[54] loss: 0.814\n",
      "[55] loss: 0.445\n",
      "[56] loss: 1.029\n",
      "[57] loss: 0.444\n",
      "[58] loss: 0.815\n",
      "[59] loss: 0.814\n",
      "[60] loss: 1.017\n",
      "[61] loss: 1.003\n",
      "[62] loss: 0.796\n",
      "[63] loss: 0.483\n",
      "[64] loss: 0.781\n",
      "[65] loss: 0.502\n",
      "[66] loss: 0.771\n",
      "[67] loss: 0.516\n",
      "[68] loss: 0.903\n",
      "[69] loss: 0.528\n",
      "[70] loss: 0.532\n",
      "[71] loss: 0.532\n",
      "[72] loss: 0.529\n",
      "[73] loss: 0.763\n",
      "[74] loss: 0.518\n",
      "[75] loss: 0.769\n",
      "[76] loss: 0.922\n",
      "[77] loss: 0.771\n",
      "[78] loss: 0.769\n",
      "[79] loss: 0.516\n",
      "[80] loss: 0.766\n",
      "[81] loss: 0.903\n",
      "[82] loss: 0.760\n",
      "[83] loss: 0.537\n",
      "[84] loss: 0.752\n",
      "[85] loss: 0.749\n",
      "[86] loss: 0.746\n",
      "[87] loss: 0.741\n",
      "[88] loss: 0.573\n",
      "[89] loss: 0.577\n",
      "[90] loss: 0.735\n",
      "[91] loss: 0.580\n",
      "[92] loss: 0.578\n",
      "[93] loss: 0.737\n",
      "[94] loss: 0.836\n",
      "[95] loss: 0.570\n",
      "[96] loss: 0.568\n",
      "[97] loss: 0.563\n",
      "[98] loss: 0.746\n",
      "[99] loss: 0.864\n",
      "[100] loss: 0.864\n",
      "[101] loss: 0.858\n",
      "[102] loss: 0.561\n",
      "[103] loss: 0.839\n",
      "[104] loss: 0.575\n",
      "[105] loss: 0.734\n",
      "[106] loss: 0.731\n",
      "[107] loss: 0.593\n",
      "[108] loss: 0.727\n",
      "[109] loss: 0.797\n",
      "[110] loss: 0.722\n",
      "[111] loss: 0.718\n",
      "[112] loss: 0.628\n",
      "[113] loss: 0.712\n",
      "[114] loss: 0.639\n",
      "[115] loss: 0.640\n",
      "[116] loss: 0.711\n",
      "[117] loss: 0.712\n",
      "[118] loss: 0.712\n",
      "[119] loss: 0.711\n",
      "[120] loss: 0.710\n",
      "[121] loss: 0.745\n",
      "[122] loss: 0.653\n",
      "[123] loss: 0.704\n",
      "[124] loss: 0.726\n",
      "[125] loss: 0.700\n",
      "[126] loss: 0.681\n",
      "[127] loss: 0.695\n",
      "[128] loss: 0.690\n",
      "[129] loss: 0.694\n",
      "[130] loss: 0.695\n",
      "[131] loss: 0.697\n",
      "[132] loss: 0.697\n",
      "[133] loss: 0.693\n",
      "[134] loss: 0.690\n",
      "[135] loss: 0.704\n",
      "[136] loss: 0.697\n",
      "[137] loss: 0.697\n",
      "[138] loss: 0.681\n",
      "[139] loss: 0.709\n",
      "[140] loss: 0.679\n",
      "[141] loss: 0.698\n",
      "[142] loss: 0.699\n",
      "[143] loss: 0.674\n",
      "[144] loss: 0.718\n",
      "[145] loss: 0.670\n",
      "[146] loss: 0.666\n",
      "[147] loss: 0.657\n",
      "[148] loss: 0.645\n",
      "[149] loss: 0.761\n",
      "[150] loss: 0.620\n",
      "[151] loss: 0.722\n",
      "[152] loss: 0.725\n",
      "[153] loss: 0.728\n",
      "[154] loss: 0.589\n",
      "[155] loss: 0.733\n",
      "[156] loss: 0.735\n",
      "[157] loss: 0.736\n",
      "[158] loss: 0.573\n",
      "[159] loss: 0.836\n",
      "[160] loss: 0.738\n",
      "[161] loss: 0.737\n",
      "[162] loss: 0.577\n",
      "[163] loss: 0.735\n",
      "[164] loss: 0.578\n",
      "[165] loss: 0.735\n",
      "[166] loss: 0.826\n",
      "[167] loss: 0.580\n",
      "[168] loss: 0.820\n",
      "[169] loss: 0.586\n",
      "[170] loss: 0.730\n",
      "[171] loss: 0.729\n",
      "[172] loss: 0.594\n",
      "[173] loss: 0.728\n",
      "[174] loss: 0.594\n",
      "[175] loss: 0.728\n",
      "[176] loss: 0.591\n",
      "[177] loss: 0.731\n",
      "[178] loss: 0.732\n",
      "[179] loss: 0.732\n",
      "[180] loss: 0.584\n",
      "[181] loss: 0.733\n",
      "[182] loss: 0.580\n",
      "[183] loss: 0.736\n",
      "[184] loss: 0.737\n",
      "[185] loss: 0.573\n",
      "[186] loss: 0.739\n",
      "[187] loss: 0.566\n",
      "[188] loss: 0.742\n",
      "[189] loss: 0.850\n",
      "[190] loss: 0.743\n",
      "[191] loss: 0.564\n",
      "[192] loss: 0.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193] loss: 0.743\n",
      "[194] loss: 0.850\n",
      "[195] loss: 0.561\n",
      "[196] loss: 0.560\n",
      "[197] loss: 0.556\n",
      "[198] loss: 0.548\n",
      "[199] loss: 0.537\n",
      "[200] loss: 0.761\n",
      "[201] loss: 0.515\n",
      "[202] loss: 0.774\n",
      "[203] loss: 0.495\n",
      "[204] loss: 0.786\n",
      "[205] loss: 0.791\n",
      "[206] loss: 0.977\n",
      "[207] loss: 0.794\n",
      "[208] loss: 0.476\n",
      "[209] loss: 0.475\n",
      "[210] loss: 0.472\n",
      "[211] loss: 0.799\n",
      "[212] loss: 0.463\n",
      "[213] loss: 0.805\n",
      "[214] loss: 0.454\n",
      "[215] loss: 0.448\n",
      "[216] loss: 0.440\n",
      "[217] loss: 1.049\n",
      "[218] loss: 0.828\n",
      "[219] loss: 0.829\n",
      "[220] loss: 0.427\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 1.059\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 1.059\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 1.059\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 1.059\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 1.059\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.829\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.426\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.426\n",
      "\n",
      "\n",
      "[1] loss: 0.829\n",
      "[2] loss: 0.427\n",
      "[3] loss: 0.830\n",
      "[4] loss: 0.425\n",
      "[5] loss: 0.423\n",
      "[6] loss: 0.836\n",
      "[7] loss: 0.837\n",
      "[8] loss: 0.417\n",
      "[9] loss: 0.838\n",
      "[10] loss: 0.416\n",
      "[11] loss: 0.414\n",
      "[12] loss: 0.409\n",
      "[13] loss: 0.850\n",
      "[14] loss: 0.400\n",
      "[15] loss: 0.858\n",
      "[16] loss: 0.860\n",
      "[17] loss: 0.860\n",
      "[18] loss: 0.858\n",
      "[19] loss: 0.855\n",
      "[20] loss: 0.403\n",
      "[21] loss: 0.406\n",
      "[22] loss: 0.406\n",
      "[23] loss: 0.404\n",
      "[24] loss: 1.109\n",
      "[25] loss: 0.401\n",
      "[26] loss: 0.853\n",
      "[27] loss: 0.852\n",
      "[28] loss: 0.850\n",
      "[29] loss: 0.408\n",
      "[30] loss: 0.410\n",
      "[31] loss: 0.409\n",
      "[32] loss: 0.847\n",
      "[33] loss: 0.406\n",
      "[34] loss: 1.104\n",
      "[35] loss: 0.405\n",
      "[36] loss: 0.848\n",
      "[37] loss: 0.846\n",
      "[38] loss: 0.410\n",
      "[39] loss: 0.842\n",
      "[40] loss: 0.414\n",
      "[41] loss: 0.839\n",
      "[42] loss: 0.837\n",
      "[43] loss: 0.421\n",
      "[44] loss: 0.423\n",
      "[45] loss: 0.422\n",
      "[46] loss: 0.836\n",
      "[47] loss: 0.837\n",
      "[48] loss: 0.836\n",
      "[49] loss: 0.833\n",
      "[50] loss: 0.427\n",
      "[51] loss: 0.827\n",
      "[52] loss: 0.824\n",
      "[53] loss: 1.036\n",
      "[54] loss: 0.812\n",
      "[55] loss: 0.803\n",
      "[56] loss: 0.472\n",
      "[57] loss: 0.789\n",
      "[58] loss: 0.782\n",
      "[59] loss: 0.775\n",
      "[60] loss: 0.913\n",
      "[61] loss: 0.529\n",
      "[62] loss: 0.540\n",
      "[63] loss: 0.749\n",
      "[64] loss: 0.555\n",
      "[65] loss: 0.744\n",
      "[66] loss: 0.563\n",
      "[67] loss: 0.842\n",
      "[68] loss: 0.738\n",
      "[69] loss: 0.735\n",
      "[70] loss: 0.732\n",
      "[71] loss: 0.728\n",
      "[72] loss: 0.604\n",
      "[73] loss: 0.609\n",
      "[74] loss: 0.609\n",
      "[75] loss: 0.605\n",
      "[76] loss: 0.597\n",
      "[77] loss: 0.731\n",
      "[78] loss: 0.735\n",
      "[79] loss: 0.831\n",
      "[80] loss: 0.737\n",
      "[81] loss: 0.574\n",
      "[82] loss: 0.572\n",
      "[83] loss: 0.566\n",
      "[84] loss: 0.744\n",
      "[85] loss: 0.551\n",
      "[86] loss: 0.752\n",
      "[87] loss: 0.536\n",
      "[88] loss: 0.760\n",
      "[89] loss: 0.520\n",
      "[90] loss: 0.915\n",
      "[91] loss: 0.771\n",
      "[92] loss: 0.771\n",
      "[93] loss: 0.770\n",
      "[94] loss: 0.769\n",
      "[95] loss: 0.517\n",
      "[96] loss: 0.518\n",
      "[97] loss: 0.909\n",
      "[98] loss: 0.765\n",
      "[99] loss: 0.762\n",
      "[100] loss: 0.529\n",
      "[101] loss: 0.531\n",
      "[102] loss: 0.529\n",
      "[103] loss: 0.897\n",
      "[104] loss: 0.897\n",
      "[105] loss: 0.530\n",
      "[106] loss: 0.531\n",
      "[107] loss: 0.529\n",
      "[108] loss: 0.762\n",
      "[109] loss: 0.520\n",
      "[110] loss: 0.514\n",
      "[111] loss: 0.772\n",
      "[112] loss: 0.776\n",
      "[113] loss: 0.778\n",
      "[114] loss: 0.778\n",
      "[115] loss: 0.937\n",
      "[116] loss: 0.928\n",
      "[117] loss: 0.768\n",
      "[118] loss: 0.895\n",
      "[119] loss: 0.753\n",
      "[120] loss: 0.744\n",
      "[121] loss: 0.574\n",
      "[122] loss: 0.585\n",
      "[123] loss: 0.806\n",
      "[124] loss: 0.724\n",
      "[125] loss: 0.614\n",
      "[126] loss: 0.717\n",
      "[127] loss: 0.628\n",
      "[128] loss: 0.630\n",
      "[129] loss: 0.763\n",
      "[130] loss: 0.713\n",
      "[131] loss: 0.712\n",
      "[132] loss: 0.710\n",
      "[133] loss: 0.707\n",
      "[134] loss: 0.654\n",
      "[135] loss: 0.704\n",
      "[136] loss: 0.703\n",
      "[137] loss: 0.702\n",
      "[138] loss: 0.670\n",
      "[139] loss: 0.700\n",
      "[140] loss: 0.699\n",
      "[141] loss: 0.712\n",
      "[142] loss: 0.683\n",
      "[143] loss: 0.695\n",
      "[144] loss: 0.688\n",
      "[145] loss: 0.686\n",
      "[146] loss: 0.679\n",
      "[147] loss: 0.668\n",
      "[148] loss: 0.705\n",
      "[149] loss: 0.642\n",
      "[150] loss: 0.714\n",
      "[151] loss: 0.718\n",
      "[152] loss: 0.722\n",
      "[153] loss: 0.793\n",
      "[154] loss: 0.602\n",
      "[155] loss: 0.799\n",
      "[156] loss: 0.798\n",
      "[157] loss: 0.723\n",
      "[158] loss: 0.612\n",
      "[159] loss: 0.614\n",
      "[160] loss: 0.720\n",
      "[161] loss: 0.612\n",
      "[162] loss: 0.607\n",
      "[163] loss: 0.599\n",
      "[164] loss: 0.587\n",
      "[165] loss: 0.573\n",
      "[166] loss: 0.744\n",
      "[167] loss: 0.868\n",
      "[168] loss: 0.538\n",
      "[169] loss: 0.759\n",
      "[170] loss: 0.899\n",
      "[171] loss: 0.522\n",
      "[172] loss: 0.765\n",
      "[173] loss: 0.766\n",
      "[174] loss: 0.766\n",
      "[175] loss: 0.764\n",
      "[176] loss: 0.524\n",
      "[177] loss: 0.524\n",
      "[178] loss: 0.521\n",
      "[179] loss: 0.515\n",
      "[180] loss: 0.772\n",
      "[181] loss: 0.500\n",
      "[182] loss: 0.781\n",
      "[183] loss: 0.785\n",
      "[184] loss: 0.959\n",
      "[185] loss: 0.486\n",
      "[186] loss: 0.485\n",
      "[187] loss: 0.788\n",
      "[188] loss: 0.966\n",
      "[189] loss: 0.483\n",
      "[190] loss: 0.787\n",
      "[191] loss: 0.956\n",
      "[192] loss: 0.492\n",
      "[193] loss: 0.495\n",
      "[194] loss: 0.941\n",
      "[195] loss: 0.499\n",
      "[196] loss: 0.500\n",
      "[197] loss: 0.777\n",
      "[198] loss: 0.777\n",
      "[199] loss: 0.776\n",
      "[200] loss: 0.774\n",
      "[201] loss: 0.771\n",
      "[202] loss: 0.767\n",
      "[203] loss: 0.762\n",
      "[204] loss: 0.757\n",
      "[205] loss: 0.870\n",
      "[206] loss: 0.744\n",
      "[207] loss: 0.573\n",
      "[208] loss: 0.732\n",
      "[209] loss: 0.594\n",
      "[210] loss: 0.599\n",
      "[211] loss: 0.725\n",
      "[212] loss: 0.724\n",
      "[213] loss: 0.607\n",
      "[214] loss: 0.787\n",
      "[215] loss: 0.612\n",
      "[216] loss: 0.612\n",
      "[217] loss: 0.722\n",
      "[218] loss: 0.605\n",
      "[219] loss: 0.725\n",
      "[220] loss: 0.802\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.800\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.597\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.726\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.597\n",
      "\n",
      "\n",
      "[1] loss: 0.597\n",
      "[2] loss: 0.803\n",
      "[3] loss: 0.597\n",
      "[4] loss: 0.727\n",
      "[5] loss: 0.595\n",
      "[6] loss: 0.728\n",
      "[7] loss: 0.729\n",
      "[8] loss: 0.729\n",
      "[9] loss: 0.592\n",
      "[10] loss: 0.809\n",
      "[11] loss: 0.728\n",
      "[12] loss: 0.597\n",
      "[13] loss: 0.596\n",
      "[14] loss: 0.592\n",
      "[15] loss: 0.732\n",
      "[16] loss: 0.822\n",
      "[17] loss: 0.579\n",
      "[18] loss: 0.576\n",
      "[19] loss: 0.739\n",
      "[20] loss: 0.564\n",
      "[21] loss: 0.745\n",
      "[22] loss: 0.551\n",
      "[23] loss: 0.752\n",
      "[24] loss: 0.754\n",
      "[25] loss: 0.756\n",
      "[26] loss: 0.533\n",
      "[27] loss: 0.529\n",
      "[28] loss: 0.763\n",
      "[29] loss: 0.765\n",
      "[30] loss: 0.515\n",
      "[31] loss: 0.770\n",
      "[32] loss: 0.771\n",
      "[33] loss: 0.507\n",
      "[34] loss: 0.503\n",
      "[35] loss: 0.778\n",
      "[36] loss: 0.944\n",
      "[37] loss: 0.779\n",
      "[38] loss: 0.777\n",
      "[39] loss: 0.774\n",
      "[40] loss: 0.770\n",
      "[41] loss: 0.517\n",
      "[42] loss: 0.902\n",
      "[43] loss: 0.529\n",
      "[44] loss: 0.533\n",
      "[45] loss: 0.756\n",
      "[46] loss: 0.536\n",
      "[47] loss: 0.534\n",
      "[48] loss: 0.889\n",
      "[49] loss: 0.530\n",
      "[50] loss: 0.527\n",
      "[51] loss: 0.764\n",
      "[52] loss: 0.517\n",
      "[53] loss: 0.511\n",
      "[54] loss: 0.775\n",
      "[55] loss: 0.496\n",
      "[56] loss: 0.487\n",
      "[57] loss: 0.970\n",
      "[58] loss: 0.472\n",
      "[59] loss: 0.799\n",
      "[60] loss: 0.802\n",
      "[61] loss: 0.459\n",
      "[62] loss: 0.455\n",
      "[63] loss: 0.449\n",
      "[64] loss: 0.818\n",
      "[65] loss: 0.435\n",
      "[66] loss: 0.427\n",
      "[67] loss: 0.836\n",
      "[68] loss: 0.412\n",
      "[69] loss: 1.100\n",
      "[70] loss: 0.402\n",
      "[71] loss: 0.398\n",
      "[72] loss: 0.392\n",
      "[73] loss: 0.867\n",
      "[74] loss: 0.380\n",
      "[75] loss: 0.878\n",
      "[76] loss: 0.882\n",
      "[77] loss: 0.883\n",
      "[78] loss: 0.881\n",
      "[79] loss: 0.374\n",
      "[80] loss: 0.877\n",
      "[81] loss: 0.874\n",
      "[82] loss: 0.869\n",
      "[83] loss: 1.132\n",
      "[84] loss: 0.853\n",
      "[85] loss: 0.842\n",
      "[86] loss: 0.424\n",
      "[87] loss: 0.823\n",
      "[88] loss: 0.814\n",
      "[89] loss: 0.456\n",
      "[90] loss: 0.800\n",
      "[91] loss: 0.793\n",
      "[92] loss: 0.484\n",
      "[93] loss: 0.781\n",
      "[94] loss: 0.499\n",
      "[95] loss: 0.774\n",
      "[96] loss: 0.770\n",
      "[97] loss: 0.766\n",
      "[98] loss: 0.896\n",
      "[99] loss: 0.754\n",
      "[100] loss: 0.747\n",
      "[101] loss: 0.840\n",
      "[102] loss: 0.732\n",
      "[103] loss: 0.724\n",
      "[104] loss: 0.620\n",
      "[105] loss: 0.712\n",
      "[106] loss: 0.707\n",
      "[107] loss: 0.727\n",
      "[108] loss: 0.698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109] loss: 0.695\n",
      "[110] loss: 0.706\n",
      "[111] loss: 0.688\n",
      "[112] loss: 0.687\n",
      "[113] loss: 0.723\n",
      "[114] loss: 0.723\n",
      "[115] loss: 0.718\n",
      "[116] loss: 0.678\n",
      "[117] loss: 0.690\n",
      "[118] loss: 0.703\n",
      "[119] loss: 0.692\n",
      "[120] loss: 0.694\n",
      "[121] loss: 0.694\n",
      "[122] loss: 0.699\n",
      "[123] loss: 0.691\n",
      "[124] loss: 0.690\n",
      "[125] loss: 0.696\n",
      "[126] loss: 0.697\n",
      "[127] loss: 0.698\n",
      "[128] loss: 0.698\n",
      "[129] loss: 0.709\n",
      "[130] loss: 0.703\n",
      "[131] loss: 0.694\n",
      "[132] loss: 0.698\n",
      "[133] loss: 0.697\n",
      "[134] loss: 0.696\n",
      "[135] loss: 0.694\n",
      "[136] loss: 0.691\n",
      "[137] loss: 0.695\n",
      "[138] loss: 0.702\n",
      "[139] loss: 0.688\n",
      "[140] loss: 0.686\n",
      "[141] loss: 0.708\n",
      "[142] loss: 0.698\n",
      "[143] loss: 0.709\n",
      "[144] loss: 0.683\n",
      "[145] loss: 0.683\n",
      "[146] loss: 0.678\n",
      "[147] loss: 0.669\n",
      "[148] loss: 0.655\n",
      "[149] loss: 0.639\n",
      "[150] loss: 0.620\n",
      "[151] loss: 0.600\n",
      "[152] loss: 0.824\n",
      "[153] loss: 0.563\n",
      "[154] loss: 0.865\n",
      "[155] loss: 0.755\n",
      "[156] loss: 0.530\n",
      "[157] loss: 0.902\n",
      "[158] loss: 0.517\n",
      "[159] loss: 0.770\n",
      "[160] loss: 0.506\n",
      "[161] loss: 0.776\n",
      "[162] loss: 0.496\n",
      "[163] loss: 0.489\n",
      "[164] loss: 0.480\n",
      "[165] loss: 0.469\n",
      "[166] loss: 0.805\n",
      "[167] loss: 0.812\n",
      "[168] loss: 0.442\n",
      "[169] loss: 0.434\n",
      "[170] loss: 0.830\n",
      "[171] loss: 0.836\n",
      "[172] loss: 0.839\n",
      "[173] loss: 0.840\n",
      "[174] loss: 0.839\n",
      "[175] loss: 0.836\n",
      "[176] loss: 0.832\n",
      "[177] loss: 0.429\n",
      "[178] loss: 1.047\n",
      "[179] loss: 0.440\n",
      "[180] loss: 0.815\n",
      "[181] loss: 0.810\n",
      "[182] loss: 0.458\n",
      "[183] loss: 0.801\n",
      "[184] loss: 0.985\n",
      "[185] loss: 0.968\n",
      "[186] loss: 0.492\n",
      "[187] loss: 0.775\n",
      "[188] loss: 0.512\n",
      "[189] loss: 0.765\n",
      "[190] loss: 0.760\n",
      "[191] loss: 0.536\n",
      "[192] loss: 0.541\n",
      "[193] loss: 0.752\n",
      "[194] loss: 0.751\n",
      "[195] loss: 0.749\n",
      "[196] loss: 0.554\n",
      "[197] loss: 0.745\n",
      "[198] loss: 0.559\n",
      "[199] loss: 0.558\n",
      "[200] loss: 0.746\n",
      "[201] loss: 0.551\n",
      "[202] loss: 0.750\n",
      "[203] loss: 0.543\n",
      "[204] loss: 0.755\n",
      "[205] loss: 0.757\n",
      "[206] loss: 0.758\n",
      "[207] loss: 0.758\n",
      "[208] loss: 0.534\n",
      "[209] loss: 0.885\n",
      "[210] loss: 0.755\n",
      "[211] loss: 0.752\n",
      "[212] loss: 0.863\n",
      "[213] loss: 0.848\n",
      "[214] loss: 0.736\n",
      "[215] loss: 0.729\n",
      "[216] loss: 0.723\n",
      "[217] loss: 0.622\n",
      "[218] loss: 0.632\n",
      "[219] loss: 0.638\n",
      "[220] loss: 0.638\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.756\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.756\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.756\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.634\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.712\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.756\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.756\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.634\n",
      "\n",
      "\n",
      "[1] loss: 0.634\n",
      "[2] loss: 0.715\n",
      "[3] loss: 0.717\n",
      "[4] loss: 0.718\n",
      "[5] loss: 0.615\n",
      "[6] loss: 0.609\n",
      "[7] loss: 0.725\n",
      "[8] loss: 0.804\n",
      "[9] loss: 0.728\n",
      "[10] loss: 0.803\n",
      "[11] loss: 0.600\n",
      "[12] loss: 0.725\n",
      "[13] loss: 0.723\n",
      "[14] loss: 0.608\n",
      "[15] loss: 0.608\n",
      "[16] loss: 0.724\n",
      "[17] loss: 0.601\n",
      "[18] loss: 0.727\n",
      "[19] loss: 0.729\n",
      "[20] loss: 0.730\n",
      "[21] loss: 0.729\n",
      "[22] loss: 0.591\n",
      "[23] loss: 0.730\n",
      "[24] loss: 0.730\n",
      "[25] loss: 0.590\n",
      "[26] loss: 0.812\n",
      "[27] loss: 0.590\n",
      "[28] loss: 0.730\n",
      "[29] loss: 0.730\n",
      "[30] loss: 0.808\n",
      "[31] loss: 0.726\n",
      "[32] loss: 0.604\n",
      "[33] loss: 0.787\n",
      "[34] loss: 0.719\n",
      "[35] loss: 0.716\n",
      "[36] loss: 0.633\n",
      "[37] loss: 0.711\n",
      "[38] loss: 0.746\n",
      "[39] loss: 0.705\n",
      "[40] loss: 0.663\n",
      "[41] loss: 0.668\n",
      "[42] loss: 0.667\n",
      "[43] loss: 0.662\n",
      "[44] loss: 0.653\n",
      "[45] loss: 0.710\n",
      "[46] loss: 0.630\n",
      "[47] loss: 0.617\n",
      "[48] loss: 0.724\n",
      "[49] loss: 0.589\n",
      "[50] loss: 0.736\n",
      "[51] loss: 0.742\n",
      "[52] loss: 0.746\n",
      "[53] loss: 0.549\n",
      "[54] loss: 0.753\n",
      "[55] loss: 0.756\n",
      "[56] loss: 0.531\n",
      "[57] loss: 0.761\n",
      "[58] loss: 0.764\n",
      "[59] loss: 0.519\n",
      "[60] loss: 0.767\n",
      "[61] loss: 0.914\n",
      "[62] loss: 0.767\n",
      "[63] loss: 0.520\n",
      "[64] loss: 0.764\n",
      "[65] loss: 0.523\n",
      "[66] loss: 0.763\n",
      "[67] loss: 0.762\n",
      "[68] loss: 0.761\n",
      "[69] loss: 0.758\n",
      "[70] loss: 0.755\n",
      "[71] loss: 0.752\n",
      "[72] loss: 0.859\n",
      "[73] loss: 0.564\n",
      "[74] loss: 0.572\n",
      "[75] loss: 0.828\n",
      "[76] loss: 0.583\n",
      "[77] loss: 0.731\n",
      "[78] loss: 0.590\n",
      "[79] loss: 0.729\n",
      "[80] loss: 0.593\n",
      "[81] loss: 0.590\n",
      "[82] loss: 0.732\n",
      "[83] loss: 0.733\n",
      "[84] loss: 0.822\n",
      "[85] loss: 0.582\n",
      "[86] loss: 0.582\n",
      "[87] loss: 0.577\n",
      "[88] loss: 0.738\n",
      "[89] loss: 0.564\n",
      "[90] loss: 0.745\n",
      "[91] loss: 0.550\n",
      "[92] loss: 0.541\n",
      "[93] loss: 0.530\n",
      "[94] loss: 0.907\n",
      "[95] loss: 0.510\n",
      "[96] loss: 0.501\n",
      "[97] loss: 0.950\n",
      "[98] loss: 0.484\n",
      "[99] loss: 0.791\n",
      "[100] loss: 0.795\n",
      "[101] loss: 0.797\n",
      "[102] loss: 0.469\n",
      "[103] loss: 0.466\n",
      "[104] loss: 0.803\n",
      "[105] loss: 0.805\n",
      "[106] loss: 0.805\n",
      "[107] loss: 0.458\n",
      "[108] loss: 1.003\n",
      "[109] loss: 0.460\n",
      "[110] loss: 0.802\n",
      "[111] loss: 0.801\n",
      "[112] loss: 0.467\n",
      "[113] loss: 0.468\n",
      "[114] loss: 0.466\n",
      "[115] loss: 0.461\n",
      "[116] loss: 0.807\n",
      "[117] loss: 0.810\n",
      "[118] loss: 0.811\n",
      "[119] loss: 0.811\n",
      "[120] loss: 0.452\n",
      "[121] loss: 0.452\n",
      "[122] loss: 0.811\n",
      "[123] loss: 0.812\n",
      "[124] loss: 0.811\n",
      "[125] loss: 0.808\n",
      "[126] loss: 0.805\n",
      "[127] loss: 0.800\n",
      "[128] loss: 0.472\n",
      "[129] loss: 0.791\n",
      "[130] loss: 0.482\n",
      "[131] loss: 0.786\n",
      "[132] loss: 0.783\n",
      "[133] loss: 0.779\n",
      "[134] loss: 0.502\n",
      "[135] loss: 0.505\n",
      "[136] loss: 0.505\n",
      "[137] loss: 0.775\n",
      "[138] loss: 0.501\n",
      "[139] loss: 0.778\n",
      "[140] loss: 0.779\n",
      "[141] loss: 0.940\n",
      "[142] loss: 0.932\n",
      "[143] loss: 0.917\n",
      "[144] loss: 0.762\n",
      "[145] loss: 0.754\n",
      "[146] loss: 0.746\n",
      "[147] loss: 0.569\n",
      "[148] loss: 0.580\n",
      "[149] loss: 0.586\n",
      "[150] loss: 0.730\n",
      "[151] loss: 0.590\n",
      "[152] loss: 0.730\n",
      "[153] loss: 0.589\n",
      "[154] loss: 0.585\n",
      "[155] loss: 0.578\n",
      "[156] loss: 0.739\n",
      "[157] loss: 0.846\n",
      "[158] loss: 0.559\n",
      "[159] loss: 0.746\n",
      "[160] loss: 0.747\n",
      "[161] loss: 0.550\n",
      "[162] loss: 0.750\n",
      "[163] loss: 0.544\n",
      "[164] loss: 0.539\n",
      "[165] loss: 0.887\n",
      "[166] loss: 0.759\n",
      "[167] loss: 0.759\n",
      "[168] loss: 0.758\n",
      "[169] loss: 0.757\n",
      "[170] loss: 0.538\n",
      "[171] loss: 0.876\n",
      "[172] loss: 0.545\n",
      "[173] loss: 0.546\n",
      "[174] loss: 0.751\n",
      "[175] loss: 0.751\n",
      "[176] loss: 0.750\n",
      "[177] loss: 0.861\n",
      "[178] loss: 0.558\n",
      "[179] loss: 0.742\n",
      "[180] loss: 0.740\n",
      "[181] loss: 0.830\n",
      "[182] loss: 0.732\n",
      "[183] loss: 0.727\n",
      "[184] loss: 0.787\n",
      "[185] loss: 0.624\n",
      "[186] loss: 0.634\n",
      "[187] loss: 0.750\n",
      "[188] loss: 0.739\n",
      "[189] loss: 0.702\n",
      "[190] loss: 0.677\n",
      "[191] loss: 0.695\n",
      "[192] loss: 0.693\n",
      "[193] loss: 0.690\n",
      "[194] loss: 0.688\n",
      "[195] loss: 0.685\n",
      "[196] loss: 0.734\n",
      "[197] loss: 0.650\n",
      "[198] loss: 0.747\n",
      "[199] loss: 0.680\n",
      "[200] loss: 0.679\n",
      "[201] loss: 0.678\n",
      "[202] loss: 0.761\n",
      "[203] loss: 0.677\n",
      "[204] loss: 0.677\n",
      "[205] loss: 0.761\n",
      "[206] loss: 0.756\n",
      "[207] loss: 0.680\n",
      "[208] loss: 0.739\n",
      "[209] loss: 0.727\n",
      "[210] loss: 0.711\n",
      "[211] loss: 0.691\n",
      "[212] loss: 0.700\n",
      "[213] loss: 0.651\n",
      "[214] loss: 0.631\n",
      "[215] loss: 0.608\n",
      "[216] loss: 0.731\n",
      "[217] loss: 0.740\n",
      "[218] loss: 0.551\n",
      "[219] loss: 0.534\n",
      "[220] loss: 0.766\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.930\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.930\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.930\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.502\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.775\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.930\n",
      "\n",
      "\n",
      "[1] loss: 0.502\n",
      "[2] loss: 0.784\n",
      "[3] loss: 0.475\n",
      "[4] loss: 0.462\n",
      "[5] loss: 0.448\n",
      "[6] loss: 1.047\n",
      "[7] loss: 0.831\n",
      "[8] loss: 0.836\n",
      "[9] loss: 1.080\n",
      "[10] loss: 0.837\n",
      "[11] loss: 0.834\n",
      "[12] loss: 1.059\n",
      "[13] loss: 0.822\n",
      "[14] loss: 0.446\n",
      "[15] loss: 1.010\n",
      "[16] loss: 0.464\n",
      "[17] loss: 0.794\n",
      "[18] loss: 0.788\n",
      "[19] loss: 0.782\n",
      "[20] loss: 0.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21] loss: 0.771\n",
      "[22] loss: 0.907\n",
      "[23] loss: 0.759\n",
      "[24] loss: 0.751\n",
      "[25] loss: 0.557\n",
      "[26] loss: 0.566\n",
      "[27] loss: 0.571\n",
      "[28] loss: 0.571\n",
      "[29] loss: 0.739\n",
      "[30] loss: 0.566\n",
      "[31] loss: 0.561\n",
      "[32] loss: 0.746\n",
      "[33] loss: 0.548\n",
      "[34] loss: 0.753\n",
      "[35] loss: 0.534\n",
      "[36] loss: 0.761\n",
      "[37] loss: 0.764\n",
      "[38] loss: 0.766\n",
      "[39] loss: 0.516\n",
      "[40] loss: 0.512\n",
      "[41] loss: 0.505\n",
      "[42] loss: 0.779\n",
      "[43] loss: 0.783\n",
      "[44] loss: 0.486\n",
      "[45] loss: 0.479\n",
      "[46] loss: 0.471\n",
      "[47] loss: 0.997\n",
      "[48] loss: 1.004\n",
      "[49] loss: 0.805\n",
      "[50] loss: 0.459\n",
      "[51] loss: 0.804\n",
      "[52] loss: 0.461\n",
      "[53] loss: 0.459\n",
      "[54] loss: 0.456\n",
      "[55] loss: 0.811\n",
      "[56] loss: 0.446\n",
      "[57] loss: 0.440\n",
      "[58] loss: 0.433\n",
      "[59] loss: 0.831\n",
      "[60] loss: 0.837\n",
      "[61] loss: 0.840\n",
      "[62] loss: 0.413\n",
      "[63] loss: 1.090\n",
      "[64] loss: 1.087\n",
      "[65] loss: 0.417\n",
      "[66] loss: 0.420\n",
      "[67] loss: 0.834\n",
      "[68] loss: 1.064\n",
      "[69] loss: 0.430\n",
      "[70] loss: 0.434\n",
      "[71] loss: 1.043\n",
      "[72] loss: 0.818\n",
      "[73] loss: 0.447\n",
      "[74] loss: 0.450\n",
      "[75] loss: 0.451\n",
      "[76] loss: 0.811\n",
      "[77] loss: 0.449\n",
      "[78] loss: 0.813\n",
      "[79] loss: 0.446\n",
      "[80] loss: 0.815\n",
      "[81] loss: 0.443\n",
      "[82] loss: 0.440\n",
      "[83] loss: 0.822\n",
      "[84] loss: 1.047\n",
      "[85] loss: 0.822\n",
      "[86] loss: 0.438\n",
      "[87] loss: 1.034\n",
      "[88] loss: 0.445\n",
      "[89] loss: 0.812\n",
      "[90] loss: 0.809\n",
      "[91] loss: 0.458\n",
      "[92] loss: 0.803\n",
      "[93] loss: 0.465\n",
      "[94] loss: 0.799\n",
      "[95] loss: 0.469\n",
      "[96] loss: 0.469\n",
      "[97] loss: 0.798\n",
      "[98] loss: 0.799\n",
      "[99] loss: 0.798\n",
      "[100] loss: 0.796\n",
      "[101] loss: 0.792\n",
      "[102] loss: 0.962\n",
      "[103] loss: 0.781\n",
      "[104] loss: 0.773\n",
      "[105] loss: 0.517\n",
      "[106] loss: 0.525\n",
      "[107] loss: 0.529\n",
      "[108] loss: 0.530\n",
      "[109] loss: 0.527\n",
      "[110] loss: 0.521\n",
      "[111] loss: 0.914\n",
      "[112] loss: 0.509\n",
      "[113] loss: 0.774\n",
      "[114] loss: 0.932\n",
      "[115] loss: 0.775\n",
      "[116] loss: 0.506\n",
      "[117] loss: 0.772\n",
      "[118] loss: 0.771\n",
      "[119] loss: 0.511\n",
      "[120] loss: 0.769\n",
      "[121] loss: 0.912\n",
      "[122] loss: 0.764\n",
      "[123] loss: 0.759\n",
      "[124] loss: 0.754\n",
      "[125] loss: 0.749\n",
      "[126] loss: 0.848\n",
      "[127] loss: 0.574\n",
      "[128] loss: 0.732\n",
      "[129] loss: 0.595\n",
      "[130] loss: 0.601\n",
      "[131] loss: 0.793\n",
      "[132] loss: 0.722\n",
      "[133] loss: 0.615\n",
      "[134] loss: 0.618\n",
      "[135] loss: 0.719\n",
      "[136] loss: 0.615\n",
      "[137] loss: 0.611\n",
      "[138] loss: 0.724\n",
      "[139] loss: 0.800\n",
      "[140] loss: 0.597\n",
      "[141] loss: 0.728\n",
      "[142] loss: 0.590\n",
      "[143] loss: 0.815\n",
      "[144] loss: 0.815\n",
      "[145] loss: 0.729\n",
      "[146] loss: 0.727\n",
      "[147] loss: 0.602\n",
      "[148] loss: 0.723\n",
      "[149] loss: 0.721\n",
      "[150] loss: 0.614\n",
      "[151] loss: 0.719\n",
      "[152] loss: 0.616\n",
      "[153] loss: 0.719\n",
      "[154] loss: 0.720\n",
      "[155] loss: 0.614\n",
      "[156] loss: 0.611\n",
      "[157] loss: 0.723\n",
      "[158] loss: 0.725\n",
      "[159] loss: 0.597\n",
      "[160] loss: 0.729\n",
      "[161] loss: 0.587\n",
      "[162] loss: 0.734\n",
      "[163] loss: 0.736\n",
      "[164] loss: 0.737\n",
      "[165] loss: 0.831\n",
      "[166] loss: 0.735\n",
      "[167] loss: 0.733\n",
      "[168] loss: 0.730\n",
      "[169] loss: 0.597\n",
      "[170] loss: 0.725\n",
      "[171] loss: 0.723\n",
      "[172] loss: 0.611\n",
      "[173] loss: 0.612\n",
      "[174] loss: 0.609\n",
      "[175] loss: 0.724\n",
      "[176] loss: 0.726\n",
      "[177] loss: 0.727\n",
      "[178] loss: 0.594\n",
      "[179] loss: 0.590\n",
      "[180] loss: 0.733\n",
      "[181] loss: 0.735\n",
      "[182] loss: 0.736\n",
      "[183] loss: 0.573\n",
      "[184] loss: 0.836\n",
      "[185] loss: 0.739\n",
      "[186] loss: 0.571\n",
      "[187] loss: 0.569\n",
      "[188] loss: 0.564\n",
      "[189] loss: 0.745\n",
      "[190] loss: 0.748\n",
      "[191] loss: 0.864\n",
      "[192] loss: 0.748\n",
      "[193] loss: 0.553\n",
      "[194] loss: 0.747\n",
      "[195] loss: 0.855\n",
      "[196] loss: 0.743\n",
      "[197] loss: 0.837\n",
      "[198] loss: 0.734\n",
      "[199] loss: 0.592\n",
      "[200] loss: 0.725\n",
      "[201] loss: 0.608\n",
      "[202] loss: 0.611\n",
      "[203] loss: 0.721\n",
      "[204] loss: 0.783\n",
      "[205] loss: 0.617\n",
      "[206] loss: 0.617\n",
      "[207] loss: 0.719\n",
      "[208] loss: 0.720\n",
      "[209] loss: 0.720\n",
      "[210] loss: 0.615\n",
      "[211] loss: 0.612\n",
      "[212] loss: 0.723\n",
      "[213] loss: 0.602\n",
      "[214] loss: 0.727\n",
      "[215] loss: 0.730\n",
      "[216] loss: 0.731\n",
      "[217] loss: 0.585\n",
      "[218] loss: 0.733\n",
      "[219] loss: 0.735\n",
      "[220] loss: 0.577\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.830\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.737\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.573\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.573\n",
      "\n",
      "\n",
      "[1] loss: 0.737\n",
      "[2] loss: 0.571\n",
      "[3] loss: 0.565\n",
      "[4] loss: 0.745\n",
      "[5] loss: 0.550\n",
      "[6] loss: 0.752\n",
      "[7] loss: 0.535\n",
      "[8] loss: 0.760\n",
      "[9] loss: 0.764\n",
      "[10] loss: 0.766\n",
      "[11] loss: 0.516\n",
      "[12] loss: 0.769\n",
      "[13] loss: 0.770\n",
      "[14] loss: 0.509\n",
      "[15] loss: 0.772\n",
      "[16] loss: 0.505\n",
      "[17] loss: 0.502\n",
      "[18] loss: 0.495\n",
      "[19] loss: 0.486\n",
      "[20] loss: 0.792\n",
      "[21] loss: 0.468\n",
      "[22] loss: 0.458\n",
      "[23] loss: 0.813\n",
      "[24] loss: 0.819\n",
      "[25] loss: 0.823\n",
      "[26] loss: 0.432\n",
      "[27] loss: 1.057\n",
      "[28] loss: 0.828\n",
      "[29] loss: 0.826\n",
      "[30] loss: 0.823\n",
      "[31] loss: 0.818\n",
      "[32] loss: 0.447\n",
      "[33] loss: 0.810\n",
      "[34] loss: 0.805\n",
      "[35] loss: 0.464\n",
      "[36] loss: 0.468\n",
      "[37] loss: 0.797\n",
      "[38] loss: 0.795\n",
      "[39] loss: 0.475\n",
      "[40] loss: 0.792\n",
      "[41] loss: 0.966\n",
      "[42] loss: 0.785\n",
      "[43] loss: 0.495\n",
      "[44] loss: 0.500\n",
      "[45] loss: 0.775\n",
      "[46] loss: 0.774\n",
      "[47] loss: 0.771\n",
      "[48] loss: 0.515\n",
      "[49] loss: 0.517\n",
      "[50] loss: 0.516\n",
      "[51] loss: 0.512\n",
      "[52] loss: 0.926\n",
      "[53] loss: 0.503\n",
      "[54] loss: 0.499\n",
      "[55] loss: 0.781\n",
      "[56] loss: 0.784\n",
      "[57] loss: 0.785\n",
      "[58] loss: 0.785\n",
      "[59] loss: 0.488\n",
      "[60] loss: 0.487\n",
      "[61] loss: 0.483\n",
      "[62] loss: 0.791\n",
      "[63] loss: 0.472\n",
      "[64] loss: 0.798\n",
      "[65] loss: 0.801\n",
      "[66] loss: 0.461\n",
      "[67] loss: 0.805\n",
      "[68] loss: 0.806\n",
      "[69] loss: 0.805\n",
      "[70] loss: 0.803\n",
      "[71] loss: 0.464\n",
      "[72] loss: 0.799\n",
      "[73] loss: 0.468\n",
      "[74] loss: 0.797\n",
      "[75] loss: 0.796\n",
      "[76] loss: 0.474\n",
      "[77] loss: 0.474\n",
      "[78] loss: 0.794\n",
      "[79] loss: 0.794\n",
      "[80] loss: 0.793\n",
      "[81] loss: 0.791\n",
      "[82] loss: 0.482\n",
      "[83] loss: 0.786\n",
      "[84] loss: 0.488\n",
      "[85] loss: 0.488\n",
      "[86] loss: 0.485\n",
      "[87] loss: 0.789\n",
      "[88] loss: 0.791\n",
      "[89] loss: 0.791\n",
      "[90] loss: 0.968\n",
      "[91] loss: 0.786\n",
      "[92] loss: 0.491\n",
      "[93] loss: 0.779\n",
      "[94] loss: 0.500\n",
      "[95] loss: 0.502\n",
      "[96] loss: 0.776\n",
      "[97] loss: 0.775\n",
      "[98] loss: 0.774\n",
      "[99] loss: 0.771\n",
      "[100] loss: 0.513\n",
      "[101] loss: 0.767\n",
      "[102] loss: 0.518\n",
      "[103] loss: 0.765\n",
      "[104] loss: 0.520\n",
      "[105] loss: 0.905\n",
      "[106] loss: 0.900\n",
      "[107] loss: 0.758\n",
      "[108] loss: 0.876\n",
      "[109] loss: 0.747\n",
      "[110] loss: 0.740\n",
      "[111] loss: 0.733\n",
      "[112] loss: 0.596\n",
      "[113] loss: 0.723\n",
      "[114] loss: 0.718\n",
      "[115] loss: 0.627\n",
      "[116] loss: 0.712\n",
      "[117] loss: 0.710\n",
      "[118] loss: 0.648\n",
      "[119] loss: 0.738\n",
      "[120] loss: 0.658\n",
      "[121] loss: 0.727\n",
      "[122] loss: 0.667\n",
      "[123] loss: 0.668\n",
      "[124] loss: 0.665\n",
      "[125] loss: 0.704\n",
      "[126] loss: 0.651\n",
      "[127] loss: 0.642\n",
      "[128] loss: 0.714\n",
      "[129] loss: 0.619\n",
      "[130] loss: 0.722\n",
      "[131] loss: 0.726\n",
      "[132] loss: 0.809\n",
      "[133] loss: 0.730\n",
      "[134] loss: 0.588\n",
      "[135] loss: 0.731\n",
      "[136] loss: 0.583\n",
      "[137] loss: 0.734\n",
      "[138] loss: 0.736\n",
      "[139] loss: 0.736\n",
      "[140] loss: 0.736\n",
      "[141] loss: 0.824\n",
      "[142] loss: 0.814\n",
      "[143] loss: 0.726\n",
      "[144] loss: 0.721\n",
      "[145] loss: 0.770\n",
      "[146] loss: 0.710\n",
      "[147] loss: 0.656\n",
      "[148] loss: 0.701\n",
      "[149] loss: 0.678\n",
      "[150] loss: 0.684\n",
      "[151] loss: 0.702\n",
      "[152] loss: 0.689\n",
      "[153] loss: 0.694\n",
      "[154] loss: 0.694\n",
      "[155] loss: 0.692\n",
      "[156] loss: 0.689\n",
      "[157] loss: 0.705\n",
      "[158] loss: 0.697\n",
      "[159] loss: 0.680\n",
      "[160] loss: 0.675\n",
      "[161] loss: 0.666\n",
      "[162] loss: 0.653\n",
      "[163] loss: 0.753\n",
      "[164] loss: 0.627\n",
      "[165] loss: 0.719\n",
      "[166] loss: 0.723\n",
      "[167] loss: 0.725\n",
      "[168] loss: 0.803\n",
      "[169] loss: 0.727\n",
      "[170] loss: 0.598\n",
      "[171] loss: 0.596\n",
      "[172] loss: 0.729\n",
      "[173] loss: 0.587\n",
      "[174] loss: 0.580\n",
      "[175] loss: 0.833\n",
      "[176] loss: 0.740\n",
      "[177] loss: 0.741\n",
      "[178] loss: 0.565\n",
      "[179] loss: 0.742\n",
      "[180] loss: 0.743\n",
      "[181] loss: 0.743\n",
      "[182] loss: 0.563\n",
      "[183] loss: 0.561\n",
      "[184] loss: 0.745\n",
      "[185] loss: 0.746\n",
      "[186] loss: 0.857\n",
      "[187] loss: 0.745\n",
      "[188] loss: 0.742\n",
      "[189] loss: 0.739\n",
      "[190] loss: 0.735\n",
      "[191] loss: 0.586\n",
      "[192] loss: 0.729\n",
      "[193] loss: 0.801\n",
      "[194] loss: 0.722\n",
      "[195] loss: 0.718\n",
      "[196] loss: 0.714\n",
      "[197] loss: 0.709\n",
      "[198] loss: 0.653\n",
      "[199] loss: 0.703\n",
      "[200] loss: 0.700\n",
      "[201] loss: 0.698\n",
      "[202] loss: 0.701\n",
      "[203] loss: 0.699\n",
      "[204] loss: 0.690\n",
      "[205] loss: 0.688\n",
      "[206] loss: 0.686\n",
      "[207] loss: 0.684\n",
      "[208] loss: 0.682\n",
      "[209] loss: 0.679\n",
      "[210] loss: 0.760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211] loss: 0.763\n",
      "[212] loss: 0.760\n",
      "[213] loss: 0.752\n",
      "[214] loss: 0.740\n",
      "[215] loss: 0.723\n",
      "[216] loss: 0.691\n",
      "[217] loss: 0.686\n",
      "[218] loss: 0.701\n",
      "[219] loss: 0.706\n",
      "[220] loss: 0.639\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.768\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.768\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.768\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.768\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.768\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.768\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.768\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.716\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.623\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.623\n",
      "\n",
      "\n",
      "[1] loss: 0.716\n",
      "[2] loss: 0.611\n",
      "[3] loss: 0.726\n",
      "[4] loss: 0.814\n",
      "[5] loss: 0.734\n",
      "[6] loss: 0.735\n",
      "[7] loss: 0.735\n",
      "[8] loss: 0.577\n",
      "[9] loss: 0.829\n",
      "[10] loss: 0.735\n",
      "[11] loss: 0.821\n",
      "[12] loss: 0.730\n",
      "[13] loss: 0.726\n",
      "[14] loss: 0.608\n",
      "[15] loss: 0.613\n",
      "[16] loss: 0.613\n",
      "[17] loss: 0.785\n",
      "[18] loss: 0.611\n",
      "[19] loss: 0.722\n",
      "[20] loss: 0.607\n",
      "[21] loss: 0.724\n",
      "[22] loss: 0.796\n",
      "[23] loss: 0.602\n",
      "[24] loss: 0.725\n",
      "[25] loss: 0.725\n",
      "[26] loss: 0.724\n",
      "[27] loss: 0.723\n",
      "[28] loss: 0.610\n",
      "[29] loss: 0.721\n",
      "[30] loss: 0.720\n",
      "[31] loss: 0.719\n",
      "[32] loss: 0.717\n",
      "[33] loss: 0.715\n",
      "[34] loss: 0.632\n",
      "[35] loss: 0.712\n",
      "[36] loss: 0.636\n",
      "[37] loss: 0.712\n",
      "[38] loss: 0.711\n",
      "[39] loss: 0.711\n",
      "[40] loss: 0.710\n",
      "[41] loss: 0.644\n",
      "[42] loss: 0.643\n",
      "[43] loss: 0.710\n",
      "[44] loss: 0.754\n",
      "[45] loss: 0.710\n",
      "[46] loss: 0.642\n",
      "[47] loss: 0.709\n",
      "[48] loss: 0.709\n",
      "[49] loss: 0.709\n",
      "[50] loss: 0.742\n",
      "[51] loss: 0.733\n",
      "[52] loss: 0.667\n",
      "[53] loss: 0.673\n",
      "[54] loss: 0.712\n",
      "[55] loss: 0.680\n",
      "[56] loss: 0.705\n",
      "[57] loss: 0.686\n",
      "[58] loss: 0.686\n",
      "[59] loss: 0.696\n",
      "[60] loss: 0.679\n",
      "[61] loss: 0.671\n",
      "[62] loss: 0.728\n",
      "[63] loss: 0.705\n",
      "[64] loss: 0.706\n",
      "[65] loss: 0.650\n",
      "[66] loss: 0.644\n",
      "[67] loss: 0.712\n",
      "[68] loss: 0.714\n",
      "[69] loss: 0.716\n",
      "[70] loss: 0.772\n",
      "[71] loss: 0.623\n",
      "[72] loss: 0.717\n",
      "[73] loss: 0.717\n",
      "[74] loss: 0.622\n",
      "[75] loss: 0.620\n",
      "[76] loss: 0.781\n",
      "[77] loss: 0.612\n",
      "[78] loss: 0.722\n",
      "[79] loss: 0.724\n",
      "[80] loss: 0.602\n",
      "[81] loss: 0.597\n",
      "[82] loss: 0.589\n",
      "[83] loss: 0.735\n",
      "[84] loss: 0.739\n",
      "[85] loss: 0.741\n",
      "[86] loss: 0.743\n",
      "[87] loss: 0.744\n",
      "[88] loss: 0.743\n",
      "[89] loss: 0.561\n",
      "[90] loss: 0.560\n",
      "[91] loss: 0.854\n",
      "[92] loss: 0.745\n",
      "[93] loss: 0.557\n",
      "[94] loss: 0.853\n",
      "[95] loss: 0.559\n",
      "[96] loss: 0.744\n",
      "[97] loss: 0.560\n",
      "[98] loss: 0.744\n",
      "[99] loss: 0.745\n",
      "[100] loss: 0.558\n",
      "[101] loss: 0.555\n",
      "[102] loss: 0.861\n",
      "[103] loss: 0.549\n",
      "[104] loss: 0.750\n",
      "[105] loss: 0.869\n",
      "[106] loss: 0.749\n",
      "[107] loss: 0.552\n",
      "[108] loss: 0.553\n",
      "[109] loss: 0.748\n",
      "[110] loss: 0.748\n",
      "[111] loss: 0.550\n",
      "[112] loss: 0.749\n",
      "[113] loss: 0.749\n",
      "[114] loss: 0.862\n",
      "[115] loss: 0.555\n",
      "[116] loss: 0.744\n",
      "[117] loss: 0.743\n",
      "[118] loss: 0.566\n",
      "[119] loss: 0.740\n",
      "[120] loss: 0.739\n",
      "[121] loss: 0.830\n",
      "[122] loss: 0.733\n",
      "[123] loss: 0.591\n",
      "[124] loss: 0.727\n",
      "[125] loss: 0.602\n",
      "[126] loss: 0.792\n",
      "[127] loss: 0.721\n",
      "[128] loss: 0.776\n",
      "[129] loss: 0.628\n",
      "[130] loss: 0.712\n",
      "[131] loss: 0.748\n",
      "[132] loss: 0.653\n",
      "[133] loss: 0.729\n",
      "[134] loss: 0.700\n",
      "[135] loss: 0.697\n",
      "[136] loss: 0.694\n",
      "[137] loss: 0.690\n",
      "[138] loss: 0.687\n",
      "[139] loss: 0.727\n",
      "[140] loss: 0.733\n",
      "[141] loss: 0.733\n",
      "[142] loss: 0.684\n",
      "[143] loss: 0.724\n",
      "[144] loss: 0.672\n",
      "[145] loss: 0.712\n",
      "[146] loss: 0.705\n",
      "[147] loss: 0.693\n",
      "[148] loss: 0.684\n",
      "[149] loss: 0.671\n",
      "[150] loss: 0.654\n",
      "[151] loss: 0.711\n",
      "[152] loss: 0.772\n",
      "[153] loss: 0.720\n",
      "[154] loss: 0.723\n",
      "[155] loss: 0.602\n",
      "[156] loss: 0.727\n",
      "[157] loss: 0.590\n",
      "[158] loss: 0.581\n",
      "[159] loss: 0.738\n",
      "[160] loss: 0.742\n",
      "[161] loss: 0.745\n",
      "[162] loss: 0.746\n",
      "[163] loss: 0.747\n",
      "[164] loss: 0.553\n",
      "[165] loss: 0.748\n",
      "[166] loss: 0.549\n",
      "[167] loss: 0.545\n",
      "[168] loss: 0.754\n",
      "[169] loss: 0.533\n",
      "[170] loss: 0.526\n",
      "[171] loss: 0.516\n",
      "[172] loss: 0.774\n",
      "[173] loss: 0.779\n",
      "[174] loss: 0.950\n",
      "[175] loss: 0.488\n",
      "[176] loss: 0.786\n",
      "[177] loss: 0.786\n",
      "[178] loss: 0.484\n",
      "[179] loss: 0.787\n",
      "[180] loss: 0.787\n",
      "[181] loss: 0.484\n",
      "[182] loss: 0.787\n",
      "[183] loss: 0.786\n",
      "[184] loss: 0.487\n",
      "[185] loss: 0.486\n",
      "[186] loss: 0.483\n",
      "[187] loss: 0.477\n",
      "[188] loss: 0.469\n",
      "[189] loss: 0.804\n",
      "[190] loss: 0.452\n",
      "[191] loss: 0.443\n",
      "[192] loss: 0.824\n",
      "[193] loss: 0.830\n",
      "[194] loss: 0.833\n",
      "[195] loss: 0.835\n",
      "[196] loss: 0.835\n",
      "[197] loss: 0.833\n",
      "[198] loss: 0.829\n",
      "[199] loss: 0.432\n",
      "[200] loss: 0.435\n",
      "[201] loss: 0.822\n",
      "[202] loss: 0.437\n",
      "[203] loss: 0.821\n",
      "[204] loss: 0.438\n",
      "[205] loss: 0.437\n",
      "[206] loss: 0.433\n",
      "[207] loss: 0.427\n",
      "[208] loss: 0.420\n",
      "[209] loss: 0.411\n",
      "[210] loss: 0.852\n",
      "[211] loss: 0.858\n",
      "[212] loss: 0.390\n",
      "[213] loss: 0.384\n",
      "[214] loss: 0.377\n",
      "[215] loss: 0.368\n",
      "[216] loss: 0.359\n",
      "[217] loss: 0.349\n",
      "[218] loss: 0.918\n",
      "[219] loss: 0.926\n",
      "[220] loss: 0.932\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 1.281\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 1.281\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 1.281\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 1.281\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 1.281\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.326\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.934\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.326\n",
      "\n",
      "\n",
      "[1] loss: 0.934\n",
      "[2] loss: 0.934\n",
      "[3] loss: 0.328\n",
      "[4] loss: 0.329\n",
      "[5] loss: 0.932\n",
      "[6] loss: 1.273\n",
      "[7] loss: 0.333\n",
      "[8] loss: 0.921\n",
      "[9] loss: 0.341\n",
      "[10] loss: 0.344\n",
      "[11] loss: 0.344\n",
      "[12] loss: 0.913\n",
      "[13] loss: 0.912\n",
      "[14] loss: 0.908\n",
      "[15] loss: 0.903\n",
      "[16] loss: 0.896\n",
      "[17] loss: 0.887\n",
      "[18] loss: 0.877\n",
      "[19] loss: 0.866\n",
      "[20] loss: 0.397\n",
      "[21] loss: 0.847\n",
      "[22] loss: 0.838\n",
      "[23] loss: 0.828\n",
      "[24] loss: 0.818\n",
      "[25] loss: 0.453\n",
      "[26] loss: 0.801\n",
      "[27] loss: 0.975\n",
      "[28] loss: 0.488\n",
      "[29] loss: 0.777\n",
      "[30] loss: 0.770\n",
      "[31] loss: 0.762\n",
      "[32] loss: 0.755\n",
      "[33] loss: 0.748\n",
      "[34] loss: 0.565\n",
      "[35] loss: 0.736\n",
      "[36] loss: 0.585\n",
      "[37] loss: 0.729\n",
      "[38] loss: 0.726\n",
      "[39] loss: 0.606\n",
      "[40] loss: 0.721\n",
      "[41] loss: 0.719\n",
      "[42] loss: 0.620\n",
      "[43] loss: 0.620\n",
      "[44] loss: 0.718\n",
      "[45] loss: 0.615\n",
      "[46] loss: 0.610\n",
      "[47] loss: 0.725\n",
      "[48] loss: 0.727\n",
      "[49] loss: 0.590\n",
      "[50] loss: 0.583\n",
      "[51] loss: 0.572\n",
      "[52] loss: 0.848\n",
      "[53] loss: 0.747\n",
      "[54] loss: 0.548\n",
      "[55] loss: 0.540\n",
      "[56] loss: 0.758\n",
      "[57] loss: 0.762\n",
      "[58] loss: 0.765\n",
      "[59] loss: 0.766\n",
      "[60] loss: 0.517\n",
      "[61] loss: 0.514\n",
      "[62] loss: 0.771\n",
      "[63] loss: 0.773\n",
      "[64] loss: 0.774\n",
      "[65] loss: 0.774\n",
      "[66] loss: 0.506\n",
      "[67] loss: 0.505\n",
      "[68] loss: 0.775\n",
      "[69] loss: 0.500\n",
      "[70] loss: 0.495\n",
      "[71] loss: 0.783\n",
      "[72] loss: 0.786\n",
      "[73] loss: 0.787\n",
      "[74] loss: 0.482\n",
      "[75] loss: 0.965\n",
      "[76] loss: 0.482\n",
      "[77] loss: 0.788\n",
      "[78] loss: 0.787\n",
      "[79] loss: 0.485\n",
      "[80] loss: 0.786\n",
      "[81] loss: 0.487\n",
      "[82] loss: 0.485\n",
      "[83] loss: 0.788\n",
      "[84] loss: 0.479\n",
      "[85] loss: 0.792\n",
      "[86] loss: 0.473\n",
      "[87] loss: 0.797\n",
      "[88] loss: 0.466\n",
      "[89] loss: 0.461\n",
      "[90] loss: 0.454\n",
      "[91] loss: 0.445\n",
      "[92] loss: 0.822\n",
      "[93] loss: 0.828\n",
      "[94] loss: 0.832\n",
      "[95] loss: 0.833\n",
      "[96] loss: 1.067\n",
      "[97] loss: 0.426\n",
      "[98] loss: 0.827\n",
      "[99] loss: 0.432\n",
      "[100] loss: 0.823\n",
      "[101] loss: 0.436\n",
      "[102] loss: 0.436\n",
      "[103] loss: 1.044\n",
      "[104] loss: 1.040\n",
      "[105] loss: 0.816\n",
      "[106] loss: 0.809\n",
      "[107] loss: 0.997\n",
      "[108] loss: 0.474\n",
      "[109] loss: 0.786\n",
      "[110] loss: 0.780\n",
      "[111] loss: 0.772\n",
      "[112] loss: 0.518\n",
      "[113] loss: 0.527\n",
      "[114] loss: 0.758\n",
      "[115] loss: 0.755\n",
      "[116] loss: 0.543\n",
      "[117] loss: 0.866\n",
      "[118] loss: 0.554\n",
      "[119] loss: 0.557\n",
      "[120] loss: 0.745\n",
      "[121] loss: 0.744\n",
      "[122] loss: 0.743\n",
      "[123] loss: 0.564\n",
      "[124] loss: 0.841\n",
      "[125] loss: 0.569\n",
      "[126] loss: 0.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127] loss: 0.740\n",
      "[128] loss: 0.740\n",
      "[129] loss: 0.740\n",
      "[130] loss: 0.738\n",
      "[131] loss: 0.736\n",
      "[132] loss: 0.734\n",
      "[133] loss: 0.586\n",
      "[134] loss: 0.730\n",
      "[135] loss: 0.591\n",
      "[136] loss: 0.729\n",
      "[137] loss: 0.728\n",
      "[138] loss: 0.803\n",
      "[139] loss: 0.602\n",
      "[140] loss: 0.790\n",
      "[141] loss: 0.612\n",
      "[142] loss: 0.614\n",
      "[143] loss: 0.720\n",
      "[144] loss: 0.720\n",
      "[145] loss: 0.614\n",
      "[146] loss: 0.720\n",
      "[147] loss: 0.784\n",
      "[148] loss: 0.719\n",
      "[149] loss: 0.620\n",
      "[150] loss: 0.717\n",
      "[151] loss: 0.716\n",
      "[152] loss: 0.715\n",
      "[153] loss: 0.631\n",
      "[154] loss: 0.760\n",
      "[155] loss: 0.711\n",
      "[156] loss: 0.642\n",
      "[157] loss: 0.709\n",
      "[158] loss: 0.708\n",
      "[159] loss: 0.739\n",
      "[160] loss: 0.704\n",
      "[161] loss: 0.667\n",
      "[162] loss: 0.700\n",
      "[163] loss: 0.698\n",
      "[164] loss: 0.697\n",
      "[165] loss: 0.687\n",
      "[166] loss: 0.695\n",
      "[167] loss: 0.691\n",
      "[168] loss: 0.695\n",
      "[169] loss: 0.695\n",
      "[170] loss: 0.695\n",
      "[171] loss: 0.688\n",
      "[172] loss: 0.695\n",
      "[173] loss: 0.696\n",
      "[174] loss: 0.696\n",
      "[175] loss: 0.684\n",
      "[176] loss: 0.697\n",
      "[177] loss: 0.697\n",
      "[178] loss: 0.679\n",
      "[179] loss: 0.673\n",
      "[180] loss: 0.664\n",
      "[181] loss: 0.706\n",
      "[182] loss: 0.641\n",
      "[183] loss: 0.714\n",
      "[184] loss: 0.718\n",
      "[185] loss: 0.721\n",
      "[186] loss: 0.790\n",
      "[187] loss: 0.790\n",
      "[188] loss: 0.611\n",
      "[189] loss: 0.611\n",
      "[190] loss: 0.608\n",
      "[191] loss: 0.796\n",
      "[192] loss: 0.725\n",
      "[193] loss: 0.599\n",
      "[194] loss: 0.727\n",
      "[195] loss: 0.593\n",
      "[196] loss: 0.730\n",
      "[197] loss: 0.584\n",
      "[198] loss: 0.578\n",
      "[199] loss: 0.568\n",
      "[200] loss: 0.853\n",
      "[201] loss: 0.748\n",
      "[202] loss: 0.750\n",
      "[203] loss: 0.544\n",
      "[204] loss: 0.539\n",
      "[205] loss: 0.531\n",
      "[206] loss: 0.521\n",
      "[207] loss: 0.508\n",
      "[208] loss: 0.780\n",
      "[209] loss: 0.786\n",
      "[210] loss: 0.476\n",
      "[211] loss: 0.798\n",
      "[212] loss: 0.803\n",
      "[213] loss: 0.805\n",
      "[214] loss: 0.806\n",
      "[215] loss: 0.806\n",
      "[216] loss: 0.804\n",
      "[217] loss: 0.463\n",
      "[218] loss: 0.800\n",
      "[219] loss: 0.797\n",
      "[220] loss: 0.977\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.962\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.962\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.962\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.962\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.962\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.481\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.962\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.788\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.481\n",
      "\n",
      "\n",
      "[1] loss: 0.788\n",
      "[2] loss: 0.781\n",
      "[3] loss: 0.774\n",
      "[4] loss: 0.767\n",
      "[5] loss: 0.529\n",
      "[6] loss: 0.754\n",
      "[7] loss: 0.749\n",
      "[8] loss: 0.558\n",
      "[9] loss: 0.841\n",
      "[10] loss: 0.575\n",
      "[11] loss: 0.580\n",
      "[12] loss: 0.733\n",
      "[13] loss: 0.585\n",
      "[14] loss: 0.583\n",
      "[15] loss: 0.578\n",
      "[16] loss: 0.738\n",
      "[17] loss: 0.841\n",
      "[18] loss: 0.564\n",
      "[19] loss: 0.560\n",
      "[20] loss: 0.553\n",
      "[21] loss: 0.751\n",
      "[22] loss: 0.755\n",
      "[23] loss: 0.757\n",
      "[24] loss: 0.889\n",
      "[25] loss: 0.533\n",
      "[26] loss: 0.886\n",
      "[27] loss: 0.755\n",
      "[28] loss: 0.542\n",
      "[29] loss: 0.751\n",
      "[30] loss: 0.547\n",
      "[31] loss: 0.750\n",
      "[32] loss: 0.749\n",
      "[33] loss: 0.748\n",
      "[34] loss: 0.745\n",
      "[35] loss: 0.742\n",
      "[36] loss: 0.568\n",
      "[37] loss: 0.738\n",
      "[38] loss: 0.827\n",
      "[39] loss: 0.732\n",
      "[40] loss: 0.594\n",
      "[41] loss: 0.798\n",
      "[42] loss: 0.608\n",
      "[43] loss: 0.720\n",
      "[44] loss: 0.718\n",
      "[45] loss: 0.715\n",
      "[46] loss: 0.712\n",
      "[47] loss: 0.709\n",
      "[48] loss: 0.650\n",
      "[49] loss: 0.705\n",
      "[50] loss: 0.659\n",
      "[51] loss: 0.729\n",
      "[52] loss: 0.702\n",
      "[53] loss: 0.670\n",
      "[54] loss: 0.700\n",
      "[55] loss: 0.714\n",
      "[56] loss: 0.679\n",
      "[57] loss: 0.680\n",
      "[58] loss: 0.698\n",
      "[59] loss: 0.698\n",
      "[60] loss: 0.698\n",
      "[61] loss: 0.698\n",
      "[62] loss: 0.678\n",
      "[63] loss: 0.698\n",
      "[64] loss: 0.675\n",
      "[65] loss: 0.700\n",
      "[66] loss: 0.666\n",
      "[67] loss: 0.704\n",
      "[68] loss: 0.736\n",
      "[69] loss: 0.736\n",
      "[70] loss: 0.657\n",
      "[71] loss: 0.657\n",
      "[72] loss: 0.653\n",
      "[73] loss: 0.644\n",
      "[74] loss: 0.713\n",
      "[75] loss: 0.716\n",
      "[76] loss: 0.778\n",
      "[77] loss: 0.779\n",
      "[78] loss: 0.774\n",
      "[79] loss: 0.714\n",
      "[80] loss: 0.711\n",
      "[81] loss: 0.647\n",
      "[82] loss: 0.651\n",
      "[83] loss: 0.651\n",
      "[84] loss: 0.646\n",
      "[85] loss: 0.711\n",
      "[86] loss: 0.713\n",
      "[87] loss: 0.714\n",
      "[88] loss: 0.625\n",
      "[89] loss: 0.718\n",
      "[90] loss: 0.719\n",
      "[91] loss: 0.720\n",
      "[92] loss: 0.613\n",
      "[93] loss: 0.721\n",
      "[94] loss: 0.606\n",
      "[95] loss: 0.600\n",
      "[96] loss: 0.729\n",
      "[97] loss: 0.584\n",
      "[98] loss: 0.736\n",
      "[99] loss: 0.739\n",
      "[100] loss: 0.563\n",
      "[101] loss: 0.555\n",
      "[102] loss: 0.545\n",
      "[103] loss: 0.757\n",
      "[104] loss: 0.763\n",
      "[105] loss: 0.909\n",
      "[106] loss: 0.515\n",
      "[107] loss: 0.916\n",
      "[108] loss: 0.512\n",
      "[109] loss: 0.510\n",
      "[110] loss: 0.504\n",
      "[111] loss: 0.497\n",
      "[112] loss: 0.487\n",
      "[113] loss: 0.792\n",
      "[114] loss: 0.467\n",
      "[115] loss: 0.806\n",
      "[116] loss: 0.811\n",
      "[117] loss: 0.814\n",
      "[118] loss: 0.443\n",
      "[119] loss: 0.819\n",
      "[120] loss: 0.820\n",
      "[121] loss: 0.820\n",
      "[122] loss: 0.440\n",
      "[123] loss: 1.034\n",
      "[124] loss: 0.815\n",
      "[125] loss: 0.450\n",
      "[126] loss: 0.809\n",
      "[127] loss: 0.805\n",
      "[128] loss: 0.993\n",
      "[129] loss: 0.473\n",
      "[130] loss: 0.789\n",
      "[131] loss: 0.487\n",
      "[132] loss: 0.491\n",
      "[133] loss: 0.781\n",
      "[134] loss: 0.779\n",
      "[135] loss: 0.777\n",
      "[136] loss: 0.505\n",
      "[137] loss: 0.507\n",
      "[138] loss: 0.772\n",
      "[139] loss: 0.772\n",
      "[140] loss: 0.770\n",
      "[141] loss: 0.912\n",
      "[142] loss: 0.763\n",
      "[143] loss: 0.532\n",
      "[144] loss: 0.878\n",
      "[145] loss: 0.547\n",
      "[146] loss: 0.746\n",
      "[147] loss: 0.560\n",
      "[148] loss: 0.742\n",
      "[149] loss: 0.839\n",
      "[150] loss: 0.736\n",
      "[151] loss: 0.815\n",
      "[152] loss: 0.598\n",
      "[153] loss: 0.788\n",
      "[154] loss: 0.619\n",
      "[155] loss: 0.715\n",
      "[156] loss: 0.635\n",
      "[157] loss: 0.710\n",
      "[158] loss: 0.642\n",
      "[159] loss: 0.641\n",
      "[160] loss: 0.753\n",
      "[161] loss: 0.637\n",
      "[162] loss: 0.712\n",
      "[163] loss: 0.713\n",
      "[164] loss: 0.631\n",
      "[165] loss: 0.626\n",
      "[166] loss: 0.618\n",
      "[167] loss: 0.606\n",
      "[168] loss: 0.592\n",
      "[169] loss: 0.736\n",
      "[170] loss: 0.844\n",
      "[171] loss: 0.555\n",
      "[172] loss: 0.750\n",
      "[173] loss: 0.539\n",
      "[174] loss: 0.530\n",
      "[175] loss: 0.765\n",
      "[176] loss: 0.770\n",
      "[177] loss: 0.774\n",
      "[178] loss: 0.776\n",
      "[179] loss: 0.500\n",
      "[180] loss: 0.779\n",
      "[181] loss: 0.779\n",
      "[182] loss: 0.495\n",
      "[183] loss: 0.781\n",
      "[184] loss: 0.492\n",
      "[185] loss: 0.783\n",
      "[186] loss: 0.487\n",
      "[187] loss: 0.483\n",
      "[188] loss: 0.477\n",
      "[189] loss: 0.797\n",
      "[190] loss: 0.801\n",
      "[191] loss: 0.803\n",
      "[192] loss: 1.000\n",
      "[193] loss: 0.801\n",
      "[194] loss: 0.797\n",
      "[195] loss: 0.476\n",
      "[196] loss: 0.966\n",
      "[197] loss: 0.784\n",
      "[198] loss: 0.496\n",
      "[199] loss: 0.775\n",
      "[200] loss: 0.771\n",
      "[201] loss: 0.516\n",
      "[202] loss: 0.520\n",
      "[203] loss: 0.901\n",
      "[204] loss: 0.761\n",
      "[205] loss: 0.533\n",
      "[206] loss: 0.756\n",
      "[207] loss: 0.539\n",
      "[208] loss: 0.753\n",
      "[209] loss: 0.542\n",
      "[210] loss: 0.540\n",
      "[211] loss: 0.535\n",
      "[212] loss: 0.760\n",
      "[213] loss: 0.763\n",
      "[214] loss: 0.764\n",
      "[215] loss: 0.519\n",
      "[216] loss: 0.767\n",
      "[217] loss: 0.514\n",
      "[218] loss: 0.770\n",
      "[219] loss: 0.507\n",
      "[220] loss: 0.502\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.941\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.941\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.941\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.941\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.779\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.941\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.941\n",
      "\n",
      "\n",
      "[1] loss: 0.779\n",
      "[2] loss: 0.783\n",
      "[3] loss: 0.953\n",
      "[4] loss: 0.782\n",
      "[5] loss: 0.780\n",
      "[6] loss: 0.776\n",
      "[7] loss: 0.772\n",
      "[8] loss: 0.515\n",
      "[9] loss: 0.764\n",
      "[10] loss: 0.894\n",
      "[11] loss: 0.755\n",
      "[12] loss: 0.749\n",
      "[13] loss: 0.559\n",
      "[14] loss: 0.740\n",
      "[15] loss: 0.575\n",
      "[16] loss: 0.734\n",
      "[17] loss: 0.732\n",
      "[18] loss: 0.591\n",
      "[19] loss: 0.728\n",
      "[20] loss: 0.726\n",
      "[21] loss: 0.724\n",
      "[22] loss: 0.607\n",
      "[23] loss: 0.786\n",
      "[24] loss: 0.719\n",
      "[25] loss: 0.716\n",
      "[26] loss: 0.713\n",
      "[27] loss: 0.710\n",
      "[28] loss: 0.707\n",
      "[29] loss: 0.703\n",
      "[30] loss: 0.700\n",
      "[31] loss: 0.696\n",
      "[32] loss: 0.693\n",
      "[33] loss: 0.691\n",
      "[34] loss: 0.706\n",
      "[35] loss: 0.707\n",
      "[36] loss: 0.691\n",
      "[37] loss: 0.700\n",
      "[38] loss: 0.693\n",
      "[39] loss: 0.699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] loss: 0.687\n",
      "[41] loss: 0.696\n",
      "[42] loss: 0.706\n",
      "[43] loss: 0.683\n",
      "[44] loss: 0.707\n",
      "[45] loss: 0.683\n",
      "[46] loss: 0.680\n",
      "[47] loss: 0.673\n",
      "[48] loss: 0.702\n",
      "[49] loss: 0.705\n",
      "[50] loss: 0.707\n",
      "[51] loss: 0.708\n",
      "[52] loss: 0.709\n",
      "[53] loss: 0.642\n",
      "[54] loss: 0.711\n",
      "[55] loss: 0.712\n",
      "[56] loss: 0.756\n",
      "[57] loss: 0.638\n",
      "[58] loss: 0.752\n",
      "[59] loss: 0.642\n",
      "[60] loss: 0.642\n",
      "[61] loss: 0.637\n",
      "[62] loss: 0.763\n",
      "[63] loss: 0.625\n",
      "[64] loss: 0.718\n",
      "[65] loss: 0.719\n",
      "[66] loss: 0.611\n",
      "[67] loss: 0.605\n",
      "[68] loss: 0.727\n",
      "[69] loss: 0.730\n",
      "[70] loss: 0.584\n",
      "[71] loss: 0.576\n",
      "[72] loss: 0.840\n",
      "[73] loss: 0.846\n",
      "[74] loss: 0.742\n",
      "[75] loss: 0.563\n",
      "[76] loss: 0.845\n",
      "[77] loss: 0.740\n",
      "[78] loss: 0.570\n",
      "[79] loss: 0.738\n",
      "[80] loss: 0.737\n",
      "[81] loss: 0.577\n",
      "[82] loss: 0.577\n",
      "[83] loss: 0.830\n",
      "[84] loss: 0.736\n",
      "[85] loss: 0.577\n",
      "[86] loss: 0.575\n",
      "[87] loss: 0.738\n",
      "[88] loss: 0.739\n",
      "[89] loss: 0.567\n",
      "[90] loss: 0.741\n",
      "[91] loss: 0.561\n",
      "[92] loss: 0.745\n",
      "[93] loss: 0.858\n",
      "[94] loss: 0.554\n",
      "[95] loss: 0.747\n",
      "[96] loss: 0.553\n",
      "[97] loss: 0.748\n",
      "[98] loss: 0.548\n",
      "[99] loss: 0.543\n",
      "[100] loss: 0.755\n",
      "[101] loss: 0.531\n",
      "[102] loss: 0.899\n",
      "[103] loss: 0.764\n",
      "[104] loss: 0.521\n",
      "[105] loss: 0.766\n",
      "[106] loss: 0.516\n",
      "[107] loss: 0.915\n",
      "[108] loss: 0.513\n",
      "[109] loss: 0.511\n",
      "[110] loss: 0.505\n",
      "[111] loss: 0.937\n",
      "[112] loss: 0.495\n",
      "[113] loss: 0.490\n",
      "[114] loss: 0.483\n",
      "[115] loss: 0.793\n",
      "[116] loss: 0.798\n",
      "[117] loss: 0.801\n",
      "[118] loss: 0.461\n",
      "[119] loss: 0.805\n",
      "[120] loss: 0.456\n",
      "[121] loss: 0.809\n",
      "[122] loss: 0.810\n",
      "[123] loss: 0.810\n",
      "[124] loss: 0.453\n",
      "[125] loss: 0.452\n",
      "[126] loss: 0.811\n",
      "[127] loss: 0.811\n",
      "[128] loss: 0.450\n",
      "[129] loss: 0.811\n",
      "[130] loss: 0.449\n",
      "[131] loss: 0.812\n",
      "[132] loss: 0.812\n",
      "[133] loss: 0.811\n",
      "[134] loss: 0.808\n",
      "[135] loss: 0.459\n",
      "[136] loss: 0.802\n",
      "[137] loss: 0.466\n",
      "[138] loss: 0.798\n",
      "[139] loss: 0.796\n",
      "[140] loss: 0.474\n",
      "[141] loss: 0.475\n",
      "[142] loss: 0.793\n",
      "[143] loss: 0.793\n",
      "[144] loss: 0.791\n",
      "[145] loss: 0.964\n",
      "[146] loss: 0.950\n",
      "[147] loss: 0.501\n",
      "[148] loss: 0.510\n",
      "[149] loss: 0.514\n",
      "[150] loss: 0.767\n",
      "[151] loss: 0.517\n",
      "[152] loss: 0.516\n",
      "[153] loss: 0.768\n",
      "[154] loss: 0.769\n",
      "[155] loss: 0.511\n",
      "[156] loss: 0.771\n",
      "[157] loss: 0.507\n",
      "[158] loss: 0.774\n",
      "[159] loss: 0.502\n",
      "[160] loss: 0.497\n",
      "[161] loss: 0.782\n",
      "[162] loss: 0.785\n",
      "[163] loss: 0.786\n",
      "[164] loss: 0.786\n",
      "[165] loss: 0.954\n",
      "[166] loss: 0.493\n",
      "[167] loss: 0.778\n",
      "[168] loss: 0.775\n",
      "[169] loss: 0.507\n",
      "[170] loss: 0.510\n",
      "[171] loss: 0.509\n",
      "[172] loss: 0.504\n",
      "[173] loss: 0.498\n",
      "[174] loss: 0.489\n",
      "[175] loss: 0.790\n",
      "[176] loss: 0.796\n",
      "[177] loss: 0.799\n",
      "[178] loss: 0.994\n",
      "[179] loss: 0.799\n",
      "[180] loss: 0.469\n",
      "[181] loss: 0.796\n",
      "[182] loss: 0.794\n",
      "[183] loss: 0.791\n",
      "[184] loss: 0.786\n",
      "[185] loss: 0.782\n",
      "[186] loss: 0.933\n",
      "[187] loss: 0.768\n",
      "[188] loss: 0.527\n",
      "[189] loss: 0.755\n",
      "[190] loss: 0.750\n",
      "[191] loss: 0.744\n",
      "[192] loss: 0.738\n",
      "[193] loss: 0.582\n",
      "[194] loss: 0.729\n",
      "[195] loss: 0.599\n",
      "[196] loss: 0.724\n",
      "[197] loss: 0.608\n",
      "[198] loss: 0.608\n",
      "[199] loss: 0.723\n",
      "[200] loss: 0.603\n",
      "[201] loss: 0.597\n",
      "[202] loss: 0.589\n",
      "[203] loss: 0.577\n",
      "[204] loss: 0.562\n",
      "[205] loss: 0.750\n",
      "[206] loss: 0.533\n",
      "[207] loss: 0.765\n",
      "[208] loss: 0.771\n",
      "[209] loss: 0.500\n",
      "[210] loss: 0.782\n",
      "[211] loss: 0.959\n",
      "[212] loss: 0.788\n",
      "[213] loss: 0.482\n",
      "[214] loss: 0.480\n",
      "[215] loss: 0.475\n",
      "[216] loss: 0.797\n",
      "[217] loss: 0.992\n",
      "[218] loss: 0.464\n",
      "[219] loss: 0.462\n",
      "[220] loss: 1.003\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 1.002\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 1.002\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 1.002\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 1.002\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 1.002\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 1.002\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.457\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.805\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 1.002\n",
      "\n",
      "\n",
      "[1] loss: 0.805\n",
      "[2] loss: 0.803\n",
      "[3] loss: 0.464\n",
      "[4] loss: 0.465\n",
      "[5] loss: 0.801\n",
      "[6] loss: 0.463\n",
      "[7] loss: 0.802\n",
      "[8] loss: 0.803\n",
      "[9] loss: 0.462\n",
      "[10] loss: 0.802\n",
      "[11] loss: 0.462\n",
      "[12] loss: 0.460\n",
      "[13] loss: 0.456\n",
      "[14] loss: 0.449\n",
      "[15] loss: 0.817\n",
      "[16] loss: 0.435\n",
      "[17] loss: 0.428\n",
      "[18] loss: 0.835\n",
      "[19] loss: 0.841\n",
      "[20] loss: 0.844\n",
      "[21] loss: 1.092\n",
      "[22] loss: 0.412\n",
      "[23] loss: 0.840\n",
      "[24] loss: 0.416\n",
      "[25] loss: 0.417\n",
      "[26] loss: 0.839\n",
      "[27] loss: 0.415\n",
      "[28] loss: 0.841\n",
      "[29] loss: 0.413\n",
      "[30] loss: 0.843\n",
      "[31] loss: 0.842\n",
      "[32] loss: 0.841\n",
      "[33] loss: 0.837\n",
      "[34] loss: 1.065\n",
      "[35] loss: 1.047\n",
      "[36] loss: 1.023\n",
      "[37] loss: 0.463\n",
      "[38] loss: 0.476\n",
      "[39] loss: 0.956\n",
      "[40] loss: 0.777\n",
      "[41] loss: 0.768\n",
      "[42] loss: 0.527\n",
      "[43] loss: 0.537\n",
      "[44] loss: 0.543\n",
      "[45] loss: 0.545\n",
      "[46] loss: 0.752\n",
      "[47] loss: 0.543\n",
      "[48] loss: 0.539\n",
      "[49] loss: 0.533\n",
      "[50] loss: 0.762\n",
      "[51] loss: 0.766\n",
      "[52] loss: 0.768\n",
      "[53] loss: 0.769\n",
      "[54] loss: 0.768\n",
      "[55] loss: 0.767\n",
      "[56] loss: 0.519\n",
      "[57] loss: 0.764\n",
      "[58] loss: 0.763\n",
      "[59] loss: 0.761\n",
      "[60] loss: 0.531\n",
      "[61] loss: 0.757\n",
      "[62] loss: 0.755\n",
      "[63] loss: 0.541\n",
      "[64] loss: 0.872\n",
      "[65] loss: 0.547\n",
      "[66] loss: 0.549\n",
      "[67] loss: 0.750\n",
      "[68] loss: 0.546\n",
      "[69] loss: 0.752\n",
      "[70] loss: 0.752\n",
      "[71] loss: 0.752\n",
      "[72] loss: 0.544\n",
      "[73] loss: 0.543\n",
      "[74] loss: 0.877\n",
      "[75] loss: 0.754\n",
      "[76] loss: 0.873\n",
      "[77] loss: 0.548\n",
      "[78] loss: 0.551\n",
      "[79] loss: 0.861\n",
      "[80] loss: 0.553\n",
      "[81] loss: 0.746\n",
      "[82] loss: 0.555\n",
      "[83] loss: 0.746\n",
      "[84] loss: 0.553\n",
      "[85] loss: 0.861\n",
      "[86] loss: 0.551\n",
      "[87] loss: 0.549\n",
      "[88] loss: 0.543\n",
      "[89] loss: 0.756\n",
      "[90] loss: 0.759\n",
      "[91] loss: 0.760\n",
      "[92] loss: 0.761\n",
      "[93] loss: 0.526\n",
      "[94] loss: 0.762\n",
      "[95] loss: 0.762\n",
      "[96] loss: 0.525\n",
      "[97] loss: 0.762\n",
      "[98] loss: 0.898\n",
      "[99] loss: 0.890\n",
      "[100] loss: 0.754\n",
      "[101] loss: 0.749\n",
      "[102] loss: 0.847\n",
      "[103] loss: 0.736\n",
      "[104] loss: 0.729\n",
      "[105] loss: 0.722\n",
      "[106] loss: 0.715\n",
      "[107] loss: 0.709\n",
      "[108] loss: 0.704\n",
      "[109] loss: 0.698\n",
      "[110] loss: 0.692\n",
      "[111] loss: 0.703\n",
      "[112] loss: 0.689\n",
      "[113] loss: 0.674\n",
      "[114] loss: 0.686\n",
      "[115] loss: 0.733\n",
      "[116] loss: 0.651\n",
      "[117] loss: 0.746\n",
      "[118] loss: 0.680\n",
      "[119] loss: 0.679\n",
      "[120] loss: 0.755\n",
      "[121] loss: 0.679\n",
      "[122] loss: 0.752\n",
      "[123] loss: 0.746\n",
      "[124] loss: 0.735\n",
      "[125] loss: 0.686\n",
      "[126] loss: 0.689\n",
      "[127] loss: 0.698\n",
      "[128] loss: 0.685\n",
      "[129] loss: 0.700\n",
      "[130] loss: 0.655\n",
      "[131] loss: 0.638\n",
      "[132] loss: 0.619\n",
      "[133] loss: 0.798\n",
      "[134] loss: 0.731\n",
      "[135] loss: 0.574\n",
      "[136] loss: 0.845\n",
      "[137] loss: 0.555\n",
      "[138] loss: 0.750\n",
      "[139] loss: 0.754\n",
      "[140] loss: 0.535\n",
      "[141] loss: 0.760\n",
      "[142] loss: 0.762\n",
      "[143] loss: 0.763\n",
      "[144] loss: 0.521\n",
      "[145] loss: 0.518\n",
      "[146] loss: 0.915\n",
      "[147] loss: 0.511\n",
      "[148] loss: 0.771\n",
      "[149] loss: 0.506\n",
      "[150] loss: 0.501\n",
      "[151] loss: 0.780\n",
      "[152] loss: 0.949\n",
      "[153] loss: 0.490\n",
      "[154] loss: 0.783\n",
      "[155] loss: 0.784\n",
      "[156] loss: 0.490\n",
      "[157] loss: 0.783\n",
      "[158] loss: 0.783\n",
      "[159] loss: 0.781\n",
      "[160] loss: 0.778\n",
      "[161] loss: 0.502\n",
      "[162] loss: 0.504\n",
      "[163] loss: 0.503\n",
      "[164] loss: 0.499\n",
      "[165] loss: 0.781\n",
      "[166] loss: 0.488\n",
      "[167] loss: 0.481\n",
      "[168] loss: 0.794\n",
      "[169] loss: 0.798\n",
      "[170] loss: 0.801\n",
      "[171] loss: 0.462\n",
      "[172] loss: 0.458\n",
      "[173] loss: 0.453\n",
      "[174] loss: 0.445\n",
      "[175] loss: 0.822\n",
      "[176] loss: 0.429\n",
      "[177] loss: 0.421\n",
      "[178] loss: 0.842\n",
      "[179] loss: 0.848\n",
      "[180] loss: 0.852\n",
      "[181] loss: 0.853\n",
      "[182] loss: 0.852\n",
      "[183] loss: 0.403\n",
      "[184] loss: 0.404\n",
      "[185] loss: 0.402\n",
      "[186] loss: 1.114\n",
      "[187] loss: 0.399\n",
      "[188] loss: 1.115\n",
      "[189] loss: 1.108\n",
      "[190] loss: 1.094\n",
      "[191] loss: 0.835\n",
      "[192] loss: 0.825\n",
      "[193] loss: 0.814\n",
      "[194] loss: 0.998\n",
      "[195] loss: 0.478\n",
      "[196] loss: 0.781\n",
      "[197] loss: 0.506\n",
      "[198] loss: 0.908\n",
      "[199] loss: 0.531\n",
      "[200] loss: 0.541\n",
      "[201] loss: 0.866\n",
      "[202] loss: 0.556\n",
      "[203] loss: 0.561\n",
      "[204] loss: 0.742\n",
      "[205] loss: 0.565\n",
      "[206] loss: 0.741\n",
      "[207] loss: 0.564\n",
      "[208] loss: 0.561\n",
      "[209] loss: 0.855\n",
      "[210] loss: 0.746\n",
      "[211] loss: 0.554\n",
      "[212] loss: 0.747\n",
      "[213] loss: 0.747\n",
      "[214] loss: 0.552\n",
      "[215] loss: 0.748\n",
      "[216] loss: 0.748\n",
      "[217] loss: 0.747\n",
      "[218] loss: 0.746\n",
      "[219] loss: 0.744\n",
      "[220] loss: 0.841\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.575\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "[4] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.827\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.827\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.827\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.827\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.575\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.827\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.736\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.827\n",
      "\n",
      "\n",
      "[1] loss: 0.736\n",
      "[2] loss: 0.731\n",
      "[3] loss: 0.598\n",
      "[4] loss: 0.605\n",
      "[5] loss: 0.787\n",
      "[6] loss: 0.719\n",
      "[7] loss: 0.770\n",
      "[8] loss: 0.712\n",
      "[9] loss: 0.707\n",
      "[10] loss: 0.703\n",
      "[11] loss: 0.713\n",
      "[12] loss: 0.691\n",
      "[13] loss: 0.702\n",
      "[14] loss: 0.690\n",
      "[15] loss: 0.688\n",
      "[16] loss: 0.718\n",
      "[17] loss: 0.719\n",
      "[18] loss: 0.688\n",
      "[19] loss: 0.711\n",
      "[20] loss: 0.703\n",
      "[21] loss: 0.691\n",
      "[22] loss: 0.698\n",
      "[23] loss: 0.663\n",
      "[24] loss: 0.707\n",
      "[25] loss: 0.711\n",
      "[26] loss: 0.715\n",
      "[27] loss: 0.619\n",
      "[28] loss: 0.785\n",
      "[29] loss: 0.723\n",
      "[30] loss: 0.724\n",
      "[31] loss: 0.602\n",
      "[32] loss: 0.799\n",
      "[33] loss: 0.599\n",
      "[34] loss: 0.596\n",
      "[35] loss: 0.730\n",
      "[36] loss: 0.585\n",
      "[37] loss: 0.577\n",
      "[38] loss: 0.566\n",
      "[39] loss: 0.553\n",
      "[40] loss: 0.754\n",
      "[41] loss: 0.526\n",
      "[42] loss: 0.768\n",
      "[43] loss: 0.774\n",
      "[44] loss: 0.940\n",
      "[45] loss: 0.780\n",
      "[46] loss: 0.780\n",
      "[47] loss: 0.778\n",
      "[48] loss: 0.776\n",
      "[49] loss: 0.506\n",
      "[50] loss: 0.771\n",
      "[51] loss: 0.915\n",
      "[52] loss: 0.520\n",
      "[53] loss: 0.762\n",
      "[54] loss: 0.758\n",
      "[55] loss: 0.879\n",
      "[56] loss: 0.863\n",
      "[57] loss: 0.563\n",
      "[58] loss: 0.573\n",
      "[59] loss: 0.579\n",
      "[60] loss: 0.734\n",
      "[61] loss: 0.583\n",
      "[62] loss: 0.581\n",
      "[63] loss: 0.735\n",
      "[64] loss: 0.573\n",
      "[65] loss: 0.740\n",
      "[66] loss: 0.741\n",
      "[67] loss: 0.561\n",
      "[68] loss: 0.745\n",
      "[69] loss: 0.746\n",
      "[70] loss: 0.552\n",
      "[71] loss: 0.749\n",
      "[72] loss: 0.750\n",
      "[73] loss: 0.546\n",
      "[74] loss: 0.542\n",
      "[75] loss: 0.755\n",
      "[76] loss: 0.532\n",
      "[77] loss: 0.524\n",
      "[78] loss: 0.767\n",
      "[79] loss: 0.508\n",
      "[80] loss: 0.499\n",
      "[81] loss: 0.783\n",
      "[82] loss: 0.789\n",
      "[83] loss: 0.792\n",
      "[84] loss: 0.473\n",
      "[85] loss: 0.467\n",
      "[86] loss: 0.460\n",
      "[87] loss: 0.810\n",
      "[88] loss: 0.814\n",
      "[89] loss: 0.441\n",
      "[90] loss: 0.822\n",
      "[91] loss: 0.432\n",
      "[92] loss: 0.828\n",
      "[93] loss: 0.831\n",
      "[94] loss: 0.424\n",
      "[95] loss: 0.833\n",
      "[96] loss: 0.834\n",
      "[97] loss: 1.065\n",
      "[98] loss: 0.827\n",
      "[99] loss: 0.821\n",
      "[100] loss: 0.445\n",
      "[101] loss: 0.810\n",
      "[102] loss: 0.804\n",
      "[103] loss: 0.466\n",
      "[104] loss: 0.471\n",
      "[105] loss: 0.976\n",
      "[106] loss: 0.790\n",
      "[107] loss: 0.785\n",
      "[108] loss: 0.779\n",
      "[109] loss: 0.925\n",
      "[110] loss: 0.764\n",
      "[111] loss: 0.534\n",
      "[112] loss: 0.751\n",
      "[113] loss: 0.745\n",
      "[114] loss: 0.837\n",
      "[115] loss: 0.583\n",
      "[116] loss: 0.727\n",
      "[117] loss: 0.605\n",
      "[118] loss: 0.611\n",
      "[119] loss: 0.720\n",
      "[120] loss: 0.719\n",
      "[121] loss: 0.620\n",
      "[122] loss: 0.620\n",
      "[123] loss: 0.719\n",
      "[124] loss: 0.613\n",
      "[125] loss: 0.606\n",
      "[126] loss: 0.800\n",
      "[127] loss: 0.593\n",
      "[128] loss: 0.585\n",
      "[129] loss: 0.736\n",
      "[130] loss: 0.837\n",
      "[131] loss: 0.565\n",
      "[132] loss: 0.847\n",
      "[133] loss: 0.560\n",
      "[134] loss: 0.745\n",
      "[135] loss: 0.555\n",
      "[136] loss: 0.860\n",
      "[137] loss: 0.748\n",
      "[138] loss: 0.746\n",
      "[139] loss: 0.745\n",
      "[140] loss: 0.844\n",
      "[141] loss: 0.572\n",
      "[142] loss: 0.735\n",
      "[143] loss: 0.732\n",
      "[144] loss: 0.729\n",
      "[145] loss: 0.725\n",
      "[146] loss: 0.608\n",
      "[147] loss: 0.720\n",
      "[148] loss: 0.774\n",
      "[149] loss: 0.629\n",
      "[150] loss: 0.633\n",
      "[151] loss: 0.633\n",
      "[152] loss: 0.714\n",
      "[153] loss: 0.715\n",
      "[154] loss: 0.626\n",
      "[155] loss: 0.621\n",
      "[156] loss: 0.613\n",
      "[157] loss: 0.601\n",
      "[158] loss: 0.813\n",
      "[159] loss: 0.823\n",
      "[160] loss: 0.735\n",
      "[161] loss: 0.576\n",
      "[162] loss: 0.737\n",
      "[163] loss: 0.738\n",
      "[164] loss: 0.570\n",
      "[165] loss: 0.740\n",
      "[166] loss: 0.740\n",
      "[167] loss: 0.566\n",
      "[168] loss: 0.562\n",
      "[169] loss: 0.555\n",
      "[170] loss: 0.750\n",
      "[171] loss: 0.539\n",
      "[172] loss: 0.530\n",
      "[173] loss: 0.765\n",
      "[174] loss: 0.918\n",
      "[175] loss: 0.772\n",
      "[176] loss: 0.772\n",
      "[177] loss: 0.771\n",
      "[178] loss: 0.511\n",
      "[179] loss: 0.510\n",
      "[180] loss: 0.772\n",
      "[181] loss: 0.506\n",
      "[182] loss: 0.501\n",
      "[183] loss: 0.779\n",
      "[184] loss: 0.490\n",
      "[185] loss: 0.786\n",
      "[186] loss: 0.789\n",
      "[187] loss: 0.790\n",
      "[188] loss: 0.478\n",
      "[189] loss: 0.792\n",
      "[190] loss: 0.792\n",
      "[191] loss: 0.791\n",
      "[192] loss: 0.481\n",
      "[193] loss: 0.788\n",
      "[194] loss: 0.483\n",
      "[195] loss: 0.787\n",
      "[196] loss: 0.483\n",
      "[197] loss: 0.788\n",
      "[198] loss: 0.481\n",
      "[199] loss: 0.790\n",
      "[200] loss: 0.967\n",
      "[201] loss: 0.787\n",
      "[202] loss: 0.783\n",
      "[203] loss: 0.496\n",
      "[204] loss: 0.499\n",
      "[205] loss: 0.499\n",
      "[206] loss: 0.939\n",
      "[207] loss: 0.777\n",
      "[208] loss: 0.775\n",
      "[209] loss: 0.507\n",
      "[210] loss: 0.919\n",
      "[211] loss: 0.767\n",
      "[212] loss: 0.762\n",
      "[213] loss: 0.532\n",
      "[214] loss: 0.879\n",
      "[215] loss: 0.750\n",
      "[216] loss: 0.745\n",
      "[217] loss: 0.739\n",
      "[218] loss: 0.579\n",
      "[219] loss: 0.586\n",
      "[220] loss: 0.730\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.806\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.806\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.806\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.806\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.806\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.806\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.592\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.728\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.806\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.806\n",
      "\n",
      "\n",
      "[1] loss: 0.592\n",
      "[2] loss: 0.728\n",
      "[3] loss: 0.805\n",
      "[4] loss: 0.797\n",
      "[5] loss: 0.609\n",
      "[6] loss: 0.719\n",
      "[7] loss: 0.621\n",
      "[8] loss: 0.716\n",
      "[9] loss: 0.626\n",
      "[10] loss: 0.625\n",
      "[11] loss: 0.619\n",
      "[12] loss: 0.609\n",
      "[13] loss: 0.799\n",
      "[14] loss: 0.591\n",
      "[15] loss: 0.582\n",
      "[16] loss: 0.569\n",
      "[17] loss: 0.555\n",
      "[18] loss: 0.538\n",
      "[19] loss: 0.902\n",
      "[20] loss: 0.770\n",
      "[21] loss: 0.502\n",
      "[22] loss: 0.492\n",
      "[23] loss: 0.480\n",
      "[24] loss: 0.467\n",
      "[25] loss: 0.452\n",
      "[26] loss: 0.821\n",
      "[27] loss: 0.830\n",
      "[28] loss: 0.837\n",
      "[29] loss: 0.412\n",
      "[30] loss: 0.848\n",
      "[31] loss: 1.107\n",
      "[32] loss: 0.402\n",
      "[33] loss: 0.852\n",
      "[34] loss: 0.851\n",
      "[35] loss: 0.849\n",
      "[36] loss: 0.845\n",
      "[37] loss: 0.840\n",
      "[38] loss: 0.833\n",
      "[39] loss: 0.431\n",
      "[40] loss: 0.436\n",
      "[41] loss: 0.439\n",
      "[42] loss: 0.819\n",
      "[43] loss: 0.441\n",
      "[44] loss: 1.033\n",
      "[45] loss: 0.444\n",
      "[46] loss: 0.445\n",
      "[47] loss: 0.816\n",
      "[48] loss: 1.027\n",
      "[49] loss: 0.811\n",
      "[50] loss: 0.806\n",
      "[51] loss: 0.801\n",
      "[52] loss: 0.977\n",
      "[53] loss: 0.486\n",
      "[54] loss: 0.779\n",
      "[55] loss: 0.505\n",
      "[56] loss: 0.769\n",
      "[57] loss: 0.765\n",
      "[58] loss: 0.528\n",
      "[59] loss: 0.757\n",
      "[60] loss: 0.876\n",
      "[61] loss: 0.748\n",
      "[62] loss: 0.743\n",
      "[63] loss: 0.572\n",
      "[64] loss: 0.580\n",
      "[65] loss: 0.732\n",
      "[66] loss: 0.731\n",
      "[67] loss: 0.806\n",
      "[68] loss: 0.602\n",
      "[69] loss: 0.722\n",
      "[70] loss: 0.780\n",
      "[71] loss: 0.624\n",
      "[72] loss: 0.714\n",
      "[73] loss: 0.754\n",
      "[74] loss: 0.646\n",
      "[75] loss: 0.706\n",
      "[76] loss: 0.658\n",
      "[77] loss: 0.703\n",
      "[78] loss: 0.662\n",
      "[79] loss: 0.703\n",
      "[80] loss: 0.704\n",
      "[81] loss: 0.703\n",
      "[82] loss: 0.661\n",
      "[83] loss: 0.659\n",
      "[84] loss: 0.652\n",
      "[85] loss: 0.709\n",
      "[86] loss: 0.712\n",
      "[87] loss: 0.627\n",
      "[88] loss: 0.718\n",
      "[89] loss: 0.720\n",
      "[90] loss: 0.722\n",
      "[91] loss: 0.723\n",
      "[92] loss: 0.723\n",
      "[93] loss: 0.723\n",
      "[94] loss: 0.721\n",
      "[95] loss: 0.613\n",
      "[96] loss: 0.720\n",
      "[97] loss: 0.719\n",
      "[98] loss: 0.617\n",
      "[99] loss: 0.615\n",
      "[100] loss: 0.609\n",
      "[101] loss: 0.600\n",
      "[102] loss: 0.588\n",
      "[103] loss: 0.573\n",
      "[104] loss: 0.745\n",
      "[105] loss: 0.751\n",
      "[106] loss: 0.756\n",
      "[107] loss: 0.527\n",
      "[108] loss: 0.517\n",
      "[109] loss: 0.506\n",
      "[110] loss: 0.781\n",
      "[111] loss: 0.483\n",
      "[112] loss: 0.795\n",
      "[113] loss: 0.463\n",
      "[114] loss: 0.453\n",
      "[115] loss: 0.441\n",
      "[116] loss: 0.827\n",
      "[117] loss: 0.419\n",
      "[118] loss: 0.409\n",
      "[119] loss: 0.855\n",
      "[120] loss: 0.863\n",
      "[121] loss: 0.384\n",
      "[122] loss: 0.874\n",
      "[123] loss: 0.374\n",
      "[124] loss: 0.884\n",
      "[125] loss: 0.366\n",
      "[126] loss: 0.892\n",
      "[127] loss: 0.894\n",
      "[128] loss: 0.893\n",
      "[129] loss: 0.362\n",
      "[130] loss: 0.890\n",
      "[131] loss: 1.185\n",
      "[132] loss: 0.881\n",
      "[133] loss: 0.873\n",
      "[134] loss: 1.134\n",
      "[135] loss: 0.851\n",
      "[136] loss: 0.415\n",
      "[137] loss: 0.829\n",
      "[138] loss: 0.438\n",
      "[139] loss: 0.813\n",
      "[140] loss: 1.005\n",
      "[141] loss: 0.796\n",
      "[142] loss: 0.484\n",
      "[143] loss: 0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31] loss: 0.713\n",
      "[32] loss: 0.713\n",
      "[33] loss: 0.630\n",
      "[34] loss: 0.625\n",
      "[35] loss: 0.718\n",
      "[36] loss: 0.783\n",
      "[37] loss: 0.721\n",
      "[38] loss: 0.720\n",
      "[39] loss: 0.719\n",
      "[40] loss: 0.619\n",
      "[41] loss: 0.718\n",
      "[42] loss: 0.717\n",
      "[43] loss: 0.623\n",
      "[44] loss: 0.621\n",
      "[45] loss: 0.615\n",
      "[46] loss: 0.605\n",
      "[47] loss: 0.805\n",
      "[48] loss: 0.587\n",
      "[49] loss: 0.577\n",
      "[50] loss: 0.565\n",
      "[51] loss: 0.551\n",
      "[52] loss: 0.882\n",
      "[53] loss: 0.525\n",
      "[54] loss: 0.768\n",
      "[55] loss: 0.504\n",
      "[56] loss: 0.943\n",
      "[57] loss: 0.783\n",
      "[58] loss: 0.487\n",
      "[59] loss: 0.482\n",
      "[60] loss: 0.474\n",
      "[61] loss: 0.799\n",
      "[62] loss: 0.458\n",
      "[63] loss: 0.810\n",
      "[64] loss: 0.814\n",
      "[65] loss: 1.030\n",
      "[66] loss: 0.815\n",
      "[67] loss: 0.447\n",
      "[68] loss: 0.812\n",
      "[69] loss: 0.451\n",
      "[70] loss: 0.451\n",
      "[71] loss: 0.812\n",
      "[72] loss: 0.448\n",
      "[73] loss: 0.814\n",
      "[74] loss: 0.444\n",
      "[75] loss: 0.817\n",
      "[76] loss: 0.818\n",
      "[77] loss: 0.817\n",
      "[78] loss: 0.444\n",
      "[79] loss: 0.814\n",
      "[80] loss: 1.021\n",
      "[81] loss: 0.453\n",
      "[82] loss: 0.805\n",
      "[83] loss: 0.801\n",
      "[84] loss: 0.797\n",
      "[85] loss: 0.791\n",
      "[86] loss: 0.785\n",
      "[87] loss: 0.778\n",
      "[88] loss: 0.508\n",
      "[89] loss: 0.515\n",
      "[90] loss: 0.765\n",
      "[91] loss: 0.762\n",
      "[92] loss: 0.530\n",
      "[93] loss: 0.532\n",
      "[94] loss: 0.531\n",
      "[95] loss: 0.894\n",
      "[96] loss: 0.892\n",
      "[97] loss: 0.757\n",
      "[98] loss: 0.753\n",
      "[99] loss: 0.548\n",
      "[100] loss: 0.551\n",
      "[101] loss: 0.858\n",
      "[102] loss: 0.556\n",
      "[103] loss: 0.557\n",
      "[104] loss: 0.746\n",
      "[105] loss: 0.746\n",
      "[106] loss: 0.855\n",
      "[107] loss: 0.847\n",
      "[108] loss: 0.570\n",
      "[109] loss: 0.736\n",
      "[110] loss: 0.818\n",
      "[111] loss: 0.593\n",
      "[112] loss: 0.599\n",
      "[113] loss: 0.601\n",
      "[114] loss: 0.798\n",
      "[115] loss: 0.795\n",
      "[116] loss: 0.722\n",
      "[117] loss: 0.616\n",
      "[118] loss: 0.717\n",
      "[119] loss: 0.623\n",
      "[120] loss: 0.623\n",
      "[121] loss: 0.717\n",
      "[122] loss: 0.776\n",
      "[123] loss: 0.619\n",
      "[124] loss: 0.617\n",
      "[125] loss: 0.612\n",
      "[126] loss: 0.724\n",
      "[127] loss: 0.727\n",
      "[128] loss: 0.806\n",
      "[129] loss: 0.728\n",
      "[130] loss: 0.802\n",
      "[131] loss: 0.603\n",
      "[132] loss: 0.723\n",
      "[133] loss: 0.785\n",
      "[134] loss: 0.618\n",
      "[135] loss: 0.716\n",
      "[136] loss: 0.627\n",
      "[137] loss: 0.714\n",
      "[138] loss: 0.714\n",
      "[139] loss: 0.759\n",
      "[140] loss: 0.710\n",
      "[141] loss: 0.648\n",
      "[142] loss: 0.706\n",
      "[143] loss: 0.656\n",
      "[144] loss: 0.705\n",
      "[145] loss: 0.732\n",
      "[146] loss: 0.662\n",
      "[147] loss: 0.702\n",
      "[148] loss: 0.702\n",
      "[149] loss: 0.668\n",
      "[150] loss: 0.666\n",
      "[151] loss: 0.660\n",
      "[152] loss: 0.706\n",
      "[153] loss: 0.642\n",
      "[154] loss: 0.713\n",
      "[155] loss: 0.622\n",
      "[156] loss: 0.721\n",
      "[157] loss: 0.724\n",
      "[158] loss: 0.727\n",
      "[159] loss: 0.728\n",
      "[160] loss: 0.590\n",
      "[161] loss: 0.731\n",
      "[162] loss: 0.581\n",
      "[163] loss: 0.736\n",
      "[164] loss: 0.738\n",
      "[165] loss: 0.739\n",
      "[166] loss: 0.836\n",
      "[167] loss: 0.737\n",
      "[168] loss: 0.579\n",
      "[169] loss: 0.581\n",
      "[170] loss: 0.579\n",
      "[171] loss: 0.573\n",
      "[172] loss: 0.741\n",
      "[173] loss: 0.744\n",
      "[174] loss: 0.553\n",
      "[175] loss: 0.750\n",
      "[176] loss: 0.542\n",
      "[177] loss: 0.534\n",
      "[178] loss: 0.762\n",
      "[179] loss: 0.766\n",
      "[180] loss: 0.513\n",
      "[181] loss: 0.506\n",
      "[182] loss: 0.496\n",
      "[183] loss: 0.786\n",
      "[184] loss: 0.477\n",
      "[185] loss: 0.466\n",
      "[186] loss: 0.807\n",
      "[187] loss: 1.021\n",
      "[188] loss: 0.444\n",
      "[189] loss: 0.819\n",
      "[190] loss: 0.436\n",
      "[191] loss: 0.825\n",
      "[192] loss: 0.429\n",
      "[193] loss: 0.424\n",
      "[194] loss: 0.836\n",
      "[195] loss: 0.414\n",
      "[196] loss: 0.409\n",
      "[197] loss: 0.851\n",
      "[198] loss: 0.397\n",
      "[199] loss: 0.861\n",
      "[200] loss: 0.388\n",
      "[201] loss: 1.145\n",
      "[202] loss: 0.383\n",
      "[203] loss: 0.381\n",
      "[204] loss: 0.875\n",
      "[205] loss: 0.877\n",
      "[206] loss: 0.876\n",
      "[207] loss: 1.155\n",
      "[208] loss: 1.140\n",
      "[209] loss: 0.856\n",
      "[210] loss: 0.408\n",
      "[211] loss: 1.077\n",
      "[212] loss: 0.827\n",
      "[213] loss: 0.442\n",
      "[214] loss: 0.809\n",
      "[215] loss: 0.463\n",
      "[216] loss: 0.471\n",
      "[217] loss: 0.474\n",
      "[218] loss: 0.475\n",
      "[219] loss: 0.473\n",
      "[220] loss: 0.797\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.989\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.989\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.989\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.989\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.799\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.465\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.989\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.465\n",
      "\n",
      "\n",
      "[1] loss: 0.465\n",
      "[2] loss: 0.460\n",
      "[3] loss: 0.453\n",
      "[4] loss: 0.815\n",
      "[5] loss: 0.438\n",
      "[6] loss: 0.825\n",
      "[7] loss: 0.426\n",
      "[8] loss: 0.419\n",
      "[9] loss: 0.843\n",
      "[10] loss: 0.405\n",
      "[11] loss: 0.854\n",
      "[12] loss: 0.858\n",
      "[13] loss: 0.860\n",
      "[14] loss: 0.859\n",
      "[15] loss: 1.119\n",
      "[16] loss: 0.402\n",
      "[17] loss: 0.847\n",
      "[18] loss: 0.842\n",
      "[19] loss: 0.836\n",
      "[20] loss: 0.828\n",
      "[21] loss: 0.820\n",
      "[22] loss: 0.448\n",
      "[23] loss: 0.455\n",
      "[24] loss: 0.803\n",
      "[25] loss: 0.465\n",
      "[26] loss: 0.468\n",
      "[27] loss: 0.798\n",
      "[28] loss: 0.797\n",
      "[29] loss: 0.472\n",
      "[30] loss: 0.472\n",
      "[31] loss: 0.796\n",
      "[32] loss: 0.797\n",
      "[33] loss: 0.795\n",
      "[34] loss: 0.474\n",
      "[35] loss: 0.474\n",
      "[36] loss: 0.979\n",
      "[37] loss: 0.474\n",
      "[38] loss: 0.473\n",
      "[39] loss: 0.796\n",
      "[40] loss: 0.468\n",
      "[41] loss: 0.800\n",
      "[42] loss: 0.463\n",
      "[43] loss: 0.459\n",
      "[44] loss: 1.011\n",
      "[45] loss: 0.809\n",
      "[46] loss: 0.452\n",
      "[47] loss: 0.451\n",
      "[48] loss: 1.021\n",
      "[49] loss: 0.812\n",
      "[50] loss: 0.810\n",
      "[51] loss: 0.807\n",
      "[52] loss: 0.461\n",
      "[53] loss: 0.800\n",
      "[54] loss: 0.797\n",
      "[55] loss: 0.792\n",
      "[56] loss: 0.482\n",
      "[57] loss: 0.955\n",
      "[58] loss: 0.779\n",
      "[59] loss: 0.773\n",
      "[60] loss: 0.515\n",
      "[61] loss: 0.763\n",
      "[62] loss: 0.759\n",
      "[63] loss: 0.754\n",
      "[64] loss: 0.749\n",
      "[65] loss: 0.849\n",
      "[66] loss: 0.574\n",
      "[67] loss: 0.584\n",
      "[68] loss: 0.810\n",
      "[69] loss: 0.598\n",
      "[70] loss: 0.603\n",
      "[71] loss: 0.724\n",
      "[72] loss: 0.605\n",
      "[73] loss: 0.724\n",
      "[74] loss: 0.794\n",
      "[75] loss: 0.606\n",
      "[76] loss: 0.789\n",
      "[77] loss: 0.783\n",
      "[78] loss: 0.620\n",
      "[79] loss: 0.715\n",
      "[80] loss: 0.713\n",
      "[81] loss: 0.711\n",
      "[82] loss: 0.708\n",
      "[83] loss: 0.652\n",
      "[84] loss: 0.705\n",
      "[85] loss: 0.659\n",
      "[86] loss: 0.704\n",
      "[87] loss: 0.728\n",
      "[88] loss: 0.665\n",
      "[89] loss: 0.665\n",
      "[90] loss: 0.661\n",
      "[91] loss: 0.652\n",
      "[92] loss: 0.640\n",
      "[93] loss: 0.625\n",
      "[94] loss: 0.607\n",
      "[95] loss: 0.730\n",
      "[96] loss: 0.737\n",
      "[97] loss: 0.560\n",
      "[98] loss: 0.867\n",
      "[99] loss: 0.754\n",
      "[100] loss: 0.757\n",
      "[101] loss: 0.889\n",
      "[102] loss: 0.757\n",
      "[103] loss: 0.536\n",
      "[104] loss: 0.536\n",
      "[105] loss: 0.533\n",
      "[106] loss: 0.760\n",
      "[107] loss: 0.762\n",
      "[108] loss: 0.521\n",
      "[109] loss: 0.766\n",
      "[110] loss: 0.767\n",
      "[111] loss: 0.767\n",
      "[112] loss: 0.766\n",
      "[113] loss: 0.764\n",
      "[114] loss: 0.896\n",
      "[115] loss: 0.756\n",
      "[116] loss: 0.868\n",
      "[117] loss: 0.743\n",
      "[118] loss: 0.574\n",
      "[119] loss: 0.816\n",
      "[120] loss: 0.598\n",
      "[121] loss: 0.607\n",
      "[122] loss: 0.783\n",
      "[123] loss: 0.717\n",
      "[124] loss: 0.714\n",
      "[125] loss: 0.710\n",
      "[126] loss: 0.739\n",
      "[127] loss: 0.702\n",
      "[128] loss: 0.679\n",
      "[129] loss: 0.688\n",
      "[130] loss: 0.695\n",
      "[131] loss: 0.692\n",
      "[132] loss: 0.689\n",
      "[133] loss: 0.717\n",
      "[134] loss: 0.686\n",
      "[135] loss: 0.685\n",
      "[136] loss: 0.659\n",
      "[137] loss: 0.682\n",
      "[138] loss: 0.680\n",
      "[139] loss: 0.678\n",
      "[140] loss: 0.676\n",
      "[141] loss: 0.778\n",
      "[142] loss: 0.612\n",
      "[143] loss: 0.789\n",
      "[144] loss: 0.791\n",
      "[145] loss: 0.786\n",
      "[146] loss: 0.674\n",
      "[147] loss: 0.768\n",
      "[148] loss: 0.755\n",
      "[149] loss: 0.738\n",
      "[150] loss: 0.718\n",
      "[151] loss: 0.695\n",
      "[152] loss: 0.669\n",
      "[153] loss: 0.709\n",
      "[154] loss: 0.717\n",
      "[155] loss: 0.603\n",
      "[156] loss: 0.583\n",
      "[157] loss: 0.742\n",
      "[158] loss: 0.545\n",
      "[159] loss: 0.760\n",
      "[160] loss: 0.913\n",
      "[161] loss: 0.505\n",
      "[162] loss: 0.779\n",
      "[163] loss: 0.488\n",
      "[164] loss: 0.789\n",
      "[165] loss: 0.976\n",
      "[166] loss: 0.472\n",
      "[167] loss: 0.797\n",
      "[168] loss: 0.798\n",
      "[169] loss: 0.797\n",
      "[170] loss: 0.471\n",
      "[171] loss: 0.470\n",
      "[172] loss: 0.467\n",
      "[173] loss: 0.802\n",
      "[174] loss: 0.459\n",
      "[175] loss: 0.453\n",
      "[176] loss: 0.813\n",
      "[177] loss: 0.817\n",
      "[178] loss: 0.439\n",
      "[179] loss: 1.042\n",
      "[180] loss: 0.822\n",
      "[181] loss: 0.820\n",
      "[182] loss: 0.816\n",
      "[183] loss: 0.812\n",
      "[184] loss: 0.806\n",
      "[185] loss: 0.464\n",
      "[186] loss: 0.796\n",
      "[187] loss: 0.476\n",
      "[188] loss: 0.789\n",
      "[189] loss: 0.484\n",
      "[190] loss: 0.955\n",
      "[191] loss: 0.492\n",
      "[192] loss: 0.495\n",
      "[193] loss: 0.780\n",
      "[194] loss: 0.495\n",
      "[195] loss: 0.944\n",
      "[196] loss: 0.778\n",
      "[197] loss: 0.775\n",
      "[198] loss: 0.772\n",
      "[199] loss: 0.767\n",
      "[200] loss: 0.523\n",
      "[201] loss: 0.528\n",
      "[202] loss: 0.529\n",
      "[203] loss: 0.526\n",
      "[204] loss: 0.520\n",
      "[205] loss: 0.512\n",
      "[206] loss: 0.775\n",
      "[207] loss: 0.942\n",
      "[208] loss: 0.945\n",
      "[209] loss: 0.779\n",
      "[210] loss: 0.500\n",
      "[211] loss: 0.501\n",
      "[212] loss: 0.777\n",
      "[213] loss: 0.777\n",
      "[214] loss: 0.501\n",
      "[215] loss: 0.934\n",
      "[216] loss: 0.503\n",
      "[217] loss: 0.503\n",
      "[218] loss: 0.776\n",
      "[219] loss: 0.499\n",
      "[220] loss: 0.779\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "[1] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.942\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.942\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.942\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.780\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.494\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.942\n",
      "\n",
      "\n",
      "[1] loss: 0.494\n",
      "[2] loss: 0.949\n",
      "[3] loss: 0.490\n",
      "[4] loss: 0.488\n",
      "[5] loss: 0.483\n",
      "[6] loss: 0.476\n",
      "[7] loss: 0.987\n",
      "[8] loss: 0.801\n",
      "[9] loss: 0.802\n",
      "[10] loss: 0.462\n",
      "[11] loss: 0.460\n",
      "[12] loss: 0.806\n",
      "[13] loss: 1.009\n",
      "[14] loss: 1.004\n",
      "[15] loss: 0.464\n",
      "[16] loss: 0.797\n",
      "[17] loss: 0.473\n",
      "[18] loss: 0.475\n",
      "[19] loss: 0.793\n",
      "[20] loss: 0.792\n",
      "[21] loss: 0.790\n",
      "[22] loss: 0.787\n",
      "[23] loss: 0.783\n",
      "[24] loss: 0.496\n",
      "[25] loss: 0.500\n",
      "[26] loss: 0.500\n",
      "[27] loss: 0.937\n",
      "[28] loss: 0.776\n",
      "[29] loss: 0.774\n",
      "[30] loss: 0.509\n",
      "[31] loss: 0.769\n",
      "[32] loss: 0.515\n",
      "[33] loss: 0.767\n",
      "[34] loss: 0.766\n",
      "[35] loss: 0.764\n",
      "[36] loss: 0.761\n",
      "[37] loss: 0.757\n",
      "[38] loss: 0.875\n",
      "[39] loss: 0.551\n",
      "[40] loss: 0.559\n",
      "[41] loss: 0.742\n",
      "[42] loss: 0.566\n",
      "[43] loss: 0.567\n",
      "[44] loss: 0.563\n",
      "[45] loss: 0.556\n",
      "[46] loss: 0.547\n",
      "[47] loss: 0.756\n",
      "[48] loss: 0.526\n",
      "[49] loss: 0.767\n",
      "[50] loss: 0.923\n",
      "[51] loss: 0.773\n",
      "[52] loss: 0.504\n",
      "[53] loss: 0.501\n",
      "[54] loss: 0.779\n",
      "[55] loss: 0.491\n",
      "[56] loss: 0.957\n",
      "[57] loss: 0.484\n",
      "[58] loss: 0.481\n",
      "[59] loss: 0.793\n",
      "[60] loss: 0.471\n",
      "[61] loss: 0.465\n",
      "[62] loss: 0.805\n",
      "[63] loss: 0.809\n",
      "[64] loss: 0.811\n",
      "[65] loss: 0.811\n",
      "[66] loss: 0.810\n",
      "[67] loss: 0.807\n",
      "[68] loss: 0.459\n",
      "[69] loss: 0.802\n",
      "[70] loss: 0.465\n",
      "[71] loss: 0.465\n",
      "[72] loss: 0.463\n",
      "[73] loss: 1.000\n",
      "[74] loss: 0.804\n",
      "[75] loss: 0.461\n",
      "[76] loss: 0.802\n",
      "[77] loss: 0.994\n",
      "[78] loss: 0.797\n",
      "[79] loss: 0.792\n",
      "[80] loss: 0.957\n",
      "[81] loss: 0.778\n",
      "[82] loss: 0.511\n",
      "[83] loss: 0.520\n",
      "[84] loss: 0.526\n",
      "[85] loss: 0.893\n",
      "[86] loss: 0.533\n",
      "[87] loss: 0.756\n",
      "[88] loss: 0.539\n",
      "[89] loss: 0.539\n",
      "[90] loss: 0.881\n",
      "[91] loss: 0.755\n",
      "[92] loss: 0.540\n",
      "[93] loss: 0.753\n",
      "[94] loss: 0.752\n",
      "[95] loss: 0.751\n",
      "[96] loss: 0.549\n",
      "[97] loss: 0.748\n",
      "[98] loss: 0.552\n",
      "[99] loss: 0.551\n",
      "[100] loss: 0.750\n",
      "[101] loss: 0.751\n",
      "[102] loss: 0.752\n",
      "[103] loss: 0.751\n",
      "[104] loss: 0.547\n",
      "[105] loss: 0.750\n",
      "[106] loss: 0.863\n",
      "[107] loss: 0.746\n",
      "[108] loss: 0.561\n",
      "[109] loss: 0.564\n",
      "[110] loss: 0.563\n",
      "[111] loss: 0.744\n",
      "[112] loss: 0.555\n",
      "[113] loss: 0.748\n",
      "[114] loss: 0.546\n",
      "[115] loss: 0.540\n",
      "[116] loss: 0.758\n",
      "[117] loss: 0.524\n",
      "[118] loss: 0.767\n",
      "[119] loss: 0.770\n",
      "[120] loss: 0.505\n",
      "[121] loss: 0.499\n",
      "[122] loss: 0.490\n",
      "[123] loss: 0.965\n",
      "[124] loss: 0.792\n",
      "[125] loss: 0.794\n",
      "[126] loss: 0.977\n",
      "[127] loss: 0.791\n",
      "[128] loss: 0.483\n",
      "[129] loss: 0.785\n",
      "[130] loss: 0.490\n",
      "[131] loss: 0.782\n",
      "[132] loss: 0.943\n",
      "[133] loss: 0.775\n",
      "[134] loss: 0.770\n",
      "[135] loss: 0.764\n",
      "[136] loss: 0.758\n",
      "[137] loss: 0.542\n",
      "[138] loss: 0.549\n",
      "[139] loss: 0.747\n",
      "[140] loss: 0.745\n",
      "[141] loss: 0.562\n",
      "[142] loss: 0.564\n",
      "[143] loss: 0.742\n",
      "[144] loss: 0.561\n",
      "[145] loss: 0.557\n",
      "[146] loss: 0.550\n",
      "[147] loss: 0.540\n",
      "[148] loss: 0.528\n",
      "[149] loss: 0.514\n",
      "[150] loss: 0.777\n",
      "[151] loss: 0.954\n",
      "[152] loss: 0.481\n",
      "[153] loss: 0.473\n",
      "[154] loss: 0.801\n",
      "[155] loss: 0.806\n",
      "[156] loss: 0.452\n",
      "[157] loss: 0.814\n",
      "[158] loss: 0.817\n",
      "[159] loss: 0.440\n",
      "[160] loss: 1.039\n",
      "[161] loss: 0.438\n",
      "[162] loss: 0.821\n",
      "[163] loss: 0.437\n",
      "[164] loss: 0.436\n",
      "[165] loss: 0.432\n",
      "[166] loss: 0.830\n",
      "[167] loss: 1.066\n",
      "[168] loss: 0.423\n",
      "[169] loss: 0.832\n",
      "[170] loss: 0.423\n",
      "[171] loss: 0.422\n",
      "[172] loss: 0.836\n",
      "[173] loss: 0.837\n",
      "[174] loss: 0.418\n",
      "[175] loss: 0.838\n",
      "[176] loss: 1.076\n",
      "[177] loss: 0.422\n",
      "[178] loss: 1.062\n",
      "[179] loss: 0.825\n",
      "[180] loss: 0.439\n",
      "[181] loss: 0.444\n",
      "[182] loss: 0.446\n",
      "[183] loss: 0.814\n",
      "[184] loss: 1.023\n",
      "[185] loss: 0.809\n",
      "[186] loss: 0.804\n",
      "[187] loss: 0.986\n",
      "[188] loss: 0.965\n",
      "[189] loss: 0.778\n",
      "[190] loss: 0.768\n",
      "[191] loss: 0.531\n",
      "[192] loss: 0.751\n",
      "[193] loss: 0.744\n",
      "[194] loss: 0.738\n",
      "[195] loss: 0.586\n",
      "[196] loss: 0.727\n",
      "[197] loss: 0.722\n",
      "[198] loss: 0.617\n",
      "[199] loss: 0.716\n",
      "[200] loss: 0.713\n",
      "[201] loss: 0.751\n",
      "[202] loss: 0.706\n",
      "[203] loss: 0.663\n",
      "[204] loss: 0.700\n",
      "[205] loss: 0.678\n",
      "[206] loss: 0.697\n",
      "[207] loss: 0.683\n",
      "[208] loss: 0.705\n",
      "[209] loss: 0.696\n",
      "[210] loss: 0.689\n",
      "[211] loss: 0.688\n",
      "[212] loss: 0.696\n",
      "[213] loss: 0.697\n",
      "[214] loss: 0.698\n",
      "[215] loss: 0.698\n",
      "[216] loss: 0.677\n",
      "[217] loss: 0.699\n",
      "[218] loss: 0.716\n",
      "[219] loss: 0.699\n",
      "[220] loss: 0.708\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.699\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.699\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.699\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.699\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.699\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.688\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.699\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.695\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.699\n",
      "\n",
      "\n",
      "[1] loss: 0.688\n",
      "[2] loss: 0.691\n",
      "[3] loss: 0.698\n",
      "[4] loss: 0.692\n",
      "[5] loss: 0.694\n",
      "[6] loss: 0.694\n",
      "[7] loss: 0.694\n",
      "[8] loss: 0.692\n",
      "[9] loss: 0.694\n",
      "[10] loss: 0.688\n",
      "[11] loss: 0.696\n",
      "[12] loss: 0.709\n",
      "[13] loss: 0.697\n",
      "[14] loss: 0.696\n",
      "[15] loss: 0.685\n",
      "[16] loss: 0.703\n",
      "[17] loss: 0.695\n",
      "[18] loss: 0.693\n",
      "[19] loss: 0.698\n",
      "[20] loss: 0.698\n",
      "[21] loss: 0.693\n",
      "[22] loss: 0.696\n",
      "[23] loss: 0.698\n",
      "[24] loss: 0.672\n",
      "[25] loss: 0.725\n",
      "[26] loss: 0.659\n",
      "[27] loss: 0.706\n",
      "[28] loss: 0.707\n",
      "[29] loss: 0.644\n",
      "[30] loss: 0.711\n",
      "[31] loss: 0.713\n",
      "[32] loss: 0.629\n",
      "[33] loss: 0.770\n",
      "[34] loss: 0.717\n",
      "[35] loss: 0.621\n",
      "[36] loss: 0.775\n",
      "[37] loss: 0.619\n",
      "[38] loss: 0.616\n",
      "[39] loss: 0.721\n",
      "[40] loss: 0.605\n",
      "[41] loss: 0.726\n",
      "[42] loss: 0.728\n",
      "[43] loss: 0.730\n",
      "[44] loss: 0.587\n",
      "[45] loss: 0.818\n",
      "[46] loss: 0.732\n",
      "[47] loss: 0.585\n",
      "[48] loss: 0.732\n",
      "[49] loss: 0.583\n",
      "[50] loss: 0.822\n",
      "[51] loss: 0.580\n",
      "[52] loss: 0.734\n",
      "[53] loss: 0.824\n",
      "[54] loss: 0.733\n",
      "[55] loss: 0.730\n",
      "[56] loss: 0.727\n",
      "[57] loss: 0.602\n",
      "[58] loss: 0.723\n",
      "[59] loss: 0.610\n",
      "[60] loss: 0.610\n",
      "[61] loss: 0.723\n",
      "[62] loss: 0.724\n",
      "[63] loss: 0.603\n",
      "[64] loss: 0.725\n",
      "[65] loss: 0.597\n",
      "[66] loss: 0.591\n",
      "[67] loss: 0.581\n",
      "[68] loss: 0.835\n",
      "[69] loss: 0.563\n",
      "[70] loss: 0.746\n",
      "[71] loss: 0.749\n",
      "[72] loss: 0.751\n",
      "[73] loss: 0.543\n",
      "[74] loss: 0.538\n",
      "[75] loss: 0.530\n",
      "[76] loss: 0.764\n",
      "[77] loss: 0.768\n",
      "[78] loss: 0.771\n",
      "[79] loss: 0.506\n",
      "[80] loss: 0.775\n",
      "[81] loss: 0.498\n",
      "[82] loss: 0.780\n",
      "[83] loss: 0.782\n",
      "[84] loss: 0.489\n",
      "[85] loss: 0.785\n",
      "[86] loss: 0.484\n",
      "[87] loss: 0.789\n",
      "[88] loss: 0.790\n",
      "[89] loss: 0.789\n",
      "[90] loss: 0.788\n",
      "[91] loss: 0.785\n",
      "[92] loss: 0.491\n",
      "[93] loss: 0.780\n",
      "[94] loss: 0.778\n",
      "[95] loss: 0.502\n",
      "[96] loss: 0.773\n",
      "[97] loss: 0.508\n",
      "[98] loss: 0.771\n",
      "[99] loss: 0.510\n",
      "[100] loss: 0.508\n",
      "[101] loss: 0.774\n",
      "[102] loss: 0.502\n",
      "[103] loss: 0.778\n",
      "[104] loss: 0.494\n",
      "[105] loss: 0.489\n",
      "[106] loss: 0.963\n",
      "[107] loss: 0.479\n",
      "[108] loss: 0.793\n",
      "[109] loss: 0.472\n",
      "[110] loss: 0.467\n",
      "[111] loss: 0.803\n",
      "[112] loss: 0.806\n",
      "[113] loss: 0.453\n",
      "[114] loss: 1.017\n",
      "[115] loss: 0.810\n",
      "[116] loss: 0.808\n",
      "[117] loss: 0.457\n",
      "[118] loss: 1.001\n",
      "[119] loss: 0.991\n",
      "[120] loss: 0.474\n",
      "[121] loss: 0.480\n",
      "[122] loss: 0.787\n",
      "[123] loss: 0.953\n",
      "[124] loss: 0.778\n",
      "[125] loss: 0.506\n",
      "[126] loss: 0.769\n",
      "[127] loss: 0.764\n",
      "[128] loss: 0.528\n",
      "[129] loss: 0.885\n",
      "[130] loss: 0.872\n",
      "[131] loss: 0.746\n",
      "[132] loss: 0.568\n",
      "[133] loss: 0.577\n",
      "[134] loss: 0.733\n",
      "[135] loss: 0.586\n",
      "[136] loss: 0.730\n",
      "[137] loss: 0.729\n",
      "[138] loss: 0.727\n",
      "[139] loss: 0.599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140] loss: 0.725\n",
      "[141] loss: 0.603\n",
      "[142] loss: 0.601\n",
      "[143] loss: 0.727\n",
      "[144] loss: 0.592\n",
      "[145] loss: 0.732\n",
      "[146] loss: 0.580\n",
      "[147] loss: 0.737\n",
      "[148] loss: 0.566\n",
      "[149] loss: 0.744\n",
      "[150] loss: 0.552\n",
      "[151] loss: 0.751\n",
      "[152] loss: 0.754\n",
      "[153] loss: 0.882\n",
      "[154] loss: 0.755\n",
      "[155] loss: 0.539\n",
      "[156] loss: 0.754\n",
      "[157] loss: 0.540\n",
      "[158] loss: 0.538\n",
      "[159] loss: 0.757\n",
      "[160] loss: 0.758\n",
      "[161] loss: 0.759\n",
      "[162] loss: 0.758\n",
      "[163] loss: 0.757\n",
      "[164] loss: 0.754\n",
      "[165] loss: 0.543\n",
      "[166] loss: 0.545\n",
      "[167] loss: 0.751\n",
      "[168] loss: 0.544\n",
      "[169] loss: 0.753\n",
      "[170] loss: 0.539\n",
      "[171] loss: 0.882\n",
      "[172] loss: 0.756\n",
      "[173] loss: 0.754\n",
      "[174] loss: 0.752\n",
      "[175] loss: 0.548\n",
      "[176] loss: 0.748\n",
      "[177] loss: 0.747\n",
      "[178] loss: 0.744\n",
      "[179] loss: 0.741\n",
      "[180] loss: 0.570\n",
      "[181] loss: 0.737\n",
      "[182] loss: 0.735\n",
      "[183] loss: 0.583\n",
      "[184] loss: 0.584\n",
      "[185] loss: 0.819\n",
      "[186] loss: 0.816\n",
      "[187] loss: 0.729\n",
      "[188] loss: 0.599\n",
      "[189] loss: 0.724\n",
      "[190] loss: 0.607\n",
      "[191] loss: 0.607\n",
      "[192] loss: 0.603\n",
      "[193] loss: 0.727\n",
      "[194] loss: 0.591\n",
      "[195] loss: 0.582\n",
      "[196] loss: 0.738\n",
      "[197] loss: 0.742\n",
      "[198] loss: 0.556\n",
      "[199] loss: 0.749\n",
      "[200] loss: 0.541\n",
      "[201] loss: 0.757\n",
      "[202] loss: 0.760\n",
      "[203] loss: 0.762\n",
      "[204] loss: 0.522\n",
      "[205] loss: 0.765\n",
      "[206] loss: 0.909\n",
      "[207] loss: 0.518\n",
      "[208] loss: 0.765\n",
      "[209] loss: 0.519\n",
      "[210] loss: 0.766\n",
      "[211] loss: 0.766\n",
      "[212] loss: 0.519\n",
      "[213] loss: 0.765\n",
      "[214] loss: 0.518\n",
      "[215] loss: 0.767\n",
      "[216] loss: 0.514\n",
      "[217] loss: 0.769\n",
      "[218] loss: 0.770\n",
      "[219] loss: 0.918\n",
      "[220] loss: 0.910\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.896\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.896\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.896\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.896\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.896\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.896\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.525\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.761\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.896\n",
      "\n",
      "\n",
      "[1] loss: 0.761\n",
      "[2] loss: 0.535\n",
      "[3] loss: 0.752\n",
      "[4] loss: 0.549\n",
      "[5] loss: 0.553\n",
      "[6] loss: 0.552\n",
      "[7] loss: 0.548\n",
      "[8] loss: 0.541\n",
      "[9] loss: 0.887\n",
      "[10] loss: 0.760\n",
      "[11] loss: 0.525\n",
      "[12] loss: 0.764\n",
      "[13] loss: 0.765\n",
      "[14] loss: 0.766\n",
      "[15] loss: 0.765\n",
      "[16] loss: 0.522\n",
      "[17] loss: 0.763\n",
      "[18] loss: 0.762\n",
      "[19] loss: 0.760\n",
      "[20] loss: 0.532\n",
      "[21] loss: 0.884\n",
      "[22] loss: 0.538\n",
      "[23] loss: 0.540\n",
      "[24] loss: 0.538\n",
      "[25] loss: 0.757\n",
      "[26] loss: 0.530\n",
      "[27] loss: 0.761\n",
      "[28] loss: 0.521\n",
      "[29] loss: 0.515\n",
      "[30] loss: 0.772\n",
      "[31] loss: 0.776\n",
      "[32] loss: 0.778\n",
      "[33] loss: 0.496\n",
      "[34] loss: 0.492\n",
      "[35] loss: 0.485\n",
      "[36] loss: 0.791\n",
      "[37] loss: 0.795\n",
      "[38] loss: 0.467\n",
      "[39] loss: 0.461\n",
      "[40] loss: 0.453\n",
      "[41] loss: 0.444\n",
      "[42] loss: 0.824\n",
      "[43] loss: 1.060\n",
      "[44] loss: 0.832\n",
      "[45] loss: 0.832\n",
      "[46] loss: 0.830\n",
      "[47] loss: 0.827\n",
      "[48] loss: 0.823\n",
      "[49] loss: 0.441\n",
      "[50] loss: 0.814\n",
      "[51] loss: 0.810\n",
      "[52] loss: 0.805\n",
      "[53] loss: 0.799\n",
      "[54] loss: 0.972\n",
      "[55] loss: 0.783\n",
      "[56] loss: 0.774\n",
      "[57] loss: 0.518\n",
      "[58] loss: 0.529\n",
      "[59] loss: 0.535\n",
      "[60] loss: 0.877\n",
      "[61] loss: 0.545\n",
      "[62] loss: 0.548\n",
      "[63] loss: 0.750\n",
      "[64] loss: 0.749\n",
      "[65] loss: 0.748\n",
      "[66] loss: 0.554\n",
      "[67] loss: 0.746\n",
      "[68] loss: 0.852\n",
      "[69] loss: 0.563\n",
      "[70] loss: 0.740\n",
      "[71] loss: 0.738\n",
      "[72] loss: 0.574\n",
      "[73] loss: 0.575\n",
      "[74] loss: 0.573\n",
      "[75] loss: 0.566\n",
      "[76] loss: 0.851\n",
      "[77] loss: 0.553\n",
      "[78] loss: 0.750\n",
      "[79] loss: 0.871\n",
      "[80] loss: 0.870\n",
      "[81] loss: 0.748\n",
      "[82] loss: 0.745\n",
      "[83] loss: 0.741\n",
      "[84] loss: 0.574\n",
      "[85] loss: 0.579\n",
      "[86] loss: 0.734\n",
      "[87] loss: 0.733\n",
      "[88] loss: 0.815\n",
      "[89] loss: 0.593\n",
      "[90] loss: 0.726\n",
      "[91] loss: 0.794\n",
      "[92] loss: 0.610\n",
      "[93] loss: 0.719\n",
      "[94] loss: 0.717\n",
      "[95] loss: 0.627\n",
      "[96] loss: 0.629\n",
      "[97] loss: 0.626\n",
      "[98] loss: 0.619\n",
      "[99] loss: 0.721\n",
      "[100] loss: 0.601\n",
      "[101] loss: 0.729\n",
      "[102] loss: 0.582\n",
      "[103] loss: 0.832\n",
      "[104] loss: 0.740\n",
      "[105] loss: 0.741\n",
      "[106] loss: 0.741\n",
      "[107] loss: 0.840\n",
      "[108] loss: 0.832\n",
      "[109] loss: 0.733\n",
      "[110] loss: 0.728\n",
      "[111] loss: 0.723\n",
      "[112] loss: 0.718\n",
      "[113] loss: 0.631\n",
      "[114] loss: 0.710\n",
      "[115] loss: 0.707\n",
      "[116] loss: 0.704\n",
      "[117] loss: 0.701\n",
      "[118] loss: 0.698\n",
      "[119] loss: 0.695\n",
      "[120] loss: 0.700\n",
      "[121] loss: 0.705\n",
      "[122] loss: 0.682\n",
      "[123] loss: 0.709\n",
      "[124] loss: 0.689\n",
      "[125] loss: 0.678\n",
      "[126] loss: 0.714\n",
      "[127] loss: 0.673\n",
      "[128] loss: 0.686\n",
      "[129] loss: 0.724\n",
      "[130] loss: 0.685\n",
      "[131] loss: 0.725\n",
      "[132] loss: 0.686\n",
      "[133] loss: 0.718\n",
      "[134] loss: 0.689\n",
      "[135] loss: 0.690\n",
      "[136] loss: 0.691\n",
      "[137] loss: 0.700\n",
      "[138] loss: 0.693\n",
      "[139] loss: 0.688\n",
      "[140] loss: 0.679\n",
      "[141] loss: 0.666\n",
      "[142] loss: 0.650\n",
      "[143] loss: 0.713\n",
      "[144] loss: 0.777\n",
      "[145] loss: 0.608\n",
      "[146] loss: 0.726\n",
      "[147] loss: 0.730\n",
      "[148] loss: 0.733\n",
      "[149] loss: 0.823\n",
      "[150] loss: 0.734\n",
      "[151] loss: 0.583\n",
      "[152] loss: 0.733\n",
      "[153] loss: 0.583\n",
      "[154] loss: 0.734\n",
      "[155] loss: 0.579\n",
      "[156] loss: 0.736\n",
      "[157] loss: 0.571\n",
      "[158] loss: 0.565\n",
      "[159] loss: 0.852\n",
      "[160] loss: 0.746\n",
      "[161] loss: 0.552\n",
      "[162] loss: 0.749\n",
      "[163] loss: 0.750\n",
      "[164] loss: 0.750\n",
      "[165] loss: 0.750\n",
      "[166] loss: 0.748\n",
      "[167] loss: 0.745\n",
      "[168] loss: 0.742\n",
      "[169] loss: 0.568\n",
      "[170] loss: 0.738\n",
      "[171] loss: 0.735\n",
      "[172] loss: 0.581\n",
      "[173] loss: 0.732\n",
      "[174] loss: 0.731\n",
      "[175] loss: 0.729\n",
      "[176] loss: 0.596\n",
      "[177] loss: 0.726\n",
      "[178] loss: 0.599\n",
      "[179] loss: 0.598\n",
      "[180] loss: 0.728\n",
      "[181] loss: 0.730\n",
      "[182] loss: 0.811\n",
      "[183] loss: 0.728\n",
      "[184] loss: 0.597\n",
      "[185] loss: 0.598\n",
      "[186] loss: 0.727\n",
      "[187] loss: 0.728\n",
      "[188] loss: 0.593\n",
      "[189] loss: 0.809\n",
      "[190] loss: 0.728\n",
      "[191] loss: 0.727\n",
      "[192] loss: 0.599\n",
      "[193] loss: 0.599\n",
      "[194] loss: 0.727\n",
      "[195] loss: 0.728\n",
      "[196] loss: 0.804\n",
      "[197] loss: 0.725\n",
      "[198] loss: 0.605\n",
      "[199] loss: 0.788\n",
      "[200] loss: 0.613\n",
      "[201] loss: 0.614\n",
      "[202] loss: 0.611\n",
      "[203] loss: 0.723\n",
      "[204] loss: 0.600\n",
      "[205] loss: 0.728\n",
      "[206] loss: 0.587\n",
      "[207] loss: 0.734\n",
      "[208] loss: 0.572\n",
      "[209] loss: 0.842\n",
      "[210] loss: 0.560\n",
      "[211] loss: 0.746\n",
      "[212] loss: 0.549\n",
      "[213] loss: 0.542\n",
      "[214] loss: 0.532\n",
      "[215] loss: 0.520\n",
      "[216] loss: 0.506\n",
      "[217] loss: 0.491\n",
      "[218] loss: 0.474\n",
      "[219] loss: 0.805\n",
      "[220] loss: 1.026\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 1.039\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 1.039\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 1.039\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 1.039\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.437\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.821\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 1.039\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 1.039\n",
      "\n",
      "\n",
      "[1] loss: 0.437\n",
      "[2] loss: 0.828\n",
      "[3] loss: 0.422\n",
      "[4] loss: 0.839\n",
      "[5] loss: 0.843\n",
      "[6] loss: 0.845\n",
      "[7] loss: 1.093\n",
      "[8] loss: 0.413\n",
      "[9] loss: 0.839\n",
      "[10] loss: 0.836\n",
      "[11] loss: 0.424\n",
      "[12] loss: 0.426\n",
      "[13] loss: 0.829\n",
      "[14] loss: 1.055\n",
      "[15] loss: 1.044\n",
      "[16] loss: 0.445\n",
      "[17] loss: 0.451\n",
      "[18] loss: 0.807\n",
      "[19] loss: 0.460\n",
      "[20] loss: 0.994\n",
      "[21] loss: 0.797\n",
      "[22] loss: 0.477\n",
      "[23] loss: 0.788\n",
      "[24] loss: 0.487\n",
      "[25] loss: 0.489\n",
      "[26] loss: 0.951\n",
      "[27] loss: 0.945\n",
      "[28] loss: 0.775\n",
      "[29] loss: 0.510\n",
      "[30] loss: 0.516\n",
      "[31] loss: 0.518\n",
      "[32] loss: 0.766\n",
      "[33] loss: 0.766\n",
      "[34] loss: 0.765\n",
      "[35] loss: 0.763\n",
      "[36] loss: 0.760\n",
      "[37] loss: 0.756\n",
      "[38] loss: 0.870\n",
      "[39] loss: 0.745\n",
      "[40] loss: 0.836\n",
      "[41] loss: 0.731\n",
      "[42] loss: 0.602\n",
      "[43] loss: 0.719\n",
      "[44] loss: 0.626\n",
      "[45] loss: 0.712\n",
      "[46] loss: 0.709\n",
      "[47] loss: 0.706\n",
      "[48] loss: 0.703\n",
      "[49] loss: 0.669\n",
      "[50] loss: 0.674\n",
      "[51] loss: 0.673\n",
      "[52] loss: 0.701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53] loss: 0.664\n",
      "[54] loss: 0.704\n",
      "[55] loss: 0.650\n",
      "[56] loss: 0.641\n",
      "[57] loss: 0.628\n",
      "[58] loss: 0.720\n",
      "[59] loss: 0.796\n",
      "[60] loss: 0.727\n",
      "[61] loss: 0.729\n",
      "[62] loss: 0.809\n",
      "[63] loss: 0.728\n",
      "[64] loss: 0.726\n",
      "[65] loss: 0.604\n",
      "[66] loss: 0.723\n",
      "[67] loss: 0.608\n",
      "[68] loss: 0.722\n",
      "[69] loss: 0.722\n",
      "[70] loss: 0.721\n",
      "[71] loss: 0.720\n",
      "[72] loss: 0.617\n",
      "[73] loss: 0.617\n",
      "[74] loss: 0.613\n",
      "[75] loss: 0.605\n",
      "[76] loss: 0.727\n",
      "[77] loss: 0.586\n",
      "[78] loss: 0.574\n",
      "[79] loss: 0.742\n",
      "[80] loss: 0.550\n",
      "[81] loss: 0.754\n",
      "[82] loss: 0.528\n",
      "[83] loss: 0.766\n",
      "[84] loss: 0.508\n",
      "[85] loss: 0.497\n",
      "[86] loss: 0.786\n",
      "[87] loss: 0.792\n",
      "[88] loss: 0.796\n",
      "[89] loss: 0.466\n",
      "[90] loss: 0.460\n",
      "[91] loss: 0.809\n",
      "[92] loss: 0.447\n",
      "[93] loss: 0.440\n",
      "[94] loss: 0.431\n",
      "[95] loss: 0.834\n",
      "[96] loss: 0.414\n",
      "[97] loss: 0.848\n",
      "[98] loss: 1.110\n",
      "[99] loss: 0.399\n",
      "[100] loss: 0.396\n",
      "[101] loss: 0.860\n",
      "[102] loss: 0.862\n",
      "[103] loss: 0.390\n",
      "[104] loss: 0.388\n",
      "[105] loss: 0.867\n",
      "[106] loss: 0.869\n",
      "[107] loss: 0.868\n",
      "[108] loss: 0.387\n",
      "[109] loss: 0.865\n",
      "[110] loss: 0.390\n",
      "[111] loss: 0.390\n",
      "[112] loss: 0.388\n",
      "[113] loss: 0.868\n",
      "[114] loss: 0.869\n",
      "[115] loss: 0.384\n",
      "[116] loss: 0.382\n",
      "[117] loss: 0.873\n",
      "[118] loss: 0.874\n",
      "[119] loss: 0.872\n",
      "[120] loss: 0.869\n",
      "[121] loss: 0.864\n",
      "[122] loss: 0.394\n",
      "[123] loss: 1.113\n",
      "[124] loss: 0.847\n",
      "[125] loss: 0.838\n",
      "[126] loss: 0.426\n",
      "[127] loss: 0.823\n",
      "[128] loss: 0.816\n",
      "[129] loss: 0.452\n",
      "[130] loss: 0.804\n",
      "[131] loss: 0.466\n",
      "[132] loss: 0.471\n",
      "[133] loss: 0.978\n",
      "[134] loss: 0.791\n",
      "[135] loss: 0.786\n",
      "[136] loss: 0.493\n",
      "[137] loss: 0.777\n",
      "[138] loss: 0.927\n",
      "[139] loss: 0.767\n",
      "[140] loss: 0.761\n",
      "[141] loss: 0.538\n",
      "[142] loss: 0.750\n",
      "[143] loss: 0.555\n",
      "[144] loss: 0.743\n",
      "[145] loss: 0.740\n",
      "[146] loss: 0.573\n",
      "[147] loss: 0.827\n",
      "[148] loss: 0.583\n",
      "[149] loss: 0.731\n",
      "[150] loss: 0.590\n",
      "[151] loss: 0.729\n",
      "[152] loss: 0.591\n",
      "[153] loss: 0.730\n",
      "[154] loss: 0.588\n",
      "[155] loss: 0.583\n",
      "[156] loss: 0.736\n",
      "[157] loss: 0.570\n",
      "[158] loss: 0.562\n",
      "[159] loss: 0.550\n",
      "[160] loss: 0.755\n",
      "[161] loss: 0.760\n",
      "[162] loss: 0.764\n",
      "[163] loss: 0.515\n",
      "[164] loss: 0.920\n",
      "[165] loss: 0.772\n",
      "[166] loss: 0.507\n",
      "[167] loss: 0.926\n",
      "[168] loss: 0.772\n",
      "[169] loss: 0.770\n",
      "[170] loss: 0.516\n",
      "[171] loss: 0.765\n",
      "[172] loss: 0.763\n",
      "[173] loss: 0.760\n",
      "[174] loss: 0.757\n",
      "[175] loss: 0.540\n",
      "[176] loss: 0.751\n",
      "[177] loss: 0.748\n",
      "[178] loss: 0.745\n",
      "[179] loss: 0.741\n",
      "[180] loss: 0.832\n",
      "[181] loss: 0.584\n",
      "[182] loss: 0.728\n",
      "[183] loss: 0.601\n",
      "[184] loss: 0.723\n",
      "[185] loss: 0.721\n",
      "[186] loss: 0.776\n",
      "[187] loss: 0.714\n",
      "[188] loss: 0.639\n",
      "[189] loss: 0.744\n",
      "[190] loss: 0.705\n",
      "[191] loss: 0.701\n",
      "[192] loss: 0.698\n",
      "[193] loss: 0.694\n",
      "[194] loss: 0.702\n",
      "[195] loss: 0.679\n",
      "[196] loss: 0.718\n",
      "[197] loss: 0.723\n",
      "[198] loss: 0.686\n",
      "[199] loss: 0.721\n",
      "[200] loss: 0.687\n",
      "[201] loss: 0.674\n",
      "[202] loss: 0.688\n",
      "[203] loss: 0.717\n",
      "[204] loss: 0.688\n",
      "[205] loss: 0.714\n",
      "[206] loss: 0.708\n",
      "[207] loss: 0.697\n",
      "[208] loss: 0.704\n",
      "[209] loss: 0.698\n",
      "[210] loss: 0.718\n",
      "[211] loss: 0.669\n",
      "[212] loss: 0.702\n",
      "[213] loss: 0.662\n",
      "[214] loss: 0.705\n",
      "[215] loss: 0.650\n",
      "[216] loss: 0.641\n",
      "[217] loss: 0.714\n",
      "[218] loss: 0.619\n",
      "[219] loss: 0.722\n",
      "[220] loss: 0.726\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.808\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.808\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.808\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.808\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.808\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.729\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.808\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.590\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.808\n",
      "\n",
      "\n",
      "[1] loss: 0.590\n",
      "[2] loss: 0.733\n",
      "[3] loss: 0.737\n",
      "[4] loss: 0.836\n",
      "[5] loss: 0.569\n",
      "[6] loss: 0.566\n",
      "[7] loss: 0.743\n",
      "[8] loss: 0.745\n",
      "[9] loss: 0.554\n",
      "[10] loss: 0.862\n",
      "[11] loss: 0.749\n",
      "[12] loss: 0.747\n",
      "[13] loss: 0.746\n",
      "[14] loss: 0.559\n",
      "[15] loss: 0.743\n",
      "[16] loss: 0.741\n",
      "[17] loss: 0.739\n",
      "[18] loss: 0.737\n",
      "[19] loss: 0.822\n",
      "[20] loss: 0.729\n",
      "[21] loss: 0.602\n",
      "[22] loss: 0.609\n",
      "[23] loss: 0.720\n",
      "[24] loss: 0.719\n",
      "[25] loss: 0.619\n",
      "[26] loss: 0.717\n",
      "[27] loss: 0.717\n",
      "[28] loss: 0.716\n",
      "[29] loss: 0.628\n",
      "[30] loss: 0.714\n",
      "[31] loss: 0.762\n",
      "[32] loss: 0.711\n",
      "[33] loss: 0.709\n",
      "[34] loss: 0.650\n",
      "[35] loss: 0.735\n",
      "[36] loss: 0.703\n",
      "[37] loss: 0.700\n",
      "[38] loss: 0.698\n",
      "[39] loss: 0.687\n",
      "[40] loss: 0.694\n",
      "[41] loss: 0.691\n",
      "[42] loss: 0.690\n",
      "[43] loss: 0.687\n",
      "[44] loss: 0.662\n",
      "[45] loss: 0.649\n",
      "[46] loss: 0.758\n",
      "[47] loss: 0.768\n",
      "[48] loss: 0.675\n",
      "[49] loss: 0.674\n",
      "[50] loss: 0.783\n",
      "[51] loss: 0.782\n",
      "[52] loss: 0.675\n",
      "[53] loss: 0.676\n",
      "[54] loss: 0.676\n",
      "[55] loss: 0.677\n",
      "[56] loss: 0.764\n",
      "[57] loss: 0.633\n",
      "[58] loss: 0.678\n",
      "[59] loss: 0.678\n",
      "[60] loss: 0.678\n",
      "[61] loss: 0.761\n",
      "[62] loss: 0.758\n",
      "[63] loss: 0.749\n",
      "[64] loss: 0.682\n",
      "[65] loss: 0.725\n",
      "[66] loss: 0.711\n",
      "[67] loss: 0.693\n",
      "[68] loss: 0.672\n",
      "[69] loss: 0.707\n",
      "[70] loss: 0.630\n",
      "[71] loss: 0.721\n",
      "[72] loss: 0.728\n",
      "[73] loss: 0.579\n",
      "[74] loss: 0.564\n",
      "[75] loss: 0.546\n",
      "[76] loss: 0.760\n",
      "[77] loss: 0.768\n",
      "[78] loss: 0.775\n",
      "[79] loss: 0.779\n",
      "[80] loss: 0.489\n",
      "[81] loss: 0.482\n",
      "[82] loss: 0.472\n",
      "[83] loss: 0.461\n",
      "[84] loss: 1.018\n",
      "[85] loss: 0.817\n",
      "[86] loss: 0.820\n",
      "[87] loss: 0.437\n",
      "[88] loss: 0.433\n",
      "[89] loss: 1.057\n",
      "[90] loss: 0.829\n",
      "[91] loss: 1.056\n",
      "[92] loss: 0.433\n",
      "[93] loss: 0.436\n",
      "[94] loss: 0.436\n",
      "[95] loss: 0.434\n",
      "[96] loss: 0.827\n",
      "[97] loss: 0.829\n",
      "[98] loss: 0.427\n",
      "[99] loss: 0.830\n",
      "[100] loss: 0.831\n",
      "[101] loss: 0.427\n",
      "[102] loss: 0.426\n",
      "[103] loss: 0.832\n",
      "[104] loss: 0.422\n",
      "[105] loss: 0.419\n",
      "[106] loss: 1.081\n",
      "[107] loss: 1.081\n",
      "[108] loss: 1.072\n",
      "[109] loss: 0.427\n",
      "[110] loss: 0.433\n",
      "[111] loss: 0.435\n",
      "[112] loss: 0.435\n",
      "[113] loss: 0.432\n",
      "[114] loss: 0.828\n",
      "[115] loss: 1.060\n",
      "[116] loss: 0.828\n",
      "[117] loss: 0.825\n",
      "[118] loss: 0.438\n",
      "[119] loss: 0.818\n",
      "[120] loss: 0.814\n",
      "[121] loss: 0.809\n",
      "[122] loss: 0.459\n",
      "[123] loss: 0.463\n",
      "[124] loss: 0.464\n",
      "[125] loss: 0.462\n",
      "[126] loss: 1.001\n",
      "[127] loss: 0.459\n",
      "[128] loss: 0.457\n",
      "[129] loss: 0.809\n",
      "[130] loss: 0.810\n",
      "[131] loss: 0.810\n",
      "[132] loss: 0.809\n",
      "[133] loss: 0.806\n",
      "[134] loss: 0.801\n",
      "[135] loss: 0.469\n",
      "[136] loss: 0.794\n",
      "[137] loss: 0.790\n",
      "[138] loss: 0.786\n",
      "[139] loss: 0.781\n",
      "[140] loss: 0.775\n",
      "[141] loss: 0.768\n",
      "[142] loss: 0.524\n",
      "[143] loss: 0.758\n",
      "[144] loss: 0.875\n",
      "[145] loss: 0.747\n",
      "[146] loss: 0.565\n",
      "[147] loss: 0.736\n",
      "[148] loss: 0.583\n",
      "[149] loss: 0.730\n",
      "[150] loss: 0.594\n",
      "[151] loss: 0.727\n",
      "[152] loss: 0.598\n",
      "[153] loss: 0.596\n",
      "[154] loss: 0.729\n",
      "[155] loss: 0.588\n",
      "[156] loss: 0.581\n",
      "[157] loss: 0.572\n",
      "[158] loss: 0.848\n",
      "[159] loss: 0.553\n",
      "[160] loss: 0.751\n",
      "[161] loss: 0.538\n",
      "[162] loss: 0.759\n",
      "[163] loss: 0.522\n",
      "[164] loss: 0.514\n",
      "[165] loss: 0.774\n",
      "[166] loss: 0.495\n",
      "[167] loss: 0.485\n",
      "[168] loss: 0.794\n",
      "[169] loss: 0.800\n",
      "[170] loss: 0.804\n",
      "[171] loss: 0.806\n",
      "[172] loss: 0.806\n",
      "[173] loss: 0.457\n",
      "[174] loss: 1.006\n",
      "[175] loss: 0.804\n",
      "[176] loss: 0.800\n",
      "[177] loss: 0.981\n",
      "[178] loss: 0.788\n",
      "[179] loss: 0.944\n",
      "[180] loss: 0.508\n",
      "[181] loss: 0.764\n",
      "[182] loss: 0.886\n",
      "[183] loss: 0.749\n",
      "[184] loss: 0.564\n",
      "[185] loss: 0.735\n",
      "[186] loss: 0.730\n",
      "[187] loss: 0.725\n",
      "[188] loss: 0.779\n",
      "[189] loss: 0.759\n",
      "[190] loss: 0.653\n",
      "[191] loss: 0.668\n",
      "[192] loss: 0.698\n",
      "[193] loss: 0.685\n",
      "[194] loss: 0.694\n",
      "[195] loss: 0.693\n",
      "[196] loss: 0.694\n",
      "[197] loss: 0.692\n",
      "[198] loss: 0.685\n",
      "[199] loss: 0.711\n",
      "[200] loss: 0.715\n",
      "[201] loss: 0.688\n",
      "[202] loss: 0.688\n",
      "[203] loss: 0.713\n",
      "[204] loss: 0.709\n",
      "[205] loss: 0.700\n",
      "[206] loss: 0.687\n",
      "[207] loss: 0.670\n",
      "[208] loss: 0.651\n",
      "[209] loss: 0.629\n",
      "[210] loss: 0.722\n",
      "[211] loss: 0.730\n",
      "[212] loss: 0.737\n",
      "[213] loss: 0.742\n",
      "[214] loss: 0.746\n",
      "[215] loss: 0.548\n",
      "[216] loss: 0.539\n",
      "[217] loss: 0.528\n",
      "[218] loss: 0.515\n",
      "[219] loss: 0.776\n",
      "[220] loss: 0.489\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.970\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.970\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.791\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "[13] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.970\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.970\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.476\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.476\n",
      "\n",
      "\n",
      "[1] loss: 0.791\n",
      "[2] loss: 0.467\n",
      "[3] loss: 0.806\n",
      "[4] loss: 1.018\n",
      "[5] loss: 0.813\n",
      "[6] loss: 0.814\n",
      "[7] loss: 1.019\n",
      "[8] loss: 1.008\n",
      "[9] loss: 0.800\n",
      "[10] loss: 0.476\n",
      "[11] loss: 0.484\n",
      "[12] loss: 0.488\n",
      "[13] loss: 0.783\n",
      "[14] loss: 0.781\n",
      "[15] loss: 0.496\n",
      "[16] loss: 0.938\n",
      "[17] loss: 0.502\n",
      "[18] loss: 0.504\n",
      "[19] loss: 0.929\n",
      "[20] loss: 0.506\n",
      "[21] loss: 0.924\n",
      "[22] loss: 0.769\n",
      "[23] loss: 0.907\n",
      "[24] loss: 0.760\n",
      "[25] loss: 0.754\n",
      "[26] loss: 0.551\n",
      "[27] loss: 0.559\n",
      "[28] loss: 0.742\n",
      "[29] loss: 0.739\n",
      "[30] loss: 0.573\n",
      "[31] loss: 0.736\n",
      "[32] loss: 0.578\n",
      "[33] loss: 0.578\n",
      "[34] loss: 0.830\n",
      "[35] loss: 0.829\n",
      "[36] loss: 0.734\n",
      "[37] loss: 0.731\n",
      "[38] loss: 0.727\n",
      "[39] loss: 0.603\n",
      "[40] loss: 0.722\n",
      "[41] loss: 0.720\n",
      "[42] loss: 0.619\n",
      "[43] loss: 0.620\n",
      "[44] loss: 0.718\n",
      "[45] loss: 0.718\n",
      "[46] loss: 0.718\n",
      "[47] loss: 0.717\n",
      "[48] loss: 0.716\n",
      "[49] loss: 0.714\n",
      "[50] loss: 0.635\n",
      "[51] loss: 0.711\n",
      "[52] loss: 0.638\n",
      "[53] loss: 0.711\n",
      "[54] loss: 0.754\n",
      "[55] loss: 0.641\n",
      "[56] loss: 0.640\n",
      "[57] loss: 0.636\n",
      "[58] loss: 0.627\n",
      "[59] loss: 0.719\n",
      "[60] loss: 0.722\n",
      "[61] loss: 0.600\n",
      "[62] loss: 0.808\n",
      "[63] loss: 0.731\n",
      "[64] loss: 0.731\n",
      "[65] loss: 0.731\n",
      "[66] loss: 0.730\n",
      "[67] loss: 0.590\n",
      "[68] loss: 0.590\n",
      "[69] loss: 0.585\n",
      "[70] loss: 0.825\n",
      "[71] loss: 0.736\n",
      "[72] loss: 0.736\n",
      "[73] loss: 0.576\n",
      "[74] loss: 0.737\n",
      "[75] loss: 0.737\n",
      "[76] loss: 0.829\n",
      "[77] loss: 0.580\n",
      "[78] loss: 0.733\n",
      "[79] loss: 0.731\n",
      "[80] loss: 0.809\n",
      "[81] loss: 0.599\n",
      "[82] loss: 0.603\n",
      "[83] loss: 0.724\n",
      "[84] loss: 0.604\n",
      "[85] loss: 0.794\n",
      "[86] loss: 0.723\n",
      "[87] loss: 0.608\n",
      "[88] loss: 0.607\n",
      "[89] loss: 0.602\n",
      "[90] loss: 0.594\n",
      "[91] loss: 0.817\n",
      "[92] loss: 0.578\n",
      "[93] loss: 0.569\n",
      "[94] loss: 0.744\n",
      "[95] loss: 0.861\n",
      "[96] loss: 0.749\n",
      "[97] loss: 0.749\n",
      "[98] loss: 0.548\n",
      "[99] loss: 0.750\n",
      "[100] loss: 0.546\n",
      "[101] loss: 0.752\n",
      "[102] loss: 0.541\n",
      "[103] loss: 0.755\n",
      "[104] loss: 0.757\n",
      "[105] loss: 0.757\n",
      "[106] loss: 0.882\n",
      "[107] loss: 0.753\n",
      "[108] loss: 0.863\n",
      "[109] loss: 0.743\n",
      "[110] loss: 0.573\n",
      "[111] loss: 0.580\n",
      "[112] loss: 0.583\n",
      "[113] loss: 0.582\n",
      "[114] loss: 0.735\n",
      "[115] loss: 0.736\n",
      "[116] loss: 0.574\n",
      "[117] loss: 0.570\n",
      "[118] loss: 0.742\n",
      "[119] loss: 0.744\n",
      "[120] loss: 0.554\n",
      "[121] loss: 0.749\n",
      "[122] loss: 0.751\n",
      "[123] loss: 0.751\n",
      "[124] loss: 0.751\n",
      "[125] loss: 0.750\n",
      "[126] loss: 0.860\n",
      "[127] loss: 0.559\n",
      "[128] loss: 0.563\n",
      "[129] loss: 0.563\n",
      "[130] loss: 0.743\n",
      "[131] loss: 0.557\n",
      "[132] loss: 0.747\n",
      "[133] loss: 0.748\n",
      "[134] loss: 0.748\n",
      "[135] loss: 0.748\n",
      "[136] loss: 0.553\n",
      "[137] loss: 0.747\n",
      "[138] loss: 0.553\n",
      "[139] loss: 0.550\n",
      "[140] loss: 0.751\n",
      "[141] loss: 0.541\n",
      "[142] loss: 0.756\n",
      "[143] loss: 0.530\n",
      "[144] loss: 0.523\n",
      "[145] loss: 0.912\n",
      "[146] loss: 0.770\n",
      "[147] loss: 0.771\n",
      "[148] loss: 0.919\n",
      "[149] loss: 0.767\n",
      "[150] loss: 0.901\n",
      "[151] loss: 0.757\n",
      "[152] loss: 0.751\n",
      "[153] loss: 0.744\n",
      "[154] loss: 0.738\n",
      "[155] loss: 0.731\n",
      "[156] loss: 0.796\n",
      "[157] loss: 0.618\n",
      "[158] loss: 0.713\n",
      "[159] loss: 0.708\n",
      "[160] loss: 0.704\n",
      "[161] loss: 0.699\n",
      "[162] loss: 0.686\n",
      "[163] loss: 0.693\n",
      "[164] loss: 0.691\n",
      "[165] loss: 0.688\n",
      "[166] loss: 0.686\n",
      "[167] loss: 0.684\n",
      "[168] loss: 0.742\n",
      "[169] loss: 0.680\n",
      "[170] loss: 0.750\n",
      "[171] loss: 0.749\n",
      "[172] loss: 0.742\n",
      "[173] loss: 0.731\n",
      "[174] loss: 0.687\n",
      "[175] loss: 0.703\n",
      "[176] loss: 0.687\n",
      "[177] loss: 0.667\n",
      "[178] loss: 0.708\n",
      "[179] loss: 0.628\n",
      "[180] loss: 0.721\n",
      "[181] loss: 0.728\n",
      "[182] loss: 0.581\n",
      "[183] loss: 0.566\n",
      "[184] loss: 0.549\n",
      "[185] loss: 0.531\n",
      "[186] loss: 0.769\n",
      "[187] loss: 0.497\n",
      "[188] loss: 0.481\n",
      "[189] loss: 0.464\n",
      "[190] loss: 0.813\n",
      "[191] loss: 0.433\n",
      "[192] loss: 0.836\n",
      "[193] loss: 0.408\n",
      "[194] loss: 0.856\n",
      "[195] loss: 1.134\n",
      "[196] loss: 0.866\n",
      "[197] loss: 0.385\n",
      "[198] loss: 0.382\n",
      "[199] loss: 1.156\n",
      "[200] loss: 0.873\n",
      "[201] loss: 0.871\n",
      "[202] loss: 0.385\n",
      "[203] loss: 0.387\n",
      "[204] loss: 0.387\n",
      "[205] loss: 0.384\n",
      "[206] loss: 0.380\n",
      "[207] loss: 1.164\n",
      "[208] loss: 0.878\n",
      "[209] loss: 1.162\n",
      "[210] loss: 0.381\n",
      "[211] loss: 0.384\n",
      "[212] loss: 0.384\n",
      "[213] loss: 0.869\n",
      "[214] loss: 0.868\n",
      "[215] loss: 0.386\n",
      "[216] loss: 0.387\n",
      "[217] loss: 0.867\n",
      "[218] loss: 0.385\n",
      "[219] loss: 0.384\n",
      "[220] loss: 0.380\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 1.162\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 1.162\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 1.162\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 1.162\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.375\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 1.162\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.877\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 1.162\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.375\n",
      "\n",
      "\n",
      "[1] loss: 0.375\n",
      "[2] loss: 0.883\n",
      "[3] loss: 0.365\n",
      "[4] loss: 0.893\n",
      "[5] loss: 0.357\n",
      "[6] loss: 0.353\n",
      "[7] loss: 1.225\n",
      "[8] loss: 0.908\n",
      "[9] loss: 0.349\n",
      "[10] loss: 0.907\n",
      "[11] loss: 0.350\n",
      "[12] loss: 0.349\n",
      "[13] loss: 0.907\n",
      "[14] loss: 0.907\n",
      "[15] loss: 0.905\n",
      "[16] loss: 0.900\n",
      "[17] loss: 0.360\n",
      "[18] loss: 0.363\n",
      "[19] loss: 0.364\n",
      "[20] loss: 0.889\n",
      "[21] loss: 0.365\n",
      "[22] loss: 0.889\n",
      "[23] loss: 0.365\n",
      "[24] loss: 0.365\n",
      "[25] loss: 0.890\n",
      "[26] loss: 0.891\n",
      "[27] loss: 0.364\n",
      "[28] loss: 0.889\n",
      "[29] loss: 0.886\n",
      "[30] loss: 1.174\n",
      "[31] loss: 1.157\n",
      "[32] loss: 0.389\n",
      "[33] loss: 0.855\n",
      "[34] loss: 0.407\n",
      "[35] loss: 0.414\n",
      "[36] loss: 0.836\n",
      "[37] loss: 0.832\n",
      "[38] loss: 0.826\n",
      "[39] loss: 0.439\n",
      "[40] loss: 0.444\n",
      "[41] loss: 0.446\n",
      "[42] loss: 0.445\n",
      "[43] loss: 1.029\n",
      "[44] loss: 1.026\n",
      "[45] loss: 0.450\n",
      "[46] loss: 0.453\n",
      "[47] loss: 0.808\n",
      "[48] loss: 0.806\n",
      "[49] loss: 0.804\n",
      "[50] loss: 0.800\n",
      "[51] loss: 0.471\n",
      "[52] loss: 0.475\n",
      "[53] loss: 0.792\n",
      "[54] loss: 0.477\n",
      "[55] loss: 0.791\n",
      "[56] loss: 0.478\n",
      "[57] loss: 0.971\n",
      "[58] loss: 0.479\n",
      "[59] loss: 0.479\n",
      "[60] loss: 0.792\n",
      "[61] loss: 0.475\n",
      "[62] loss: 0.795\n",
      "[63] loss: 0.980\n",
      "[64] loss: 0.474\n",
      "[65] loss: 0.793\n",
      "[66] loss: 0.477\n",
      "[67] loss: 0.476\n",
      "[68] loss: 0.794\n",
      "[69] loss: 0.471\n",
      "[70] loss: 0.797\n",
      "[71] loss: 0.799\n",
      "[72] loss: 0.798\n",
      "[73] loss: 0.469\n",
      "[74] loss: 0.797\n",
      "[75] loss: 0.470\n",
      "[76] loss: 0.797\n",
      "[77] loss: 0.796\n",
      "[78] loss: 0.472\n",
      "[79] loss: 0.795\n",
      "[80] loss: 0.976\n",
      "[81] loss: 0.790\n",
      "[82] loss: 0.486\n",
      "[83] loss: 0.490\n",
      "[84] loss: 0.782\n",
      "[85] loss: 0.780\n",
      "[86] loss: 0.778\n",
      "[87] loss: 0.503\n",
      "[88] loss: 0.773\n",
      "[89] loss: 0.920\n",
      "[90] loss: 0.517\n",
      "[91] loss: 0.764\n",
      "[92] loss: 0.760\n",
      "[93] loss: 0.883\n",
      "[94] loss: 0.750\n",
      "[95] loss: 0.744\n",
      "[96] loss: 0.570\n",
      "[97] loss: 0.734\n",
      "[98] loss: 0.587\n",
      "[99] loss: 0.591\n",
      "[100] loss: 0.807\n",
      "[101] loss: 0.727\n",
      "[102] loss: 0.724\n",
      "[103] loss: 0.785\n",
      "[104] loss: 0.717\n",
      "[105] loss: 0.757\n",
      "[106] loss: 0.649\n",
      "[107] loss: 0.703\n",
      "[108] loss: 0.700\n",
      "[109] loss: 0.681\n",
      "[110] loss: 0.695\n",
      "[111] loss: 0.693\n",
      "[112] loss: 0.693\n",
      "[113] loss: 0.697\n",
      "[114] loss: 0.694\n",
      "[115] loss: 0.692\n",
      "[116] loss: 0.689\n",
      "[117] loss: 0.682\n",
      "[118] loss: 0.717\n",
      "[119] loss: 0.665\n",
      "[120] loss: 0.704\n",
      "[121] loss: 0.648\n",
      "[122] loss: 0.710\n",
      "[123] loss: 0.630\n",
      "[124] loss: 0.774\n",
      "[125] loss: 0.613\n",
      "[126] loss: 0.604\n",
      "[127] loss: 0.592\n",
      "[128] loss: 0.578\n",
      "[129] loss: 0.561\n",
      "[130] loss: 0.543\n",
      "[131] loss: 0.762\n",
      "[132] loss: 0.508\n",
      "[133] loss: 0.946\n",
      "[134] loss: 0.788\n",
      "[135] loss: 0.973\n",
      "[136] loss: 0.793\n",
      "[137] loss: 0.793\n",
      "[138] loss: 0.791\n",
      "[139] loss: 0.788\n",
      "[140] loss: 0.784\n",
      "[141] loss: 0.779\n",
      "[142] loss: 0.503\n",
      "[143] loss: 0.508\n",
      "[144] loss: 0.920\n",
      "[145] loss: 0.514\n",
      "[146] loss: 0.766\n",
      "[147] loss: 0.764\n",
      "[148] loss: 0.525\n",
      "[149] loss: 0.760\n",
      "[150] loss: 0.530\n",
      "[151] loss: 0.759\n",
      "[152] loss: 0.531\n",
      "[153] loss: 0.759\n",
      "[154] loss: 0.528\n",
      "[155] loss: 0.525\n",
      "[156] loss: 0.765\n",
      "[157] loss: 0.767\n",
      "[158] loss: 0.513\n",
      "[159] loss: 0.771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160] loss: 0.923\n",
      "[161] loss: 0.770\n",
      "[162] loss: 0.768\n",
      "[163] loss: 0.903\n",
      "[164] loss: 0.888\n",
      "[165] loss: 0.544\n",
      "[166] loss: 0.746\n",
      "[167] loss: 0.564\n",
      "[168] loss: 0.570\n",
      "[169] loss: 0.737\n",
      "[170] loss: 0.575\n",
      "[171] loss: 0.574\n",
      "[172] loss: 0.739\n",
      "[173] loss: 0.567\n",
      "[174] loss: 0.743\n",
      "[175] loss: 0.744\n",
      "[176] loss: 0.556\n",
      "[177] loss: 0.747\n",
      "[178] loss: 0.548\n",
      "[179] loss: 0.752\n",
      "[180] loss: 0.539\n",
      "[181] loss: 0.757\n",
      "[182] loss: 0.759\n",
      "[183] loss: 0.760\n",
      "[184] loss: 0.760\n",
      "[185] loss: 0.889\n",
      "[186] loss: 0.755\n",
      "[187] loss: 0.751\n",
      "[188] loss: 0.855\n",
      "[189] loss: 0.837\n",
      "[190] loss: 0.815\n",
      "[191] loss: 0.605\n",
      "[192] loss: 0.717\n",
      "[193] loss: 0.711\n",
      "[194] loss: 0.706\n",
      "[195] loss: 0.701\n",
      "[196] loss: 0.696\n",
      "[197] loss: 0.691\n",
      "[198] loss: 0.716\n",
      "[199] loss: 0.685\n",
      "[200] loss: 0.735\n",
      "[201] loss: 0.738\n",
      "[202] loss: 0.652\n",
      "[203] loss: 0.682\n",
      "[204] loss: 0.646\n",
      "[205] loss: 0.751\n",
      "[206] loss: 0.753\n",
      "[207] loss: 0.680\n",
      "[208] loss: 0.680\n",
      "[209] loss: 0.746\n",
      "[210] loss: 0.682\n",
      "[211] loss: 0.683\n",
      "[212] loss: 0.733\n",
      "[213] loss: 0.685\n",
      "[214] loss: 0.720\n",
      "[215] loss: 0.689\n",
      "[216] loss: 0.701\n",
      "[217] loss: 0.694\n",
      "[218] loss: 0.680\n",
      "[219] loss: 0.667\n",
      "[220] loss: 0.650\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.759\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.759\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.759\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.759\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.631\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.759\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.713\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.631\n",
      "\n",
      "\n",
      "[1] loss: 0.759\n",
      "[2] loss: 0.619\n",
      "[3] loss: 0.790\n",
      "[4] loss: 0.596\n",
      "[5] loss: 0.731\n",
      "[6] loss: 0.735\n",
      "[7] loss: 0.737\n",
      "[8] loss: 0.568\n",
      "[9] loss: 0.742\n",
      "[10] loss: 0.557\n",
      "[11] loss: 0.550\n",
      "[12] loss: 0.540\n",
      "[13] loss: 0.527\n",
      "[14] loss: 0.913\n",
      "[15] loss: 0.773\n",
      "[16] loss: 0.776\n",
      "[17] loss: 0.497\n",
      "[18] loss: 0.781\n",
      "[19] loss: 0.783\n",
      "[20] loss: 0.488\n",
      "[21] loss: 0.786\n",
      "[22] loss: 0.787\n",
      "[23] loss: 0.484\n",
      "[24] loss: 0.787\n",
      "[25] loss: 0.482\n",
      "[26] loss: 0.479\n",
      "[27] loss: 0.793\n",
      "[28] loss: 0.470\n",
      "[29] loss: 0.799\n",
      "[30] loss: 0.462\n",
      "[31] loss: 0.805\n",
      "[32] loss: 0.807\n",
      "[33] loss: 1.009\n",
      "[34] loss: 0.458\n",
      "[35] loss: 0.459\n",
      "[36] loss: 0.805\n",
      "[37] loss: 0.457\n",
      "[38] loss: 1.006\n",
      "[39] loss: 0.458\n",
      "[40] loss: 0.805\n",
      "[41] loss: 0.804\n",
      "[42] loss: 0.801\n",
      "[43] loss: 0.468\n",
      "[44] loss: 0.796\n",
      "[45] loss: 0.976\n",
      "[46] loss: 0.788\n",
      "[47] loss: 0.491\n",
      "[48] loss: 0.939\n",
      "[49] loss: 0.772\n",
      "[50] loss: 0.766\n",
      "[51] loss: 0.759\n",
      "[52] loss: 0.752\n",
      "[53] loss: 0.745\n",
      "[54] loss: 0.835\n",
      "[55] loss: 0.730\n",
      "[56] loss: 0.723\n",
      "[57] loss: 0.624\n",
      "[58] loss: 0.637\n",
      "[59] loss: 0.708\n",
      "[60] loss: 0.652\n",
      "[61] loss: 0.654\n",
      "[62] loss: 0.652\n",
      "[63] loss: 0.708\n",
      "[64] loss: 0.709\n",
      "[65] loss: 0.710\n",
      "[66] loss: 0.638\n",
      "[67] loss: 0.712\n",
      "[68] loss: 0.631\n",
      "[69] loss: 0.624\n",
      "[70] loss: 0.613\n",
      "[71] loss: 0.725\n",
      "[72] loss: 0.590\n",
      "[73] loss: 0.735\n",
      "[74] loss: 0.838\n",
      "[75] loss: 0.741\n",
      "[76] loss: 0.561\n",
      "[77] loss: 0.556\n",
      "[78] loss: 0.863\n",
      "[79] loss: 0.750\n",
      "[80] loss: 0.750\n",
      "[81] loss: 0.750\n",
      "[82] loss: 0.549\n",
      "[83] loss: 0.748\n",
      "[84] loss: 0.748\n",
      "[85] loss: 0.746\n",
      "[86] loss: 0.557\n",
      "[87] loss: 0.744\n",
      "[88] loss: 0.743\n",
      "[89] loss: 0.563\n",
      "[90] loss: 0.843\n",
      "[91] loss: 0.567\n",
      "[92] loss: 0.739\n",
      "[93] loss: 0.738\n",
      "[94] loss: 0.736\n",
      "[95] loss: 0.734\n",
      "[96] loss: 0.585\n",
      "[97] loss: 0.730\n",
      "[98] loss: 0.729\n",
      "[99] loss: 0.727\n",
      "[100] loss: 0.601\n",
      "[101] loss: 0.724\n",
      "[102] loss: 0.723\n",
      "[103] loss: 0.610\n",
      "[104] loss: 0.609\n",
      "[105] loss: 0.605\n",
      "[106] loss: 0.597\n",
      "[107] loss: 0.731\n",
      "[108] loss: 0.577\n",
      "[109] loss: 0.740\n",
      "[110] loss: 0.744\n",
      "[111] loss: 0.746\n",
      "[112] loss: 0.748\n",
      "[113] loss: 0.549\n",
      "[114] loss: 0.751\n",
      "[115] loss: 0.752\n",
      "[116] loss: 0.542\n",
      "[117] loss: 0.754\n",
      "[118] loss: 0.537\n",
      "[119] loss: 0.757\n",
      "[120] loss: 0.758\n",
      "[121] loss: 0.758\n",
      "[122] loss: 0.757\n",
      "[123] loss: 0.535\n",
      "[124] loss: 0.535\n",
      "[125] loss: 0.758\n",
      "[126] loss: 0.759\n",
      "[127] loss: 0.758\n",
      "[128] loss: 0.532\n",
      "[129] loss: 0.758\n",
      "[130] loss: 0.758\n",
      "[131] loss: 0.756\n",
      "[132] loss: 0.754\n",
      "[133] loss: 0.751\n",
      "[134] loss: 0.550\n",
      "[135] loss: 0.553\n",
      "[136] loss: 0.747\n",
      "[137] loss: 0.553\n",
      "[138] loss: 0.550\n",
      "[139] loss: 0.751\n",
      "[140] loss: 0.540\n",
      "[141] loss: 0.884\n",
      "[142] loss: 0.757\n",
      "[143] loss: 0.757\n",
      "[144] loss: 0.756\n",
      "[145] loss: 0.753\n",
      "[146] loss: 0.545\n",
      "[147] loss: 0.546\n",
      "[148] loss: 0.751\n",
      "[149] loss: 0.544\n",
      "[150] loss: 0.540\n",
      "[151] loss: 0.756\n",
      "[152] loss: 0.759\n",
      "[153] loss: 0.528\n",
      "[154] loss: 0.762\n",
      "[155] loss: 0.903\n",
      "[156] loss: 0.763\n",
      "[157] loss: 0.760\n",
      "[158] loss: 0.885\n",
      "[159] loss: 0.542\n",
      "[160] loss: 0.863\n",
      "[161] loss: 0.850\n",
      "[162] loss: 0.737\n",
      "[163] loss: 0.731\n",
      "[164] loss: 0.794\n",
      "[165] loss: 0.717\n",
      "[166] loss: 0.640\n",
      "[167] loss: 0.653\n",
      "[168] loss: 0.703\n",
      "[169] loss: 0.700\n",
      "[170] loss: 0.677\n",
      "[171] loss: 0.680\n",
      "[172] loss: 0.697\n",
      "[173] loss: 0.677\n",
      "[174] loss: 0.699\n",
      "[175] loss: 0.669\n",
      "[176] loss: 0.703\n",
      "[177] loss: 0.656\n",
      "[178] loss: 0.647\n",
      "[179] loss: 0.756\n",
      "[180] loss: 0.627\n",
      "[181] loss: 0.617\n",
      "[182] loss: 0.604\n",
      "[183] loss: 0.588\n",
      "[184] loss: 0.833\n",
      "[185] loss: 0.560\n",
      "[186] loss: 0.750\n",
      "[187] loss: 0.537\n",
      "[188] loss: 0.761\n",
      "[189] loss: 0.909\n",
      "[190] loss: 0.768\n",
      "[191] loss: 0.769\n",
      "[192] loss: 0.513\n",
      "[193] loss: 0.510\n",
      "[194] loss: 0.773\n",
      "[195] loss: 0.774\n",
      "[196] loss: 0.775\n",
      "[197] loss: 0.774\n",
      "[198] loss: 0.772\n",
      "[199] loss: 0.511\n",
      "[200] loss: 0.512\n",
      "[201] loss: 0.770\n",
      "[202] loss: 0.510\n",
      "[203] loss: 0.772\n",
      "[204] loss: 0.772\n",
      "[205] loss: 0.772\n",
      "[206] loss: 0.510\n",
      "[207] loss: 0.770\n",
      "[208] loss: 0.770\n",
      "[209] loss: 0.768\n",
      "[210] loss: 0.765\n",
      "[211] loss: 0.524\n",
      "[212] loss: 0.760\n",
      "[213] loss: 0.530\n",
      "[214] loss: 0.887\n",
      "[215] loss: 0.536\n",
      "[216] loss: 0.755\n",
      "[217] loss: 0.539\n",
      "[218] loss: 0.754\n",
      "[219] loss: 0.540\n",
      "[220] loss: 0.755\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.755\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.879\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.536\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.879\n",
      "\n",
      "\n",
      "[1] loss: 0.536\n",
      "[2] loss: 0.757\n",
      "[3] loss: 0.758\n",
      "[4] loss: 0.531\n",
      "[5] loss: 0.759\n",
      "[6] loss: 0.760\n",
      "[7] loss: 0.529\n",
      "[8] loss: 0.526\n",
      "[9] loss: 0.763\n",
      "[10] loss: 0.518\n",
      "[11] loss: 0.769\n",
      "[12] loss: 0.771\n",
      "[13] loss: 0.507\n",
      "[14] loss: 0.503\n",
      "[15] loss: 0.939\n",
      "[16] loss: 0.779\n",
      "[17] loss: 0.779\n",
      "[18] loss: 0.498\n",
      "[19] loss: 0.778\n",
      "[20] loss: 0.499\n",
      "[21] loss: 0.778\n",
      "[22] loss: 0.778\n",
      "[23] loss: 0.499\n",
      "[24] loss: 0.777\n",
      "[25] loss: 0.777\n",
      "[26] loss: 0.775\n",
      "[27] loss: 0.506\n",
      "[28] loss: 0.772\n",
      "[29] loss: 0.770\n",
      "[30] loss: 0.768\n",
      "[31] loss: 0.904\n",
      "[32] loss: 0.529\n",
      "[33] loss: 0.756\n",
      "[34] loss: 0.542\n",
      "[35] loss: 0.545\n",
      "[36] loss: 0.544\n",
      "[37] loss: 0.540\n",
      "[38] loss: 0.757\n",
      "[39] loss: 0.528\n",
      "[40] loss: 0.902\n",
      "[41] loss: 0.519\n",
      "[42] loss: 0.768\n",
      "[43] loss: 0.769\n",
      "[44] loss: 0.916\n",
      "[45] loss: 0.767\n",
      "[46] loss: 0.521\n",
      "[47] loss: 0.523\n",
      "[48] loss: 0.522\n",
      "[49] loss: 0.907\n",
      "[50] loss: 0.518\n",
      "[51] loss: 0.515\n",
      "[52] loss: 0.510\n",
      "[53] loss: 0.502\n",
      "[54] loss: 0.781\n",
      "[55] loss: 0.484\n",
      "[56] loss: 0.475\n",
      "[57] loss: 0.464\n",
      "[58] loss: 0.809\n",
      "[59] loss: 0.442\n",
      "[60] loss: 0.431\n",
      "[61] loss: 0.420\n",
      "[62] loss: 0.407\n",
      "[63] loss: 0.394\n",
      "[64] loss: 0.872\n",
      "[65] loss: 0.370\n",
      "[66] loss: 0.359\n",
      "[67] loss: 0.348\n",
      "[68] loss: 0.920\n",
      "[69] loss: 0.931\n",
      "[70] loss: 0.937\n",
      "[71] loss: 1.293\n",
      "[72] loss: 0.939\n",
      "[73] loss: 1.280\n",
      "[74] loss: 0.925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75] loss: 0.342\n",
      "[76] loss: 0.348\n",
      "[77] loss: 0.352\n",
      "[78] loss: 1.211\n",
      "[79] loss: 0.360\n",
      "[80] loss: 0.890\n",
      "[81] loss: 0.884\n",
      "[82] loss: 0.375\n",
      "[83] loss: 0.379\n",
      "[84] loss: 0.381\n",
      "[85] loss: 0.871\n",
      "[86] loss: 0.383\n",
      "[87] loss: 0.382\n",
      "[88] loss: 0.380\n",
      "[89] loss: 0.376\n",
      "[90] loss: 0.370\n",
      "[91] loss: 0.363\n",
      "[92] loss: 0.355\n",
      "[93] loss: 0.346\n",
      "[94] loss: 0.337\n",
      "[95] loss: 0.327\n",
      "[96] loss: 0.946\n",
      "[97] loss: 0.956\n",
      "[98] loss: 0.962\n",
      "[99] loss: 0.304\n",
      "[100] loss: 1.348\n",
      "[101] loss: 1.345\n",
      "[102] loss: 1.331\n",
      "[103] loss: 0.315\n",
      "[104] loss: 0.940\n",
      "[105] loss: 1.271\n",
      "[106] loss: 0.340\n",
      "[107] loss: 0.905\n",
      "[108] loss: 0.894\n",
      "[109] loss: 0.882\n",
      "[110] loss: 0.383\n",
      "[111] loss: 0.859\n",
      "[112] loss: 0.403\n",
      "[113] loss: 0.842\n",
      "[114] loss: 0.834\n",
      "[115] loss: 0.431\n",
      "[116] loss: 0.438\n",
      "[117] loss: 1.030\n",
      "[118] loss: 0.811\n",
      "[119] loss: 0.804\n",
      "[120] loss: 0.796\n",
      "[121] loss: 0.788\n",
      "[122] loss: 0.494\n",
      "[123] loss: 0.503\n",
      "[124] loss: 0.507\n",
      "[125] loss: 0.508\n",
      "[126] loss: 0.923\n",
      "[127] loss: 0.919\n",
      "[128] loss: 0.516\n",
      "[129] loss: 0.764\n",
      "[130] loss: 0.761\n",
      "[131] loss: 0.886\n",
      "[132] loss: 0.542\n",
      "[133] loss: 0.548\n",
      "[134] loss: 0.550\n",
      "[135] loss: 0.748\n",
      "[136] loss: 0.549\n",
      "[137] loss: 0.750\n",
      "[138] loss: 0.868\n",
      "[139] loss: 0.749\n",
      "[140] loss: 0.746\n",
      "[141] loss: 0.743\n",
      "[142] loss: 0.568\n",
      "[143] loss: 0.572\n",
      "[144] loss: 0.571\n",
      "[145] loss: 0.740\n",
      "[146] loss: 0.841\n",
      "[147] loss: 0.838\n",
      "[148] loss: 0.736\n",
      "[149] loss: 0.817\n",
      "[150] loss: 0.727\n",
      "[151] loss: 0.609\n",
      "[152] loss: 0.618\n",
      "[153] loss: 0.621\n",
      "[154] loss: 0.717\n",
      "[155] loss: 0.717\n",
      "[156] loss: 0.771\n",
      "[157] loss: 0.763\n",
      "[158] loss: 0.710\n",
      "[159] loss: 0.651\n",
      "[160] loss: 0.657\n",
      "[161] loss: 0.704\n",
      "[162] loss: 0.703\n",
      "[163] loss: 0.663\n",
      "[164] loss: 0.702\n",
      "[165] loss: 0.725\n",
      "[166] loss: 0.667\n",
      "[167] loss: 0.667\n",
      "[168] loss: 0.662\n",
      "[169] loss: 0.705\n",
      "[170] loss: 0.707\n",
      "[171] loss: 0.709\n",
      "[172] loss: 0.710\n",
      "[173] loss: 0.710\n",
      "[174] loss: 0.640\n",
      "[175] loss: 0.753\n",
      "[176] loss: 0.710\n",
      "[177] loss: 0.709\n",
      "[178] loss: 0.742\n",
      "[179] loss: 0.732\n",
      "[180] loss: 0.700\n",
      "[181] loss: 0.704\n",
      "[182] loss: 0.700\n",
      "[183] loss: 0.711\n",
      "[184] loss: 0.687\n",
      "[185] loss: 0.686\n",
      "[186] loss: 0.660\n",
      "[187] loss: 0.738\n",
      "[188] loss: 0.646\n",
      "[189] loss: 0.751\n",
      "[190] loss: 0.679\n",
      "[191] loss: 0.757\n",
      "[192] loss: 0.679\n",
      "[193] loss: 0.753\n",
      "[194] loss: 0.746\n",
      "[195] loss: 0.653\n",
      "[196] loss: 0.730\n",
      "[197] loss: 0.667\n",
      "[198] loss: 0.687\n",
      "[199] loss: 0.688\n",
      "[200] loss: 0.688\n",
      "[201] loss: 0.713\n",
      "[202] loss: 0.689\n",
      "[203] loss: 0.706\n",
      "[204] loss: 0.698\n",
      "[205] loss: 0.700\n",
      "[206] loss: 0.706\n",
      "[207] loss: 0.697\n",
      "[208] loss: 0.696\n",
      "[209] loss: 0.685\n",
      "[210] loss: 0.696\n",
      "[211] loss: 0.696\n",
      "[212] loss: 0.682\n",
      "[213] loss: 0.678\n",
      "[214] loss: 0.718\n",
      "[215] loss: 0.701\n",
      "[216] loss: 0.701\n",
      "[217] loss: 0.666\n",
      "[218] loss: 0.702\n",
      "[219] loss: 0.703\n",
      "[220] loss: 0.659\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.734\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.734\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.734\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.734\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.705\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.654\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.734\n",
      "\n",
      "\n",
      "[1] loss: 0.705\n",
      "[2] loss: 0.706\n",
      "[3] loss: 0.739\n",
      "[4] loss: 0.705\n",
      "[5] loss: 0.703\n",
      "[6] loss: 0.664\n",
      "[7] loss: 0.701\n",
      "[8] loss: 0.701\n",
      "[9] loss: 0.716\n",
      "[10] loss: 0.697\n",
      "[11] loss: 0.688\n",
      "[12] loss: 0.694\n",
      "[13] loss: 0.693\n",
      "[14] loss: 0.700\n",
      "[15] loss: 0.699\n",
      "[16] loss: 0.694\n",
      "[17] loss: 0.696\n",
      "[18] loss: 0.710\n",
      "[19] loss: 0.698\n",
      "[20] loss: 0.712\n",
      "[21] loss: 0.697\n",
      "[22] loss: 0.701\n",
      "[23] loss: 0.692\n",
      "[24] loss: 0.707\n",
      "[25] loss: 0.675\n",
      "[26] loss: 0.721\n",
      "[27] loss: 0.724\n",
      "[28] loss: 0.666\n",
      "[29] loss: 0.685\n",
      "[30] loss: 0.684\n",
      "[31] loss: 0.683\n",
      "[32] loss: 0.682\n",
      "[33] loss: 0.744\n",
      "[34] loss: 0.744\n",
      "[35] loss: 0.650\n",
      "[36] loss: 0.682\n",
      "[37] loss: 0.740\n",
      "[38] loss: 0.683\n",
      "[39] loss: 0.733\n",
      "[40] loss: 0.685\n",
      "[41] loss: 0.720\n",
      "[42] loss: 0.689\n",
      "[43] loss: 0.701\n",
      "[44] loss: 0.697\n",
      "[45] loss: 0.703\n",
      "[46] loss: 0.683\n",
      "[47] loss: 0.678\n",
      "[48] loss: 0.669\n",
      "[49] loss: 0.704\n",
      "[50] loss: 0.708\n",
      "[51] loss: 0.638\n",
      "[52] loss: 0.627\n",
      "[53] loss: 0.720\n",
      "[54] loss: 0.602\n",
      "[55] loss: 0.588\n",
      "[56] loss: 0.737\n",
      "[57] loss: 0.743\n",
      "[58] loss: 0.747\n",
      "[59] loss: 0.751\n",
      "[60] loss: 0.753\n",
      "[61] loss: 0.539\n",
      "[62] loss: 0.756\n",
      "[63] loss: 0.758\n",
      "[64] loss: 0.887\n",
      "[65] loss: 0.756\n",
      "[66] loss: 0.541\n",
      "[67] loss: 0.543\n",
      "[68] loss: 0.541\n",
      "[69] loss: 0.536\n",
      "[70] loss: 0.760\n",
      "[71] loss: 0.763\n",
      "[72] loss: 0.520\n",
      "[73] loss: 0.768\n",
      "[74] loss: 0.770\n",
      "[75] loss: 0.770\n",
      "[76] loss: 0.770\n",
      "[77] loss: 0.513\n",
      "[78] loss: 0.512\n",
      "[79] loss: 0.508\n",
      "[80] loss: 0.502\n",
      "[81] loss: 0.780\n",
      "[82] loss: 0.784\n",
      "[83] loss: 0.483\n",
      "[84] loss: 0.477\n",
      "[85] loss: 0.796\n",
      "[86] loss: 0.464\n",
      "[87] loss: 0.806\n",
      "[88] loss: 0.809\n",
      "[89] loss: 0.449\n",
      "[90] loss: 0.445\n",
      "[91] loss: 0.438\n",
      "[92] loss: 0.430\n",
      "[93] loss: 0.835\n",
      "[94] loss: 0.841\n",
      "[95] loss: 0.409\n",
      "[96] loss: 0.849\n",
      "[97] loss: 0.852\n",
      "[98] loss: 0.853\n",
      "[99] loss: 0.852\n",
      "[100] loss: 0.849\n",
      "[101] loss: 0.409\n",
      "[102] loss: 0.411\n",
      "[103] loss: 0.842\n",
      "[104] loss: 0.841\n",
      "[105] loss: 0.838\n",
      "[106] loss: 0.833\n",
      "[107] loss: 0.827\n",
      "[108] loss: 1.038\n",
      "[109] loss: 0.449\n",
      "[110] loss: 0.458\n",
      "[111] loss: 0.801\n",
      "[112] loss: 0.796\n",
      "[113] loss: 0.478\n",
      "[114] loss: 0.787\n",
      "[115] loss: 0.783\n",
      "[116] loss: 0.496\n",
      "[117] loss: 0.499\n",
      "[118] loss: 0.499\n",
      "[119] loss: 0.497\n",
      "[120] loss: 0.782\n",
      "[121] loss: 0.488\n",
      "[122] loss: 0.482\n",
      "[123] loss: 0.793\n",
      "[124] loss: 0.469\n",
      "[125] loss: 0.802\n",
      "[126] loss: 0.457\n",
      "[127] loss: 0.450\n",
      "[128] loss: 0.817\n",
      "[129] loss: 0.821\n",
      "[130] loss: 0.824\n",
      "[131] loss: 0.825\n",
      "[132] loss: 0.433\n",
      "[133] loss: 0.825\n",
      "[134] loss: 0.433\n",
      "[135] loss: 0.431\n",
      "[136] loss: 0.427\n",
      "[137] loss: 0.833\n",
      "[138] loss: 1.074\n",
      "[139] loss: 0.835\n",
      "[140] loss: 0.423\n",
      "[141] loss: 1.063\n",
      "[142] loss: 1.053\n",
      "[143] loss: 1.036\n",
      "[144] loss: 1.012\n",
      "[145] loss: 0.797\n",
      "[146] loss: 0.785\n",
      "[147] loss: 0.504\n",
      "[148] loss: 0.765\n",
      "[149] loss: 0.533\n",
      "[150] loss: 0.752\n",
      "[151] loss: 0.746\n",
      "[152] loss: 0.840\n",
      "[153] loss: 0.581\n",
      "[154] loss: 0.729\n",
      "[155] loss: 0.724\n",
      "[156] loss: 0.615\n",
      "[157] loss: 0.621\n",
      "[158] loss: 0.769\n",
      "[159] loss: 0.629\n",
      "[160] loss: 0.631\n",
      "[161] loss: 0.714\n",
      "[162] loss: 0.714\n",
      "[163] loss: 0.714\n",
      "[164] loss: 0.630\n",
      "[165] loss: 0.714\n",
      "[166] loss: 0.714\n",
      "[167] loss: 0.628\n",
      "[168] loss: 0.715\n",
      "[169] loss: 0.716\n",
      "[170] loss: 0.768\n",
      "[171] loss: 0.762\n",
      "[172] loss: 0.710\n",
      "[173] loss: 0.649\n",
      "[174] loss: 0.734\n",
      "[175] loss: 0.702\n",
      "[176] loss: 0.699\n",
      "[177] loss: 0.696\n",
      "[178] loss: 0.692\n",
      "[179] loss: 0.707\n",
      "[180] loss: 0.688\n",
      "[181] loss: 0.687\n",
      "[182] loss: 0.725\n",
      "[183] loss: 0.685\n",
      "[184] loss: 0.728\n",
      "[185] loss: 0.685\n",
      "[186] loss: 0.723\n",
      "[187] loss: 0.687\n",
      "[188] loss: 0.711\n",
      "[189] loss: 0.701\n",
      "[190] loss: 0.688\n",
      "[191] loss: 0.700\n",
      "[192] loss: 0.704\n",
      "[193] loss: 0.646\n",
      "[194] loss: 0.712\n",
      "[195] loss: 0.716\n",
      "[196] loss: 0.614\n",
      "[197] loss: 0.603\n",
      "[198] loss: 0.730\n",
      "[199] loss: 0.734\n",
      "[200] loss: 0.738\n",
      "[201] loss: 0.741\n",
      "[202] loss: 0.562\n",
      "[203] loss: 0.556\n",
      "[204] loss: 0.546\n",
      "[205] loss: 0.535\n",
      "[206] loss: 0.763\n",
      "[207] loss: 0.769\n",
      "[208] loss: 0.774\n",
      "[209] loss: 0.499\n",
      "[210] loss: 0.781\n",
      "[211] loss: 0.784\n",
      "[212] loss: 0.485\n",
      "[213] loss: 0.788\n",
      "[214] loss: 0.790\n",
      "[215] loss: 0.478\n",
      "[216] loss: 0.792\n",
      "[217] loss: 0.973\n",
      "[218] loss: 0.479\n",
      "[219] loss: 0.479\n",
      "[220] loss: 0.791\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.969\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.969\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.969\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.969\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.969\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.969\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.791\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "[25] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.477\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.791\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.477\n",
      "\n",
      "\n",
      "[1] loss: 0.791\n",
      "[2] loss: 0.966\n",
      "[3] loss: 0.785\n",
      "[4] loss: 0.494\n",
      "[5] loss: 0.777\n",
      "[6] loss: 0.774\n",
      "[7] loss: 0.770\n",
      "[8] loss: 0.519\n",
      "[9] loss: 0.523\n",
      "[10] loss: 0.524\n",
      "[11] loss: 0.764\n",
      "[12] loss: 0.764\n",
      "[13] loss: 0.763\n",
      "[14] loss: 0.525\n",
      "[15] loss: 0.762\n",
      "[16] loss: 0.761\n",
      "[17] loss: 0.890\n",
      "[18] loss: 0.755\n",
      "[19] loss: 0.750\n",
      "[20] loss: 0.854\n",
      "[21] loss: 0.835\n",
      "[22] loss: 0.587\n",
      "[23] loss: 0.599\n",
      "[24] loss: 0.722\n",
      "[25] loss: 0.719\n",
      "[26] loss: 0.716\n",
      "[27] loss: 0.712\n",
      "[28] loss: 0.745\n",
      "[29] loss: 0.659\n",
      "[30] loss: 0.668\n",
      "[31] loss: 0.716\n",
      "[32] loss: 0.697\n",
      "[33] loss: 0.695\n",
      "[34] loss: 0.696\n",
      "[35] loss: 0.687\n",
      "[36] loss: 0.689\n",
      "[37] loss: 0.687\n",
      "[38] loss: 0.685\n",
      "[39] loss: 0.683\n",
      "[40] loss: 0.745\n",
      "[41] loss: 0.680\n",
      "[42] loss: 0.752\n",
      "[43] loss: 0.679\n",
      "[44] loss: 0.750\n",
      "[45] loss: 0.681\n",
      "[46] loss: 0.740\n",
      "[47] loss: 0.731\n",
      "[48] loss: 0.717\n",
      "[49] loss: 0.700\n",
      "[50] loss: 0.697\n",
      "[51] loss: 0.664\n",
      "[52] loss: 0.645\n",
      "[53] loss: 0.623\n",
      "[54] loss: 0.600\n",
      "[55] loss: 0.735\n",
      "[56] loss: 0.851\n",
      "[57] loss: 0.751\n",
      "[58] loss: 0.536\n",
      "[59] loss: 0.524\n",
      "[60] loss: 0.916\n",
      "[61] loss: 0.774\n",
      "[62] loss: 0.499\n",
      "[63] loss: 0.492\n",
      "[64] loss: 0.787\n",
      "[65] loss: 0.477\n",
      "[66] loss: 0.468\n",
      "[67] loss: 0.804\n",
      "[68] loss: 0.809\n",
      "[69] loss: 1.021\n",
      "[70] loss: 0.447\n",
      "[71] loss: 0.814\n",
      "[72] loss: 0.446\n",
      "[73] loss: 0.815\n",
      "[74] loss: 0.443\n",
      "[75] loss: 0.441\n",
      "[76] loss: 0.821\n",
      "[77] loss: 0.823\n",
      "[78] loss: 0.433\n",
      "[79] loss: 0.826\n",
      "[80] loss: 0.826\n",
      "[81] loss: 0.824\n",
      "[82] loss: 0.436\n",
      "[83] loss: 0.436\n",
      "[84] loss: 0.822\n",
      "[85] loss: 0.435\n",
      "[86] loss: 0.433\n",
      "[87] loss: 0.428\n",
      "[88] loss: 0.833\n",
      "[89] loss: 0.418\n",
      "[90] loss: 1.084\n",
      "[91] loss: 0.412\n",
      "[92] loss: 0.844\n",
      "[93] loss: 0.844\n",
      "[94] loss: 0.411\n",
      "[95] loss: 0.410\n",
      "[96] loss: 0.407\n",
      "[97] loss: 0.850\n",
      "[98] loss: 0.400\n",
      "[99] loss: 0.396\n",
      "[100] loss: 0.862\n",
      "[101] loss: 0.865\n",
      "[102] loss: 0.866\n",
      "[103] loss: 0.387\n",
      "[104] loss: 0.386\n",
      "[105] loss: 0.869\n",
      "[106] loss: 0.383\n",
      "[107] loss: 0.872\n",
      "[108] loss: 0.872\n",
      "[109] loss: 0.870\n",
      "[110] loss: 0.866\n",
      "[111] loss: 0.391\n",
      "[112] loss: 0.394\n",
      "[113] loss: 0.858\n",
      "[114] loss: 0.856\n",
      "[115] loss: 0.401\n",
      "[116] loss: 0.850\n",
      "[117] loss: 0.847\n",
      "[118] loss: 0.842\n",
      "[119] loss: 0.836\n",
      "[120] loss: 0.829\n",
      "[121] loss: 0.821\n",
      "[122] loss: 0.813\n",
      "[123] loss: 0.459\n",
      "[124] loss: 0.467\n",
      "[125] loss: 0.471\n",
      "[126] loss: 0.794\n",
      "[127] loss: 0.791\n",
      "[128] loss: 0.481\n",
      "[129] loss: 0.960\n",
      "[130] loss: 0.783\n",
      "[131] loss: 0.778\n",
      "[132] loss: 0.505\n",
      "[133] loss: 0.770\n",
      "[134] loss: 0.766\n",
      "[135] loss: 0.524\n",
      "[136] loss: 0.527\n",
      "[137] loss: 0.760\n",
      "[138] loss: 0.529\n",
      "[139] loss: 0.760\n",
      "[140] loss: 0.760\n",
      "[141] loss: 0.759\n",
      "[142] loss: 0.533\n",
      "[143] loss: 0.533\n",
      "[144] loss: 0.758\n",
      "[145] loss: 0.529\n",
      "[146] loss: 0.762\n",
      "[147] loss: 0.522\n",
      "[148] loss: 0.907\n",
      "[149] loss: 0.766\n",
      "[150] loss: 0.519\n",
      "[151] loss: 0.518\n",
      "[152] loss: 0.513\n",
      "[153] loss: 0.924\n",
      "[154] loss: 0.504\n",
      "[155] loss: 0.933\n",
      "[156] loss: 0.500\n",
      "[157] loss: 0.777\n",
      "[158] loss: 0.497\n",
      "[159] loss: 0.780\n",
      "[160] loss: 0.493\n",
      "[161] loss: 0.489\n",
      "[162] loss: 0.482\n",
      "[163] loss: 0.793\n",
      "[164] loss: 0.985\n",
      "[165] loss: 0.798\n",
      "[166] loss: 0.983\n",
      "[167] loss: 0.792\n",
      "[168] loss: 0.787\n",
      "[169] loss: 0.782\n",
      "[170] loss: 0.501\n",
      "[171] loss: 0.772\n",
      "[172] loss: 0.767\n",
      "[173] loss: 0.898\n",
      "[174] loss: 0.755\n",
      "[175] loss: 0.748\n",
      "[176] loss: 0.741\n",
      "[177] loss: 0.578\n",
      "[178] loss: 0.730\n",
      "[179] loss: 0.725\n",
      "[180] loss: 0.721\n",
      "[181] loss: 0.622\n",
      "[182] loss: 0.714\n",
      "[183] loss: 0.636\n",
      "[184] loss: 0.710\n",
      "[185] loss: 0.709\n",
      "[186] loss: 0.741\n",
      "[187] loss: 0.704\n",
      "[188] loss: 0.667\n",
      "[189] loss: 0.672\n",
      "[190] loss: 0.700\n",
      "[191] loss: 0.699\n",
      "[192] loss: 0.699\n",
      "[193] loss: 0.698\n",
      "[194] loss: 0.696\n",
      "[195] loss: 0.695\n",
      "[196] loss: 0.693\n",
      "[197] loss: 0.701\n",
      "[198] loss: 0.691\n",
      "[199] loss: 0.705\n",
      "[200] loss: 0.691\n",
      "[201] loss: 0.691\n",
      "[202] loss: 0.691\n",
      "[203] loss: 0.703\n",
      "[204] loss: 0.687\n",
      "[205] loss: 0.691\n",
      "[206] loss: 0.690\n",
      "[207] loss: 0.708\n",
      "[208] loss: 0.690\n",
      "[209] loss: 0.706\n",
      "[210] loss: 0.691\n",
      "[211] loss: 0.689\n",
      "[212] loss: 0.691\n",
      "[213] loss: 0.703\n",
      "[214] loss: 0.686\n",
      "[215] loss: 0.690\n",
      "[216] loss: 0.708\n",
      "[217] loss: 0.690\n",
      "[218] loss: 0.706\n",
      "[219] loss: 0.701\n",
      "[220] loss: 0.694\n",
      "$$Finished Training This Epoch\n",
      "Start a new val_epoch\n",
      "Validation\n",
      "[1] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[2] loss: 0.702\n",
      "\n",
      "\n",
      "Validation\n",
      "[3] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[4] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[5] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[6] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[7] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[8] loss: 0.702\n",
      "\n",
      "\n",
      "Validation\n",
      "[9] loss: 0.702\n",
      "\n",
      "\n",
      "Validation\n",
      "[10] loss: 0.702\n",
      "\n",
      "\n",
      "Validation\n",
      "[11] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[12] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[13] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[14] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[15] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[16] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[17] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[18] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[19] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[20] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[21] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[22] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[23] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[24] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[25] loss: 0.702\n",
      "\n",
      "\n",
      "Validation\n",
      "[26] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[27] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[28] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[29] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[30] loss: 0.684\n",
      "\n",
      "\n",
      "Validation\n",
      "[31] loss: 0.696\n",
      "\n",
      "\n",
      "Validation\n",
      "[32] loss: 0.684\n",
      "\n",
      "\n",
      "[1] loss: 0.684\n",
      "[2] loss: 0.699\n",
      "[3] loss: 0.702\n",
      "[4] loss: 0.704\n",
      "[5] loss: 0.654\n",
      "[6] loss: 0.646\n",
      "[7] loss: 0.756\n",
      "[8] loss: 0.628\n",
      "[9] loss: 0.619\n",
      "[10] loss: 0.606\n",
      "[11] loss: 0.807\n",
      "[12] loss: 0.732\n",
      "[13] loss: 0.735\n",
      "[14] loss: 0.573\n",
      "[15] loss: 0.740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def ToTensor(np_array):\n",
    "    tensor = torch.from_numpy(np_array)\n",
    "    tensor = tensor.float()\n",
    "    return tensor\n",
    "\n",
    "loss_val_min = 1000000\n",
    "#threshold = 20\n",
    "count = 0\n",
    "#count_big = 0\n",
    "epoch = 50\n",
    "min_total_loss = 1000000\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    for i_batch, sample_batched in enumerate(dataloader_train):\n",
    "        #print(sample_batched[images].shape)\n",
    "        #print(i_batch)\n",
    "        #print(i_batch,\n",
    "        #      sample_batched['patient_id'])\n",
    "        \n",
    "        labels = sample_batched['labels'].cuda()\n",
    "        #labels_arr = np.asarray(sample_batched['labels'])\n",
    "        #print(labels_arr.shape)\n",
    "        running_loss = 0.0\n",
    "       \n",
    "    # get the inputs\n",
    "        \n",
    "        #labels_arr = np.asarray(sample_batched['labels'])\n",
    "        #labels_arr = labels_arr.astype(np.int)\n",
    "        #labels = ToTensor(labels_arr).cuda()\n",
    "\n",
    "        images = sample_batched['image'].float().cuda()\n",
    "        images = np.expand_dims(images, 1)\n",
    "        images = ToTensor(images).cuda()\n",
    "        #images_arr = np.asarray(sample_batched['image'])\n",
    "        #images_arr = images_arr.astype(np.float)\n",
    "        #images_arr = np.expand_dims(images_arr, 1)\n",
    "        #images = ToTensor(images_arr).cuda()\n",
    "\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #before actual training\n",
    "        net_3d.train()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net_3d(images)\n",
    "        #print(outputs)\n",
    "        #print(labels.long())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        print('[%d] loss: %.3f' %\n",
    "                (i_batch + 1, loss.item()))\n",
    "\n",
    "    print('$$Finished Training This Epoch')\n",
    "    \n",
    "    #validation for the epoch\n",
    "    net_3d.eval()\n",
    "    total_val_loss = 0\n",
    "    print('Start a new val_epoch')\n",
    "    for i_batch, sample_batched in enumerate(dataloader_val):\n",
    "        #print(i_batch)\n",
    "              #sample_batched['patient_id'])\n",
    "\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        labels = sample_batched['labels'].cuda()\n",
    "        images = sample_batched['image'].float().cuda()\n",
    "        images = np.expand_dims(images, 1)\n",
    "        images = ToTensor(images).cuda()\n",
    "        # get the inputs\n",
    "        #labels_arr = np.asarray(sample_batched['labels'])\n",
    "        #labels_arr = labels_arr.astype(np.int)\n",
    "        #labels = ToTensor(labels_arr).cuda()\n",
    "\n",
    "        #images_arr = np.asarray(sample_batched['image'])\n",
    "        #images_arr = images_arr.astype(np.float)\n",
    "        #images_arr = np.expand_dims(images_arr, 1)\n",
    "        #images = ToTensor(images_arr).cuda()\n",
    "        \n",
    "        outputs = net_3d(images)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        print('Validation')\n",
    "        print('[%d] loss: %.3f' %\n",
    "                (i_batch + 1, loss.item()))\n",
    "        #print(loss.item())\n",
    "        #print(type(loss.item()))\n",
    "        print('\\n')\n",
    "        \n",
    "        total_val_loss = total_val_loss + loss.cpu().data.numpy()\n",
    "        \n",
    "    if(total_val_loss < loss_val_min):\n",
    "        loss_val_min = total_val_loss\n",
    "        torch.save(net_3d, 'best_model_3D_Feb4_weighted_MCI_CN.pkl')\n",
    "    #if(total_val_loss < min_total_loss):\n",
    "        #min_total_loss = total_val_loss\n",
    "        #save best model\n",
    "        #torch.save(net_2d, 'best_model_Jan27_2d_3types.pkl')\n",
    "    #if(count > threshold):\n",
    "        #break\n",
    "    #if(total_val_loss > 0.7):\n",
    "        #count_big += 1\n",
    "    #if(count_big > threshold):\n",
    "        #break\n",
    "    #if(total_val_loss < 0.67):\n",
    "        #break\n",
    "\n",
    "print(\"we're done training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "126\n",
      "actual 80 46\n",
      "correct_sum 0.0\n",
      "correct_sum_MCI 80\n",
      "correct_sum_CN 0\n",
      "126.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#test after finish all epochs\n",
    "\n",
    "#load the best_model back \n",
    "final_net = torch.load('best_model_3D_Feb4_weighted_MCI_CN.pkl')\n",
    "final_net.eval()\n",
    "correct_sum = 0.\n",
    "total_sum = 0.\n",
    "results_all_type = []\n",
    "labels_all = []\n",
    "for i_batch, sample_batched in enumerate(dataloader_test):\n",
    "    #print(i_batch)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    labels = sample_batched['labels'].cuda()\n",
    "    # get the inputs\n",
    "    # labels_arr = np.asarray(sample_batched['labels'])\n",
    "    # labels_arr = labels_arr.astype(np.int)\n",
    "    # labels = ToTensor(labels_arr).cuda()\n",
    "    images = sample_batched['image'].float().cuda()\n",
    "    images = np.expand_dims(images, 1)\n",
    "    images = ToTensor(images).cuda()\n",
    "    # images_arr = np.asarray(sample_batched['image'])\n",
    "    # images_arr = images_arr.astype(np.float)\n",
    "    # images = ToTensor(images_arr).cuda()\n",
    "\n",
    "    outputs = final_net(images)#n * 3\n",
    "    results_type = np.argmax(outputs.cpu().data.numpy(), axis=1)\n",
    "    results_type = ToTensor(results_type)\n",
    "    #print(outputs)\n",
    "\n",
    "    #calculate accuracy\n",
    "    labels = labels.cpu()\n",
    "    #print(\"predicted:\\n\", results_type, \"\\nactual:\\n\", labels)\n",
    "\n",
    "    results_all_type.append(results_type[0])\n",
    "    results_all_type.append(results_type[1])\n",
    "    labels_all.append(labels[0])\n",
    "    labels_all.append(labels[1])\n",
    "print(len(results_all_type))\n",
    "print(len(labels_all))\n",
    "CN_num = 0\n",
    "MCI_num = 0\n",
    "correct_sum_MCI = 0\n",
    "correct_sum_CN = 0\n",
    "for label in labels_all:\n",
    "    if (label.float() == 1):\n",
    "        MCI_num += 1\n",
    "    if (label.float() == 0):\n",
    "        CN_num += 1\n",
    "print(\"actual\", MCI_num, CN_num)\n",
    "\n",
    "for i in range(len(results_all_type)):\n",
    "    if(labels_all[i].float() == results_all_type[i].float()):\n",
    "        if(results_all_type[i].float() == 1):\n",
    "            correct_sum_MCI += 1\n",
    "    if(labels_all[i].float() == results_all_type[i].float()):\n",
    "        if(results_all_type[i].float() == 0):\n",
    "            correct_sum_CN += 1\n",
    "    total_sum += 1\n",
    "    \n",
    "print(\"correct_sum\", correct_sum)\n",
    "print(\"correct_sum_MCI\", correct_sum_MCI)\n",
    "print(\"correct_sum_CN\", correct_sum_CN)\n",
    "print(total_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
